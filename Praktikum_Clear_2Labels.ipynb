{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7H2KAnONza1V"
      },
      "source": [
        "#Installing Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvwTuouQzWcg",
        "outputId": "d289ea5d-e40a-48e6-b5b0-984283fb8576"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-24.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 23.1.2\n",
            "    Uninstalling pip-23.1.2:\n",
            "      Successfully uninstalled pip-23.1.2\n",
            "Successfully installed pip-24.1\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade pip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Ct0qWoYzdRa",
        "outputId": "a8026aea-1be9-481e-9f56-150cf9323d43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Collecting pydicom\n",
            "  Downloading pydicom-2.4.4-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (0.19.3)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (2.31.6)\n",
            "Collecting pylibjpeg\n",
            "  Downloading pylibjpeg-2.0.1-py3-none-any.whl (24 kB)\n",
            "Collecting pylibjpeg-libjpeg\n",
            "  Downloading pylibjpeg_libjpeg-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pylibjpeg-openjpeg\n",
            "  Downloading pylibjpeg_openjpeg-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.11.4)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (3.3)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (9.4.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2024.6.18)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (24.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Installing collected packages: pylibjpeg-openjpeg, pylibjpeg-libjpeg, pylibjpeg, pydicom\n",
            "Successfully installed pydicom-2.4.4 pylibjpeg-2.0.1 pylibjpeg-libjpeg-2.2.0 pylibjpeg-openjpeg-2.3.0\n"
          ]
        }
      ],
      "source": [
        "# Install the required packages\n",
        "!pip install numpy pandas pydicom scikit-image imageio pylibjpeg pylibjpeg-libjpeg pylibjpeg-openjpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wk3ieXwRzhKg",
        "outputId": "2d383b9a-3ea3-46d4-a8d6-74dd36182283"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting monai\n",
            "  Downloading monai-1.3.2-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.0+cu121)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.10/dist-packages (4.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.4)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from monai) (1.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from nibabel) (24.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nibabel) (67.7.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, monai\n",
            "Successfully installed monai-1.3.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ],
      "source": [
        "!pip install monai torch torchvision nibabel tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ulf7nZ5czhQI",
        "outputId": "a02ec24b-a17c-4d8a-f2a3-a9fb773a1dd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: pydicom in /usr/local/lib/python3.10/dist-packages (2.4.4)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (0.19.3)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (2.31.6)\n",
            "Requirement already satisfied: pylibjpeg in /usr/local/lib/python3.10/dist-packages (2.0.1)\n",
            "Requirement already satisfied: pylibjpeg-libjpeg in /usr/local/lib/python3.10/dist-packages (2.2.0)\n",
            "Requirement already satisfied: pylibjpeg-openjpeg in /usr/local/lib/python3.10/dist-packages (2.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.11.4)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (3.3)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (9.4.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2024.6.18)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (24.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "# Install the required packages\n",
        "!pip install numpy pandas pydicom scikit-image imageio pylibjpeg pylibjpeg-libjpeg pylibjpeg-openjpeg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJwOK37rzg2m"
      },
      "source": [
        "#DICOM Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NEUXMS9KzkhT"
      },
      "outputs": [],
      "source": [
        "from typing import AnyStr, BinaryIO, Dict, List, NamedTuple, Optional, Union\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pydicom as dicom\n",
        "from skimage.exposure import rescale_intensity\n",
        "import imageio\n",
        "\n",
        "def dcmread_image(fp: Union[str, os.PathLike[AnyStr], BinaryIO], view: str, index: Optional[np.uint] = None) -> np.ndarray:\n",
        "    \"\"\"Read pixel array from DBT DICOM file.\"\"\"\n",
        "    ds = dicom.dcmread(fp)\n",
        "    ds.decompress(handler_name=\"pylibjpeg\")  # Use pylibjpeg for decompression\n",
        "    pixel_array = ds.pixel_array\n",
        "    view_laterality = view[0].upper()\n",
        "    image_laterality = _get_image_laterality(pixel_array[index or 0])\n",
        "\n",
        "    if index is not None:\n",
        "        pixel_array = pixel_array[index]\n",
        "\n",
        "    if not image_laterality == view_laterality:\n",
        "        pixel_array = np.flip(pixel_array, axis=(-1, -2))\n",
        "\n",
        "    window_center = _get_window_center(ds)\n",
        "    window_width = _get_window_width(ds)\n",
        "    low = (2 * window_center - window_width) / 2\n",
        "    high = (2 * window_center + window_width) / 2\n",
        "    pixel_array = rescale_intensity(pixel_array, in_range=(low, high), out_range=\"dtype\")\n",
        "\n",
        "    return pixel_array\n",
        "\n",
        "def read_boxes(boxes_fp: str, filepaths_fp: str) -> pd.DataFrame:\n",
        "    \"\"\"Read pandas DataFrame with bounding boxes joined with file paths.\"\"\"\n",
        "    df_boxes = pd.read_csv(boxes_fp)\n",
        "    df_filepaths = pd.read_csv(filepaths_fp)\n",
        "    primary_key = (\"PatientID\", \"StudyUID\", \"View\")\n",
        "        if not all([key in df_boxes.columns for key in primary_key]):\n",
        "        raise AssertionError(f\"Not all primary key columns {primary_key} are present in bounding boxes columns {df_boxes.columns}\")\n",
        "\n",
        "    if not all([key in df_filepaths.columns for key in primary_key]):\n",
        "        raise AssertionError(f\"Not all primary key columns {primary_key} are present in file paths columns {df_filepaths.columns}\")\n",
        "\n",
        "    return pd.merge(df_boxes, df_filepaths, on=primary_key)\n",
        "\n",
        "def draw_box(image: np.ndarray, x: int, y: int, width: int, height: int, color: Optional[Union[int, tuple]] = None, lw=4) -> np.ndarray:\n",
        "    \"\"\"Draw bounding box on the image.\"\"\"\n",
        "    x = min(max(x, 0), image.shape[1] - 1)\n",
        "    y = min(max(y, 0), image.shape[0] - 1)\n",
        "\n",
        "    if color is None:\n",
        "        color = 255\n",
        "\n",
        "    if len(image.shape) > 2 and not hasattr(color, \"__len__\"):\n",
        "        color = (color,) + (0,) * (image.shape[-1] - 1)\n",
        "\n",
        "    image[y : y + lw, x : x + width] = color\n",
        "    image[y + height - lw : y + height, x : x + width] = color\n",
        "    image[y : y + height, x : x + lw] = color\n",
        "    image[y : y + height, x + width - lw : x + width] = color\n",
        "\n",
        "    return image\n",
        "\n",
        "def evaluate(labels_fp: str, boxes_fp: str, predictions_fp: str) -> Dict[str, float]:\n",
        "    \"\"\"Evaluate predictions.\"\"\"\n",
        "    df_labels = pd.read_csv(labels_fp)\n",
        "    df_boxes = pd.read_csv(boxes_fp, dtype={\"VolumeSlices\": float})\n",
        "    df_pred = pd.read_csv(predictions_fp, dtype={\"Score\": float})\n",
        "\n",
        "    df_labels = df_labels.reset_index().set_index([\"StudyUID\", \"View\"]).sort_index()\n",
        "    df_boxes = df_boxes.reset_index().set_index([\"StudyUID\", \"View\"]).sort_index()\n",
        "    df_pred = df_pred.reset_index().set_index([\"StudyUID\", \"View\"]).sort_index()\n",
        "\n",
        "    df_pred[\"TP\"] = 0\n",
        "    df_pred[\"GTID\"] = -1\n",
        "\n",
        "    thresholds = [df_pred[\"Score\"].max() + 1.0]\n",
        "\n",
        "    for box_pred in df_pred.itertuples():\n",
        "        if box_pred.Index not in df_boxes.index:\n",
        "            continue\n",
        "\n",
        "        df_boxes_view = df_boxes.loc[[box_pred.Index]]\n",
        "        view_slice_offset = df_boxes.loc[[box_pred.Index], \"VolumeSlices\"].iloc[0] / 4\n",
        "        tp_boxes = [b for b in df_boxes_view.itertuples() if _is_tp(box_pred, b, slice_offset=view_slice_offset)]\n",
        "\n",
        "        if len(tp_boxes) > 1:\n",
        "            tp_distances = [_distance(box_pred, b) for b in tp_boxes]\n",
        "            tp_boxes = [tp_boxes[np.argmin(tp_distances)]]\n",
        "\n",
        "        if len(tp_boxes) > 0:\n",
        "            tp_i = tp_boxes[0].index\n",
        "            df_pred.loc[df_pred[\"index\"] == box_pred.index, (\"TP\", \"GTID\")] = (1, tp_i)\n",
        "            thresholds.append(box_pred.Score)\n",
        "\n",
        "    thresholds.append(df_pred[\"Score\"].min() - 1.0)\n",
        "\n",
        "    evaluation_fps_all = (2.0,)\n",
        "    tpr_all = _froc(df_pred=df_pred, thresholds=thresholds, n_volumes=len(df_labels), n_boxes=len(df_boxes), evaluation_fps=evaluation_fps_all)\n",
        "    result = {f\"sensitivity_at_2_fps_all\": tpr_all[0]}\n",
        "\n",
        "    df_pred = df_pred[df_pred.index.isin(df_boxes.index)]\n",
        "    df_labels = df_labels[df_labels.index.isin(df_boxes.index)]\n",
        "    evaluation_fps_positive = (1.0, 2.0, 3.0, 4.0)\n",
        "    tpr_positive = _froc(df_pred=df_pred, thresholds=thresholds, n_volumes=len(df_labels), n_boxes=len(df_boxes), evaluation_fps=evaluation_fps_positive)\n",
        "\n",
        "    result.update(dict((f\"sensitivity_at_{int(x)}_fps_positive\", y) for x, y in zip(evaluation_fps_positive, tpr_positive)))\n",
        "    result.update({\"mean_sensitivity_positive\": np.mean(tpr_positive)})\n",
        "\n",
        "    return result\n",
        "\n",
        "def _froc(df_pred: pd.DataFrame, thresholds: List[float], n_volumes: int, n_boxes: int, evaluation_fps: tuple) -> List[float]:\n",
        "    \"\"\"Free-response receiver operating characteristic (FROC) calculation.\"\"\"\n",
        "    tpr = []\n",
        "    fps = []\n",
        "\n",
        "    for th in sorted(thresholds, reverse=True):\n",
        "        df_th = df_pred.loc[df_pred[\"Score\"] >= th]\n",
        "        df_th_unique_tp = df_th.reset_index().drop_duplicates(subset=[\"StudyUID\", \"View\", \"TP\", \"GTID\"])\n",
        "        n_tps_th = float(sum(df_th_unique_tp[\"TP\"]))\n",
        "        tpr_th = n_tps_th / n_boxes\n",
        "        n_fps_th = float(len(df_th[df_th[\"TP\"] == 0]))\n",
        "        fps_th = n_fps_th / n_volumes\n",
        "        tpr.append(tpr_th)\n",
        "        fps.append(fps_th)\n",
        "\n",
        "        if fps_th > max(evaluation_fps):\n",
        "            break\n",
        "\n",
        "    return [np.interp(x, fps, tpr) for x in evaluation_fps]\n",
        "\n",
        "def _is_tp(box_pred: NamedTuple, box_true: NamedTuple, slice_offset: int, min_dist: int = 100) -> bool:\n",
        "    \"\"\"Determine if a prediction is a true positive.\"\"\"\n",
        "    pred_y = box_pred.Y + box_pred.Height / 2\n",
        "    pred_x = box_pred.X + box_pred.Width / 2\n",
        "    pred_z = box_pred.Z + box_pred.Depth / 2\n",
        "    true_y = box_true.Y + box_true.Height / 2\n",
        "    true_x = box_true.X + box_true.Width / 2\n",
        "    true_z = box_true.Slice\n",
        "\n",
        "    dist = np.linalg.norm((pred_x - true_x, pred_y - true_y))\n",
        "    dist_threshold = np.sqrt(box_true.Width ** 2 + box_true.Height ** 2) / 2.0\n",
        "    dist_threshold = max(dist_threshold, min_dist)\n",
        "    slice_diff = np.abs(pred_z - true_z)\n",
        "\n",
        "    return dist <= dist_threshold and slice_diff <= slice_offset\n",
        "\n",
        "def _distance(box_pred: NamedTuple, box_true: NamedTuple) -> float:\n",
        "    \"\"\"Calculate the Euclidean distance between predicted and true box centers.\"\"\"\n",
        "    pred_y = box_pred.Y + box_pred.Height / 2\n",
        "    pred_x = box_pred.X + box_pred.Width / 2\n",
        "    pred_z = box_pred.Z + box_pred.Depth / 2\n",
        "    true_y = box_true.Y + box_true.Height / 2\n",
        "    true_x = box_true.X + box_true.Width / 2\n",
        "    true_z = box_true.Slice\n",
        "\n",
        "    return np.linalg.norm((pred_x - true_x, pred_y - true_y, pred_z - true_z))\n",
        "\n",
        "def _get_dicom_laterality(ds: dicom.dataset.FileDataset) -> str:\n",
        "    \"\"\"Get laterality from DICOM metadata (unreliable).\"\"\"\n",
        "    return ds[0x5200, 0x9229][0][0x0020, 0x9071][0][0x0020, 0x9072].value\n",
        "\n",
        "def _get_image_laterality(pixel_array: np.ndarray) -> str:\n",
        "    \"\"\"Determine laterality based on image pixel intensity.\"\"\"\n",
        "    left_edge = np.sum(pixel_array[:, 0])  # sum of left edge pixels\n",
        "    right_edge = np.sum(pixel_array[:, -1])  # sum of right edge pixels\n",
        "    return \"R\" if left_edge < right_edge else \"L\"\n",
        "\n",
        "def _get_window_center(ds: dicom.dataset.FileDataset) -> np.float32:\n",
        "    \"\"\"Get window center from DICOM metadata.\"\"\"\n",
        "    return np.float32(ds[0x5200, 0x9229][0][0x0028, 0x9132][0][0x0028, 0x1050].value)\n",
        "\n",
        "def _get_window_width(ds: dicom.dataset.FileDataset) -> np.float32:\n",
        "    \"\"\"Get window width from DICOM metadata.\"\"\"\n",
        "    return np.float32(ds[0x5200, 0x9229][0][0x0028, 0x9132][0][0x0028, 0x1051].value)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfeBJQYwzoS-"
      },
      "source": [
        "#Processing DICOM Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YB5rr2zLzq8k"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def process_dicom_files(dicom_files: List[str], boxes_csv_path: str, filepaths_csv_path: str, labels_csv_path: str, predictions_csv_path: str):\n",
        "    # Read bounding boxes and file paths\n",
        "    df = read_boxes(boxes_csv_path, filepaths_csv_path)\n",
        "\n",
        "    for dicom_file_path in dicom_files:\n",
        "        # Extract the view from the file path or use a default view\n",
        "        view = 'LCC'  # Example view; adjust as needed\n",
        "\n",
        "        # Read and process the DICOM file\n",
        "        image_array = dcmread_image(dicom_file_path, view)\n",
        "\n",
        "        # Draw a bounding box on the image (example coordinates)\n",
        "        x, y, width, height = 50, 50, 100, 100  # Replace with actual coordinates if available\n",
        "        image_with_box = draw_box(image_array, x, y, width, height)\n",
        "\n",
        "        # Save the image with the bounding box\n",
        "        output_image_path = os.path.splitext(dicom_file_path)[0] + '_output.png'\n",
        "        imageio.imwrite(output_image_path, image_with_box)\n",
        "\n",
        "        # Evaluate predictions\n",
        "        if labels_csv_path and predictions_csv_path:\n",
        "            evaluation_results = evaluate(labels_csv_path, boxes_csv_path, predictions_csv_path)\n",
        "            print(f\"Evaluation results for {dicom_file_path}: {evaluation_results}\")\n",
        "\n",
        "# Define file paths\n",
        "boxes_csv_path = '/content/Breast-Cancer-Screening-DBT/boxes.csv'\n",
        "filepaths_csv_path = '/content/Breast-Cancer-Screening-DBT/filepaths.csv'\n",
        "labels_csv_path = '/content/Breast-Cancer-Screening-DBT/labels.csv'\n",
        "predictions_csv_path = '/content/Breast-Cancer-Screening-DBT/predictions.csv'\n",
        "\n",
        "# Process the DICOM files\n",
        "process_dicom_files(dicom_files, boxes_csv_path, filepaths_csv_path, labels_csv_path, predictions_csv_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrNeKW6-zlrk"
      },
      "source": [
        "#Unzipping and Combining"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYjKbDilzutW",
        "outputId": "dd45e065-1d39-4bb4-ac39-5c98e51e7b07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Found 200 DICOM files.\n"
          ]
        }
      ],
      "source": [
        "# @title\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the function to combine and extract ZIP files\n",
        "import zipfile\n",
        "import os\n",
        "from typing import List\n",
        "\n",
        "def combine_and_extract_zip_files(zip_files: List[str], extract_to: str) -> List[str]:\n",
        "    \"\"\"\n",
        "    Extract multiple ZIP files into a single directory.\n",
        "    Collect all DICOM file paths from the extracted directories.\n",
        "\n",
        "    Parameters:\n",
        "    - zip_files: List of ZIP file paths to be extracted.\n",
        "    - extract_to: Directory where the ZIP files will be extracted.\n",
        "\n",
        "    Returns:\n",
        "    - List of all DICOM file paths.\n",
        "    \"\"\"\n",
        "    all_dicom_files = []\n",
        "\n",
        "    # Extract each ZIP file\n",
        "    for zip_file in zip_files:\n",
        "        with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
        "            zip_ref.extractall(extract_to)\n",
        "\n",
        "    # Collect all DICOM files from the extracted directories\n",
        "    for subdir, _, files in os.walk(extract_to):\n",
        "        for file in files:\n",
        "            if file.lower().endswith('.dcm'):\n",
        "                all_dicom_files.append(os.path.join(subdir, file))\n",
        "\n",
        "    return all_dicom_files\n",
        "\n",
        "\n",
        "# Define the directory to extract the ZIP files to\n",
        "extract_to = '/content/dataset/'\n",
        "\n",
        "# List of ZIP file paths on Google Drive\n",
        "zip_file_paths = [\n",
        "    '/content/drive/MyDrive/Praktikum/Breast-Cancer-Screening-DBT_before4000.zip',\n",
        "    '/content/drive/MyDrive/Praktikum/Breast-Cancer-Screening-DBT.zip'\n",
        "]\n",
        "\n",
        "# Combine and extract the ZIP files, and collect all DICOM file paths\n",
        "dicom_files = combine_and_extract_zip_files(zip_file_paths, extract_to)\n",
        "\n",
        "# Print the number of DICOM files found\n",
        "print(f\"Found {len(dicom_files)} DICOM files.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nO40rHbz3rX"
      },
      "source": [
        "#3D Patching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8T-XmiGz66K",
        "outputId": "db79ea27-bebf-4f1f-dbb1-39adb6cf7bfb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 164 DICOM files.\n",
            "/content/dataset/Breast-Cancer-Screening-DBT/normal/DBT-P00149/01-01-2000-DBT-S02770-MAMMO screening digital bilateral-29294/11753.000000-NA-97529/1-1.dcm\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 79%|███████▉  | 130/164 [00:35<00:10,  3.11it/s]"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pydicom\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from skimage.exposure import rescale_intensity\n",
        "import nibabel as nib\n",
        "from tqdm import tqdm\n",
        "import gc\n",
        "from typing import List\n",
        "import random\n",
        "\n",
        "def load_dicom_volume(dicom_file):\n",
        "    ds = pydicom.dcmread(dicom_file)\n",
        "    volume = ds.pixel_array\n",
        "    volume = rescale_intensity(volume, out_range=(0, 255)).astype(np.uint8)\n",
        "    return volume\n",
        "\n",
        "def get_patient_and_study_id(dicom_file_path):\n",
        "    \"\"\"\n",
        "    Extract Patient ID and Study ID from a DICOM file.\n",
        "\n",
        "    Parameters:\n",
        "    - dicom_file_path: Path to the DICOM file.\n",
        "\n",
        "    Returns:\n",
        "    - patient_id: The Patient ID extracted from the DICOM file.\n",
        "    - study_uid: The Study ID extracted from the DICOM file.\n",
        "    \"\"\"\n",
        "    ds = pydicom.dcmread(dicom_file_path)\n",
        "    patient_id = ds.PatientID\n",
        "    study_uid = ds.StudyInstanceUID\n",
        "    view = ds.ViewPosition\n",
        "    return patient_id, study_uid, view\n",
        "\n",
        "def collect_dicom_files(root_dir: str) -> List[str]:\n",
        "    \"\"\"Collect all DICOM file paths from the directory structure.\"\"\"\n",
        "    dicom_files = []\n",
        "    for subdir, _, files in os.walk(root_dir):\n",
        "        for file in files:\n",
        "            if file.lower().endswith('.dcm'):\n",
        "                dicom_files.append(os.path.join(subdir, file))\n",
        "    return dicom_files\n",
        "\n",
        "def save_slices_based_on_csv(csv_path, dicom_files, save_dir):\n",
        "    # Load the CSV file\n",
        "    csv_data = pd.read_csv(csv_path)\n",
        "\n",
        "    # Create a DataFrame to save metadata\n",
        "    df = pd.DataFrame(columns=['PatientID', 'StudyUID', 'view', 'img_path', 'Normal', 'Actionable', 'Benign', 'Cancer'])\n",
        "\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    for dicom_file in tqdm(dicom_files):\n",
        "        try:\n",
        "            patient_id, study_uid = get_patient_and_study_id(dicom_file)\n",
        "            matching_rows = csv_data[(csv_data['PatientID'] == patient_id)]\n",
        "\n",
        "            if not matching_rows.empty:\n",
        "                volume = load_dicom_volume(dicom_file)\n",
        "\n",
        "                for _, row in matching_rows.iterrows():\n",
        "                    view = row['View']\n",
        "                    x = row['X']\n",
        "                    y = row['Y']\n",
        "                    width = row['Width']\n",
        "                    height = row['Height']\n",
        "                    slice_idx = row['Slice']\n",
        "\n",
        "                    # Ensure the slice index is within bounds\n",
        "                    if 0 <= slice_idx < volume.shape[0]:\n",
        "                      try:\n",
        "                        slice_volume = volume[slice_idx-10:slice_idx+10,y-height-128:y+height+128 ,x-width-128:x+width+128]\n",
        "                        slice_name = f\"{patient_id}_{study_uid}_{view}_slice_{slice_idx}.nii.gz\"\n",
        "                        slice_nifti = nib.Nifti1Image(slice_volume, np.eye(4))\n",
        "                        nib.save(slice_nifti, os.path.join(save_dir, slice_name))\n",
        "\n",
        "                        df.loc[len(df)] = [\n",
        "                            patient_id, study_uid, view, os.path.join(save_dir, slice_name),\n",
        "                            row['Normal'], row['Actionable'], row['Benign'], row['Cancer']\n",
        "                        ]\n",
        "                      except Exception as a:\n",
        "                        print(print(f\"Error getting volume {dicom_file}: {a}\"))\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {dicom_file}: {e}\")\n",
        "        gc.collect()\n",
        "\n",
        "    # Save the metadata DataFrame\n",
        "    df.to_csv(os.path.join(save_dir, 'slices_metadata.csv'), index=False)\n",
        "\n",
        "# Define paths\n",
        "csv_path = '/content/drive/MyDrive/Praktikum/boxes.csv'\n",
        "dicom_dir = '/content/dataset/Breast-Cancer-Screening-DBT/normal/'\n",
        "save_dir = '/content/3d_slices_nii_3D_30P_normal/'\n",
        "\n",
        "# Collect all DICOM file paths\n",
        "dicom_files = collect_dicom_files(dicom_dir)\n",
        "print(f\"Found {len(dicom_files)} DICOM files.\")\n",
        "print(dicom_files[0])\n",
        "\n",
        "# Process the DICOM files based on the CSV data\n",
        "save_slices_based_on_csv(csv_path, dicom_files, save_dir)\n",
        "\n",
        "# Copy the saved slices to Google Drive\n",
        "!cp -r /content/3d_slices_nii_3D_30P_normal/ /content/drive/MyDrive/Praktikum/3d_dataset_slices_fcsv2_30P_normal/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CN0b6Qnq5-wt"
      },
      "source": [
        "#3D Patcing-Normal DS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcG0Xmgt6Bcj",
        "outputId": "a62ebb6d-1608-430d-8999-050b683cba39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 164 DICOM files.\n",
            "/content/dataset/Breast-Cancer-Screening-DBT/normal/DBT-P00149/01-01-2000-DBT-S02770-MAMMO screening digital bilateral-29294/11753.000000-NA-97529/1-1.dcm\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/164 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/pydicom/pixel_data_handlers/pillow_handler.py:238: UserWarning: The (0028,0101) 'Bits Stored' value (10-bit) doesn't match the JPEG 2000 data (16-bit). It's recommended that you change the 'Bits Stored' value\n",
            "  warnings.warn(\n",
            "  1%|          | 1/164 [00:44<2:01:07, 44.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 2/164 [01:25<1:54:40, 42.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 3/164 [02:01<1:45:48, 39.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 4/164 [02:36<1:40:15, 37.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 5/164 [03:06<1:32:41, 34.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  4%|▎         | 6/164 [03:33<1:25:03, 32.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  4%|▍         | 7/164 [04:05<1:24:21, 32.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  5%|▍         | 8/164 [04:31<1:18:38, 30.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  5%|▌         | 9/164 [04:50<1:08:34, 26.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  6%|▌         | 10/164 [05:08<1:01:48, 24.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  7%|▋         | 11/164 [05:32<1:00:50, 23.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  7%|▋         | 12/164 [05:56<1:01:16, 24.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  8%|▊         | 13/164 [06:14<55:26, 22.03s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  9%|▊         | 14/164 [06:40<58:05, 23.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  9%|▉         | 15/164 [06:57<53:00, 21.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 10%|▉         | 16/164 [07:22<55:40, 22.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 17/164 [07:53<1:01:48, 25.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 11%|█         | 18/164 [08:34<1:12:55, 29.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 12%|█▏        | 19/164 [09:09<1:15:31, 31.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 12%|█▏        | 20/164 [09:47<1:20:23, 33.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 13%|█▎        | 21/164 [10:25<1:22:38, 34.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 13%|█▎        | 22/164 [11:01<1:23:21, 35.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 14%|█▍        | 23/164 [11:52<1:33:34, 39.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 15%|█▍        | 24/164 [12:27<1:30:00, 38.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 15%|█▌        | 25/164 [12:45<1:14:52, 32.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 16%|█▌        | 26/164 [12:59<1:01:38, 26.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 16%|█▋        | 27/164 [13:13<52:26, 22.97s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 17%|█▋        | 28/164 [13:30<48:00, 21.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 18%|█▊        | 29/164 [14:20<1:06:51, 29.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 18%|█▊        | 30/164 [15:15<1:23:41, 37.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 19%|█▉        | 31/164 [16:02<1:29:26, 40.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|█▉        | 32/164 [17:03<1:42:17, 46.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 33/164 [17:39<1:34:40, 43.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 21%|██        | 34/164 [18:17<1:30:26, 41.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 21%|██▏       | 35/164 [18:53<1:25:41, 39.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 22%|██▏       | 36/164 [19:26<1:20:58, 37.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 23%|██▎       | 37/164 [20:04<1:20:28, 38.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 23%|██▎       | 38/164 [20:37<1:16:42, 36.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 24%|██▍       | 39/164 [21:16<1:17:24, 37.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 24%|██▍       | 40/164 [21:48<1:13:18, 35.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 25%|██▌       | 41/164 [22:47<1:27:26, 42.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 26%|██▌       | 42/164 [23:30<1:26:46, 42.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 26%|██▌       | 43/164 [24:06<1:22:09, 40.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 27%|██▋       | 44/164 [24:57<1:27:39, 43.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 27%|██▋       | 45/164 [25:42<1:27:39, 44.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 28%|██▊       | 46/164 [26:24<1:25:21, 43.40s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 29%|██▊       | 47/164 [26:55<1:17:39, 39.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 29%|██▉       | 48/164 [27:24<1:10:29, 36.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 30%|██▉       | 49/164 [27:38<57:05, 29.79s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 50/164 [27:52<47:26, 24.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 31%|███       | 51/164 [28:06<40:46, 21.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 32%|███▏      | 52/164 [28:20<36:23, 19.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 32%|███▏      | 53/164 [28:38<35:11, 19.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 54/164 [28:58<35:17, 19.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 34%|███▎      | 55/164 [29:19<35:55, 19.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 34%|███▍      | 56/164 [29:36<34:28, 19.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 35%|███▍      | 57/164 [30:00<36:15, 20.33s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 35%|███▌      | 58/164 [30:17<34:17, 19.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 36%|███▌      | 59/164 [30:40<36:03, 20.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 37%|███▋      | 60/164 [30:59<34:55, 20.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 37%|███▋      | 61/164 [31:29<39:34, 23.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 38%|███▊      | 62/164 [31:57<41:43, 24.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 38%|███▊      | 63/164 [32:27<43:50, 26.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 39%|███▉      | 64/164 [33:10<52:01, 31.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|███▉      | 65/164 [33:54<57:38, 34.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 66/164 [34:26<55:48, 34.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 41%|████      | 67/164 [35:10<1:00:15, 37.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 41%|████▏     | 68/164 [35:44<57:59, 36.24s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 42%|████▏     | 69/164 [36:30<1:01:45, 39.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 43%|████▎     | 70/164 [37:24<1:08:11, 43.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 43%|████▎     | 71/164 [38:06<1:07:00, 43.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 44%|████▍     | 72/164 [38:45<1:04:12, 41.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 45%|████▍     | 73/164 [39:01<51:35, 34.02s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 45%|████▌     | 74/164 [39:17<43:07, 28.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 46%|████▌     | 75/164 [39:37<38:36, 26.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 46%|████▋     | 76/164 [39:57<35:28, 24.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 47%|████▋     | 77/164 [40:15<32:18, 22.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 48%|████▊     | 78/164 [40:39<32:48, 22.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 48%|████▊     | 79/164 [40:56<30:04, 21.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 49%|████▉     | 80/164 [41:22<31:32, 22.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 49%|████▉     | 81/164 [42:03<38:46, 28.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 82/164 [42:36<40:32, 29.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 51%|█████     | 83/164 [43:17<44:43, 33.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 51%|█████     | 84/164 [44:02<48:37, 36.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 52%|█████▏    | 85/164 [44:31<45:20, 34.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 52%|█████▏    | 86/164 [45:06<44:59, 34.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 53%|█████▎    | 87/164 [45:39<43:50, 34.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 54%|█████▎    | 88/164 [46:04<39:37, 31.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 54%|█████▍    | 89/164 [46:41<41:10, 32.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 55%|█████▍    | 90/164 [47:08<38:20, 31.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 55%|█████▌    | 91/164 [47:35<36:36, 30.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 56%|█████▌    | 92/164 [48:10<37:38, 31.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 57%|█████▋    | 93/164 [48:24<31:05, 26.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 57%|█████▋    | 94/164 [48:39<26:36, 22.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 58%|█████▊    | 95/164 [48:57<24:46, 21.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 59%|█████▊    | 96/164 [49:17<23:46, 20.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 59%|█████▉    | 97/164 [49:49<26:57, 24.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|█████▉    | 98/164 [50:15<27:24, 24.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 99/164 [50:44<28:09, 25.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 61%|██████    | 100/164 [51:12<28:29, 26.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 62%|██████▏   | 101/164 [51:48<30:46, 29.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 62%|██████▏   | 102/164 [52:12<28:43, 27.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 63%|██████▎   | 103/164 [52:45<29:55, 29.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 63%|██████▎   | 104/164 [53:13<29:02, 29.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 64%|██████▍   | 105/164 [53:55<32:19, 32.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 65%|██████▍   | 106/164 [54:43<36:00, 37.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 65%|██████▌   | 107/164 [55:10<32:41, 34.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 66%|██████▌   | 108/164 [55:39<30:28, 32.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 66%|██████▋   | 109/164 [56:24<33:26, 36.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 110/164 [57:10<35:25, 39.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 68%|██████▊   | 111/164 [58:00<37:30, 42.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 68%|██████▊   | 112/164 [58:46<37:34, 43.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 69%|██████▉   | 113/164 [59:33<37:52, 44.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 70%|██████▉   | 114/164 [1:00:19<37:33, 45.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 70%|███████   | 115/164 [1:01:08<37:49, 46.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 71%|███████   | 116/164 [1:01:52<36:20, 45.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 71%|███████▏  | 117/164 [1:02:17<30:56, 39.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 72%|███████▏  | 118/164 [1:02:45<27:26, 35.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 73%|███████▎  | 119/164 [1:03:07<23:45, 31.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 73%|███████▎  | 120/164 [1:03:27<20:45, 28.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 74%|███████▍  | 121/164 [1:03:44<17:51, 24.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 74%|███████▍  | 122/164 [1:04:00<15:38, 22.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 75%|███████▌  | 123/164 [1:04:21<14:49, 21.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 76%|███████▌  | 124/164 [1:04:50<16:02, 24.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 76%|███████▌  | 125/164 [1:05:08<14:24, 22.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 77%|███████▋  | 126/164 [1:05:21<12:13, 19.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 77%|███████▋  | 127/164 [1:05:43<12:27, 20.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 78%|███████▊  | 128/164 [1:06:05<12:26, 20.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 79%|███████▊  | 129/164 [1:06:22<11:32, 19.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 79%|███████▉  | 130/164 [1:06:29<08:53, 15.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 80%|███████▉  | 131/164 [1:06:35<07:05, 12.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 132/164 [1:06:47<06:43, 12.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 81%|████████  | 133/164 [1:07:08<07:53, 15.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 82%|████████▏ | 134/164 [1:07:38<09:49, 19.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 82%|████████▏ | 135/164 [1:08:08<10:56, 22.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 83%|████████▎ | 136/164 [1:08:33<10:55, 23.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 84%|████████▎ | 137/164 [1:08:59<10:52, 24.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 84%|████████▍ | 138/164 [1:09:31<11:27, 26.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 85%|████████▍ | 139/164 [1:09:58<11:08, 26.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 85%|████████▌ | 140/164 [1:10:28<11:07, 27.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 86%|████████▌ | 141/164 [1:11:00<11:06, 28.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 87%|████████▋ | 142/164 [1:11:28<10:27, 28.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 87%|████████▋ | 143/164 [1:11:56<09:55, 28.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 88%|████████▊ | 144/164 [1:12:30<10:00, 30.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 88%|████████▊ | 145/164 [1:12:51<08:40, 27.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 89%|████████▉ | 146/164 [1:13:12<07:41, 25.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 90%|████████▉ | 147/164 [1:13:32<06:44, 23.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 90%|█████████ | 148/164 [1:13:50<05:55, 22.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 91%|█████████ | 149/164 [1:14:43<07:50, 31.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 91%|█████████▏| 150/164 [1:15:43<09:18, 39.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 92%|█████████▏| 151/164 [1:16:28<08:59, 41.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 93%|█████████▎| 152/164 [1:17:10<08:20, 41.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 93%|█████████▎| 153/164 [1:17:47<07:22, 40.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 94%|█████████▍| 154/164 [1:18:29<06:47, 40.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 95%|█████████▍| 155/164 [1:19:09<06:04, 40.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 95%|█████████▌| 156/164 [1:19:50<05:24, 40.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 96%|█████████▌| 157/164 [1:20:27<04:36, 39.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 96%|█████████▋| 158/164 [1:20:44<03:17, 32.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 97%|█████████▋| 159/164 [1:21:15<02:41, 32.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 98%|█████████▊| 160/164 [1:21:36<01:55, 28.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 98%|█████████▊| 161/164 [1:21:57<01:19, 26.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 99%|█████████▉| 162/164 [1:22:15<00:47, 23.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 99%|█████████▉| 163/164 [1:22:34<00:22, 22.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 164/164 [1:22:52<00:00, 30.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X,Y: 1228,998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pydicom\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from skimage.exposure import rescale_intensity\n",
        "import nibabel as nib\n",
        "from tqdm import tqdm\n",
        "import gc\n",
        "from typing import List\n",
        "import random\n",
        "\n",
        "def load_dicom_volume(dicom_file):\n",
        "    ds = pydicom.dcmread(dicom_file)\n",
        "    volume = ds.pixel_array\n",
        "    volume = rescale_intensity(volume, out_range=(0, 255)).astype(np.uint8)\n",
        "    return volume\n",
        "\n",
        "def get_patient_and_study_id(dicom_file_path):\n",
        "    \"\"\"\n",
        "    Extract Patient ID and Study ID from a DICOM file.\n",
        "\n",
        "    Parameters:\n",
        "    - dicom_file_path: Path to the DICOM file.\n",
        "\n",
        "    Returns:\n",
        "    - patient_id: The Patient ID extracted from the DICOM file.\n",
        "    - study_uid: The Study ID extracted from the DICOM file.\n",
        "    \"\"\"\n",
        "    ds = pydicom.dcmread(dicom_file_path)\n",
        "    patient_id = ds.PatientID\n",
        "    study_uid = ds.StudyInstanceUID\n",
        "    view = ds.ViewPosition\n",
        "    return patient_id, study_uid, view\n",
        "\n",
        "def collect_dicom_files(root_dir: str) -> List[str]:\n",
        "    \"\"\"Collect all DICOM file paths from the directory structure.\"\"\"\n",
        "    dicom_files = []\n",
        "    for subdir, _, files in os.walk(root_dir):\n",
        "        for file in files:\n",
        "            if file.lower().endswith('.dcm'):\n",
        "                dicom_files.append(os.path.join(subdir, file))\n",
        "    return dicom_files\n",
        "\n",
        "def save_slices_based_on_csv(csv_path, dicom_files, save_dir):\n",
        "    # Load the CSV file\n",
        "    csv_data = pd.read_csv(csv_path)\n",
        "\n",
        "    # Create a DataFrame to save metadata\n",
        "    df = pd.DataFrame(columns=['PatientID', 'StudyUID', 'view', 'img_path', 'Normal', 'Actionable', 'Benign', 'Cancer'])\n",
        "\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    for dicom_file in tqdm(dicom_files):\n",
        "          patient_id, study_uid, view = get_patient_and_study_id(dicom_file)\n",
        "          volume = load_dicom_volume(dicom_file)\n",
        "          #view = row['View']\n",
        "          # Middle of the image for X and Y\n",
        "          y = int(volume.shape[1] / 2)\n",
        "          x = int(volume.shape[2] / 2)\n",
        "          print(f\"Shape X,Y: {y},{x}\")\n",
        "          width = random.randint(200, 250)\n",
        "          height = random.randint(200, 250)\n",
        "          slice_idx = random.randint(15, 35)\n",
        "\n",
        "          # Ensure the slice index is within bounds\n",
        "          if 0 <= slice_idx-15 < volume.shape[0]:\n",
        "            slice_volume = volume[slice_idx-10:slice_idx+10,y-height:y+height ,x-width:x+width]\n",
        "            slice_name = f\"{patient_id}_{study_uid}_{view}_slice_{slice_idx}.nii.gz\"\n",
        "            slice_nifti = nib.Nifti1Image(slice_volume, np.eye(4))\n",
        "            nib.save(slice_nifti, os.path.join(save_dir, slice_name))\n",
        "\n",
        "# Define paths\n",
        "csv_path = '/content/drive/MyDrive/Praktikum/boxes.csv'\n",
        "dicom_dir = '/content/dataset/Breast-Cancer-Screening-DBT/normal/'\n",
        "save_dir = '/content/3d_slices_nii_3D_20P_normal/'\n",
        "\n",
        "# Collect all DICOM file paths\n",
        "dicom_files = collect_dicom_files(dicom_dir)\n",
        "print(f\"Found {len(dicom_files)} DICOM files.\")\n",
        "print(dicom_files[0])\n",
        "\n",
        "# Process the DICOM files based on the CSV data\n",
        "save_slices_based_on_csv(csv_path, dicom_files, save_dir)\n",
        "\n",
        "# Copy the saved slices to Google Drive\n",
        "!cp -r /content/3d_slices_nii_3D_20P_normal/ /content/drive/MyDrive/Praktikum/3d_dataset_slices_fcsv2_20P_normal/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQeb1Zmf0Gsf"
      },
      "source": [
        "#Dataset Filter - Clear from blank data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nCYvs_Qi0N9c"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def filter_and_delete_files_by_size(directory, max_size_kb):\n",
        "    # Convert max_size_kb to bytes\n",
        "    max_size_bytes = max_size_kb * 1024\n",
        "\n",
        "    # List to hold files less than max_size_kb\n",
        "    small_files = []\n",
        "\n",
        "    # Iterate over all files in the directory\n",
        "    for filename in os.listdir(directory):\n",
        "        filepath = os.path.join(directory, filename)\n",
        "        if os.path.isfile(filepath):\n",
        "            # Get file size\n",
        "            file_size = os.path.getsize(filepath)\n",
        "            # Check if file size is less than max_size_bytes\n",
        "            if file_size < max_size_bytes:\n",
        "                small_files.append((filename, file_size))\n",
        "\n",
        "    # Print all files and their sizes\n",
        "    print(\"All files and their sizes:\")\n",
        "    for filename in os.listdir(directory):\n",
        "        filepath = os.path.join(directory, filename)\n",
        "        if os.path.isfile(filepath):\n",
        "            file_size = os.path.getsize(filepath)\n",
        "            print(f\"{filename}: {file_size / 1024:.2f} KB\")\n",
        "\n",
        "    # Delete files smaller than max_size_kb\n",
        "    for file, size in small_files:\n",
        "        os.remove(os.path.join(directory, file))\n",
        "        print(f\"Deleted {file}: {size / 1024:.2f} KB\")\n",
        "\n",
        "# Example usage\n",
        "directory = '/content/drive/MyDrive/Praktikum/3d_dataset_slices_fcsv2_20P/'  # Replace with your directory path\n",
        "max_size_kb = 76\n",
        "filter_and_delete_files_by_size(directory, max_size_kb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FxjVzlQBAqK"
      },
      "source": [
        "#Getting Same Patient IDs for 3D Patches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcUea6ZDBFOT",
        "outputId": "4f47b69d-f556-416a-a4c1-4080bf5f8c7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collected files from 2 directories.\n",
            "Found 35 common patient IDs.\n",
            "Files copied to new datasets based on common patient IDs.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "from typing import List, Dict, Set\n",
        "from collections import defaultdict\n",
        "\n",
        "def collect_files_in_directories(directories: List[str]) -> Dict[str, List[str]]:\n",
        "    \"\"\"Collect files in each directory and map them to the directory.\"\"\"\n",
        "    dir_files = {}\n",
        "    for directory in directories:\n",
        "        files = []\n",
        "        for subdir, _, file_list in os.walk(directory):\n",
        "            for file in file_list:\n",
        "                files.append(os.path.join(subdir, file))\n",
        "        dir_files[directory] = files\n",
        "    return dir_files\n",
        "\n",
        "def extract_patient_id(file_path: str) -> str:\n",
        "    \"\"\"Extract patient ID from the file path assuming it is part of the filename.\"\"\"\n",
        "    return os.path.basename(file_path).split('_')[0]\n",
        "\n",
        "def find_common_patient_ids(dir_files: Dict[str, List[str]]) -> Set[str]:\n",
        "    \"\"\"Find common patient IDs across all directories.\"\"\"\n",
        "    patient_ids_sets = []\n",
        "    for files in dir_files.values():\n",
        "        patient_ids = {extract_patient_id(file) for file in files}\n",
        "        patient_ids_sets.append(patient_ids)\n",
        "    common_patient_ids = set.intersection(*patient_ids_sets)\n",
        "    return common_patient_ids\n",
        "\n",
        "def copy_files_to_new_datasets(dir_files: Dict[str, List[str]], common_patient_ids: Set[str], output_dirs: List[str]):\n",
        "    \"\"\"Copy files to new dataset directories based on common patient IDs.\"\"\"\n",
        "    for directory, files in dir_files.items():\n",
        "        for patient_id in common_patient_ids:\n",
        "            patient_files = [file for file in files if extract_patient_id(file) == patient_id]\n",
        "            for output_dir in output_dirs:\n",
        "                if not os.path.exists(output_dir):\n",
        "                    os.makedirs(output_dir)\n",
        "                for file in patient_files:\n",
        "                    shutil.copy(file, output_dir)\n",
        "\n",
        "# Define root directories containing the files\n",
        "root_dirs = [\n",
        "    '/content/drive/MyDrive/Praktikum/3d_dataset_slices_fcsv2_20P_normal/',\n",
        "    '/content/drive/MyDrive/Praktikum/3d_dataset_slices_fcsv2_30P_normal/'\n",
        "    # Add more folders as needed\n",
        "]\n",
        "\n",
        "# Define output directories where files will be copied\n",
        "output_dirs = [\n",
        "    '/content/3d_dataset_slices_fcsv2_20P_common_normal/',\n",
        "    '/content/3d_dataset_slices_fcsv2_30P_common_normal/'\n",
        "]\n",
        "\n",
        "# Collect files in each directory\n",
        "dir_files = collect_files_in_directories(root_dirs)\n",
        "print(f\"Collected files from {len(dir_files)} directories.\")\n",
        "\n",
        "# Find common patient IDs across directories\n",
        "common_patient_ids = find_common_patient_ids(dir_files)\n",
        "print(f\"Found {len(common_patient_ids)} common patient IDs.\")\n",
        "\n",
        "# Copy files to new datasets based on common patient IDs\n",
        "copy_files_to_new_datasets(dir_files, common_patient_ids, output_dirs)\n",
        "print(\"Files copied to new datasets based on common patient IDs.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3H7IxS0QeSX",
        "outputId": "3ce226f3-a903-422c-98b8-bdbd48a09183"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    302     302   28840\n",
            "    302     302   28840\n"
          ]
        }
      ],
      "source": [
        "!ls 3d_dataset_slices_fcsv2_20P_common_normal/|wc\n",
        "!ls 3d_dataset_slices_fcsv2_30P_common_normal/|wc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bR1imBGD0O9Z"
      },
      "source": [
        "#Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84zCmv7u0Rlp"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import monai\n",
        "from monai.data import ImageDataset, DataLoader\n",
        "from monai.transforms import EnsureChannelFirst, Compose, RandRotate90, Resize, ScaleIntensity, RepeatChannel\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, recall_score, roc_auc_score, f1_score, roc_curve, confusion_matrix, matthews_corrcoef\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision.models.video import r3d_18\n",
        "\n",
        "def load_image_paths_and_labels(data_dir, labels_csv):\n",
        "    \"\"\"\n",
        "    Load image paths and corresponding labels from the directory and CSV file.\n",
        "\n",
        "    Args:\n",
        "    - data_dir (str): Directory containing the image files.\n",
        "    - labels_csv (str): Path to the CSV file containing labels.\n",
        "\n",
        "    Returns:\n",
        "    - image_paths (List[str]): List of image file paths.\n",
        "    - labels (List[int]): List of labels corresponding to the image file paths.\n",
        "    \"\"\"\n",
        "    # Read labels CSV\n",
        "    labels_df = pd.read_csv(labels_csv)\n",
        "\n",
        "    image_paths = []\n",
        "    labels = []\n",
        "\n",
        "    for _, row in labels_df.iterrows():\n",
        "        patient_id = row['PatientID']\n",
        "        label = row['Cancer']\n",
        "        # Find all image files for the patient\n",
        "        patient_images = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.startswith(patient_id)]\n",
        "        image_paths.extend(patient_images)\n",
        "        labels.extend([label] * len(patient_images))\n",
        "\n",
        "    return image_paths, labels\n",
        "\n",
        "def plot_and_save_metrics(epochs, train_metrics, val_metrics, metric_name, save_path):\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, train_metrics, label=f'Train {metric_name}')\n",
        "    plt.plot(epochs, val_metrics, label=f'Validation {metric_name}')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel(metric_name)\n",
        "    plt.legend()\n",
        "    plt.title(f'Train and Validation {metric_name}')\n",
        "    plt.savefig(os.path.join(save_path, f'{metric_name}.png'))\n",
        "\n",
        "class ResNeXt3D(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super(ResNeXt3D, self).__init__()\n",
        "        self.model = r3d_18(pretrained=True)\n",
        "        self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "def main():\n",
        "    monai.config.print_config()\n",
        "    logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
        "\n",
        "    # Define data paths\n",
        "    data_dir = '/content/drive/MyDrive/Praktikum/filtered_512_20P/'  # Directory containing the image files\n",
        "    labels_csv = '/content/drive/MyDrive/Praktikum/labels.csv'  # Path to the CSV file containing labels\n",
        "\n",
        "    # Number of epochs\n",
        "    num_epochs = 50  # Change this value to set the number of epochs\n",
        "\n",
        "    # Load image paths and labels\n",
        "    images, labels = load_image_paths_and_labels(data_dir, labels_csv)\n",
        "    labels = np.array(labels, dtype=np.int64)\n",
        "\n",
        "    # Debugging: Print number of images and labels\n",
        "    print(f\"Number of images: {len(images)}, Number of labels: {len(labels)}\")\n",
        "    print(f\"Labels distribution: {np.bincount(labels)}\")\n",
        "\n",
        "    # Define transforms\n",
        "    train_transforms = Compose([ScaleIntensity(), EnsureChannelFirst(), RepeatChannel(repeats=3), Resize((96, 96, 96)), RandRotate90()])\n",
        "    val_transforms = Compose([ScaleIntensity(), EnsureChannelFirst(), RepeatChannel(repeats=3), Resize((96, 96, 96))])\n",
        "\n",
        "    # Split dataset into training and validation sets\n",
        "    train_images, val_images, train_labels, val_labels = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Debugging: Print train and validation label distributions\n",
        "    print(f\"Train labels distribution: {np.bincount(train_labels)}\")\n",
        "    print(f\"Validation labels distribution: {np.bincount(val_labels)}\")\n",
        "\n",
        "    # Create datasets and dataloaders\n",
        "    train_ds = ImageDataset(image_files=train_images, labels=train_labels, transform=train_transforms)\n",
        "    val_ds = ImageDataset(image_files=val_images, labels=val_labels, transform=val_transforms)\n",
        "\n",
        "    train_loader = DataLoader(train_ds, batch_size=2, shuffle=True, num_workers=2, pin_memory=torch.cuda.is_available())\n",
        "    val_loader = DataLoader(val_ds, batch_size=2, num_workers=2, pin_memory=torch.cuda.is_available())\n",
        "\n",
        "    # Create ResNeXt50 3D, CrossEntropyLoss and Adam optimizer\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = ResNeXt3D(num_classes=2).to(device)\n",
        "    loss_function = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), 1e-5)\n",
        "\n",
        "    val_interval = 2\n",
        "    best_metric = -1\n",
        "    best_metric_epoch = -1\n",
        "    epoch_loss_values = list()\n",
        "    epoch_accuracy_values = list()\n",
        "    epoch_recall_values = list()\n",
        "    epoch_auc_values = list()\n",
        "    epoch_f1_values = list()\n",
        "    epoch_mcc_values = list()\n",
        "    writer = SummaryWriter()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(\"-\" * 10)\n",
        "        print(f\"epoch {epoch + 1}/{num_epochs}\")\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        step = 0\n",
        "        for batch_data in train_loader:\n",
        "            step += 1\n",
        "            inputs, labels = batch_data[0].to(device), batch_data[1].to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_function(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_len = len(train_ds) // train_loader.batch_size\n",
        "            print(f\"{step}/{epoch_len}, train_loss: {loss.item():.4f}\")\n",
        "            writer.add_scalar(\"train_loss\", loss.item(), epoch_len * epoch + step)\n",
        "        epoch_loss /= step\n",
        "        epoch_loss_values.append(epoch_loss)\n",
        "        print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
        "\n",
        "        if (epoch + 1) % val_interval == 0:\n",
        "            model.eval()\n",
        "            val_preds = []\n",
        "            val_true = []\n",
        "            with torch.no_grad():\n",
        "                num_correct = 0.0\n",
        "                metric_count = 0\n",
        "                for val_data in val_loader:\n",
        "                    val_images, val_labels = val_data[0].to(device), val_data[1].to(device)\n",
        "                    val_outputs = model(val_images)\n",
        "                    val_preds.extend(val_outputs.argmax(dim=1).cpu().numpy())\n",
        "                    val_true.extend(val_labels.cpu().numpy())\n",
        "                    value = torch.eq(val_outputs.argmax(dim=1), val_labels)\n",
        "                    metric_count += len(value)\n",
        "                    num_correct += value.sum().item()\n",
        "            accuracy = accuracy_score(val_true, val_preds)\n",
        "            recall = recall_score(val_true, val_preds)\n",
        "            auc = roc_auc_score(val_true, val_preds)\n",
        "            f1 = f1_score(val_true, val_preds)\n",
        "            mcc = matthews_corrcoef(val_true, val_preds)\n",
        "\n",
        "            epoch_accuracy_values.append(accuracy)\n",
        "            epoch_recall_values.append(recall)\n",
        "            epoch_auc_values.append(auc)\n",
        "            epoch_f1_values.append(f1)\n",
        "            epoch_mcc_values.append(mcc)\n",
        "\n",
        "            if accuracy > best_metric:\n",
        "                best_metric = accuracy\n",
        "                best_metric_epoch = epoch + 1\n",
        "                torch.save(model.state_dict(), \"best_metric_model_classification3d_5E_RNext50_3D_512_20P.pth\")\n",
        "                print(\"saved new best metric model\")\n",
        "            print(\n",
        "                f\"current epoch: {epoch + 1} current accuracy: {accuracy:.4f} best accuracy: {best_metric:.4f} at epoch {best_metric_epoch}\"\n",
        "            )\n",
        "            writer.add_scalar(\"val_accuracy\", accuracy, epoch + 1)\n",
        "\n",
        "    # Save metrics as PNG\n",
        "    epochs = list(range(1, num_epochs + 1))\n",
        "    metrics = {\n",
        "        'accuracy': epoch_accuracy_values,\n",
        "        'recall': epoch_recall_values,\n",
        "        'auc': epoch_auc_values,\n",
        "        'f1': epoch_f1_values,\n",
        "        'mcc': epoch_mcc_values\n",
        "    }\n",
        "    for metric_name, metric_values in metrics.items():\n",
        "        plot_and_save_metrics(epochs[:len(metric_values)], epoch_loss_values[:len(metric_values)], metric_values, metric_name, '/content/')\n",
        "\n",
        "    print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")\n",
        "    writer.close()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhCV3lZmewRl"
      },
      "source": [
        "#Training - 2 Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "D6GYOm4he2ir",
        "outputId": "f8f10568-5333-4c8b-bb6a-0704a3234e70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MONAI version: 1.3.2\n",
            "Numpy version: 1.25.2\n",
            "Pytorch version: 2.3.0+cu121\n",
            "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
            "MONAI rev id: 59a7211070538586369afd4a01eca0a7fe2e742e\n",
            "MONAI __file__: /usr/local/lib/python3.10/dist-packages/monai/__init__.py\n",
            "\n",
            "Optional dependencies:\n",
            "Pytorch Ignite version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "ITK version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "Nibabel version: 4.0.2\n",
            "scikit-image version: 0.19.3\n",
            "scipy version: 1.11.4\n",
            "Pillow version: 9.4.0\n",
            "Tensorboard version: 2.15.2\n",
            "gdown version: 4.7.3\n",
            "TorchVision version: 0.18.0+cu121\n",
            "tqdm version: 4.66.4\n",
            "lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "psutil version: 5.9.5\n",
            "pandas version: 2.0.3\n",
            "einops version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "transformers version: 4.41.2\n",
            "mlflow version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "pynrrd version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "clearml version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "\n",
            "For details about installing the optional dependencies, please visit:\n",
            "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
            "\n",
            "Number of images: 465, Number of labels: 465\n",
            "Labels distribution: [302 163]\n",
            "Train labels distribution: [241 131]\n",
            "Validation labels distribution: [61 32]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=R3D_18_Weights.KINETICS400_V1`. You can also use `weights=R3D_18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------\n",
            "epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/186, train_loss: 0.3949\n",
            "2/186, train_loss: 0.8422\n",
            "3/186, train_loss: 1.0566\n",
            "4/186, train_loss: 1.1601\n",
            "5/186, train_loss: 0.7442\n",
            "6/186, train_loss: 1.1315\n",
            "7/186, train_loss: 0.4027\n",
            "8/186, train_loss: 0.3870\n",
            "9/186, train_loss: 0.4036\n",
            "10/186, train_loss: 0.3946\n",
            "11/186, train_loss: 0.9015\n",
            "12/186, train_loss: 0.3869\n",
            "13/186, train_loss: 0.6575\n",
            "14/186, train_loss: 0.4011\n",
            "15/186, train_loss: 0.6464\n",
            "16/186, train_loss: 0.3818\n",
            "17/186, train_loss: 0.3858\n",
            "18/186, train_loss: 1.2459\n",
            "19/186, train_loss: 0.6205\n",
            "20/186, train_loss: 0.4024\n",
            "21/186, train_loss: 0.4503\n",
            "22/186, train_loss: 0.6527\n",
            "23/186, train_loss: 0.3723\n",
            "24/186, train_loss: 0.3717\n",
            "25/186, train_loss: 0.4022\n",
            "26/186, train_loss: 0.3967\n",
            "27/186, train_loss: 0.4012\n",
            "28/186, train_loss: 0.6186\n",
            "29/186, train_loss: 0.7610\n",
            "30/186, train_loss: 0.4240\n",
            "31/186, train_loss: 0.6950\n",
            "32/186, train_loss: 0.4325\n",
            "33/186, train_loss: 0.4038\n",
            "34/186, train_loss: 0.6091\n",
            "35/186, train_loss: 0.4119\n",
            "36/186, train_loss: 0.3890\n",
            "37/186, train_loss: 1.2761\n",
            "38/186, train_loss: 0.5893\n",
            "39/186, train_loss: 0.3799\n",
            "40/186, train_loss: 1.2083\n",
            "41/186, train_loss: 0.3878\n",
            "42/186, train_loss: 0.3831\n",
            "43/186, train_loss: 0.4948\n",
            "44/186, train_loss: 1.1371\n",
            "45/186, train_loss: 0.3177\n",
            "46/186, train_loss: 0.3913\n",
            "47/186, train_loss: 1.1479\n",
            "48/186, train_loss: 0.3810\n",
            "49/186, train_loss: 0.7438\n",
            "50/186, train_loss: 0.9522\n",
            "51/186, train_loss: 0.3825\n",
            "52/186, train_loss: 0.8294\n",
            "53/186, train_loss: 0.4132\n",
            "54/186, train_loss: 0.4580\n",
            "55/186, train_loss: 0.4483\n",
            "56/186, train_loss: 1.1765\n",
            "57/186, train_loss: 0.3858\n",
            "58/186, train_loss: 0.2556\n",
            "59/186, train_loss: 0.4452\n",
            "60/186, train_loss: 0.3948\n",
            "61/186, train_loss: 0.3891\n",
            "62/186, train_loss: 0.5205\n",
            "63/186, train_loss: 0.2176\n",
            "64/186, train_loss: 0.3879\n",
            "65/186, train_loss: 0.7855\n",
            "66/186, train_loss: 0.1604\n",
            "67/186, train_loss: 0.2873\n",
            "68/186, train_loss: 0.4051\n",
            "69/186, train_loss: 0.5142\n",
            "70/186, train_loss: 0.4488\n",
            "71/186, train_loss: 1.1653\n",
            "72/186, train_loss: 0.1980\n",
            "73/186, train_loss: 0.4691\n",
            "74/186, train_loss: 0.3834\n",
            "75/186, train_loss: 0.4425\n",
            "76/186, train_loss: 0.3731\n",
            "77/186, train_loss: 0.4124\n",
            "78/186, train_loss: 0.3916\n",
            "79/186, train_loss: 0.7344\n",
            "80/186, train_loss: 0.3513\n",
            "81/186, train_loss: 0.5769\n",
            "82/186, train_loss: 0.3365\n",
            "83/186, train_loss: 0.7522\n",
            "84/186, train_loss: 0.3941\n",
            "85/186, train_loss: 0.3831\n",
            "86/186, train_loss: 1.3305\n",
            "87/186, train_loss: 0.3754\n",
            "88/186, train_loss: 0.9207\n",
            "89/186, train_loss: 1.1695\n",
            "90/186, train_loss: 0.7054\n",
            "91/186, train_loss: 0.3891\n",
            "92/186, train_loss: 0.7628\n",
            "93/186, train_loss: 0.2452\n",
            "94/186, train_loss: 0.1281\n",
            "95/186, train_loss: 1.1431\n",
            "96/186, train_loss: 0.5267\n",
            "97/186, train_loss: 0.6849\n",
            "98/186, train_loss: 0.1264\n",
            "99/186, train_loss: 0.5423\n",
            "100/186, train_loss: 0.6597\n",
            "101/186, train_loss: 0.3765\n",
            "102/186, train_loss: 0.7705\n",
            "103/186, train_loss: 0.2104\n",
            "104/186, train_loss: 0.2445\n",
            "105/186, train_loss: 0.2527\n",
            "106/186, train_loss: 0.4495\n",
            "107/186, train_loss: 0.5786\n",
            "108/186, train_loss: 0.2251\n",
            "109/186, train_loss: 0.3848\n",
            "110/186, train_loss: 0.4018\n",
            "111/186, train_loss: 0.1577\n",
            "112/186, train_loss: 0.2652\n",
            "113/186, train_loss: 0.2793\n",
            "114/186, train_loss: 0.4605\n",
            "115/186, train_loss: 0.2378\n",
            "116/186, train_loss: 0.4123\n",
            "117/186, train_loss: 0.4971\n",
            "118/186, train_loss: 0.5180\n",
            "119/186, train_loss: 0.6311\n",
            "120/186, train_loss: 0.0819\n",
            "121/186, train_loss: 0.2394\n",
            "122/186, train_loss: 0.4435\n",
            "123/186, train_loss: 0.4990\n",
            "124/186, train_loss: 0.4232\n",
            "125/186, train_loss: 0.3794\n",
            "126/186, train_loss: 1.1757\n",
            "127/186, train_loss: 1.1487\n",
            "128/186, train_loss: 0.1236\n",
            "129/186, train_loss: 1.1461\n",
            "130/186, train_loss: 0.3696\n",
            "131/186, train_loss: 1.0138\n",
            "132/186, train_loss: 0.3842\n",
            "133/186, train_loss: 0.4274\n",
            "134/186, train_loss: 0.3904\n",
            "135/186, train_loss: 0.4555\n",
            "136/186, train_loss: 0.4089\n",
            "137/186, train_loss: 0.9097\n",
            "138/186, train_loss: 0.4055\n",
            "139/186, train_loss: 0.4082\n",
            "140/186, train_loss: 0.3869\n",
            "141/186, train_loss: 0.1916\n",
            "142/186, train_loss: 0.4274\n",
            "143/186, train_loss: 0.1865\n",
            "144/186, train_loss: 1.4135\n",
            "145/186, train_loss: 0.4318\n",
            "146/186, train_loss: 0.5899\n",
            "147/186, train_loss: 0.4030\n",
            "148/186, train_loss: 0.0957\n",
            "149/186, train_loss: 0.2827\n",
            "150/186, train_loss: 0.3845\n",
            "151/186, train_loss: 1.1342\n",
            "152/186, train_loss: 1.1632\n",
            "153/186, train_loss: 0.3635\n",
            "154/186, train_loss: 0.7121\n",
            "155/186, train_loss: 0.5933\n",
            "156/186, train_loss: 0.1295\n",
            "157/186, train_loss: 0.5740\n",
            "158/186, train_loss: 0.1874\n",
            "159/186, train_loss: 0.1452\n",
            "160/186, train_loss: 1.4631\n",
            "161/186, train_loss: 1.3177\n",
            "162/186, train_loss: 0.3686\n",
            "163/186, train_loss: 0.4873\n",
            "164/186, train_loss: 0.3965\n",
            "165/186, train_loss: 1.1269\n",
            "166/186, train_loss: 0.6933\n",
            "167/186, train_loss: 1.6065\n",
            "168/186, train_loss: 0.1305\n",
            "169/186, train_loss: 0.4564\n",
            "170/186, train_loss: 0.3817\n",
            "171/186, train_loss: 0.7879\n",
            "172/186, train_loss: 0.1057\n",
            "173/186, train_loss: 0.2527\n",
            "174/186, train_loss: 0.4168\n",
            "175/186, train_loss: 0.4272\n",
            "176/186, train_loss: 0.3717\n",
            "177/186, train_loss: 0.4132\n",
            "178/186, train_loss: 0.7690\n",
            "179/186, train_loss: 0.5562\n",
            "180/186, train_loss: 0.2162\n",
            "181/186, train_loss: 0.1789\n",
            "182/186, train_loss: 0.4250\n",
            "183/186, train_loss: 0.4055\n",
            "184/186, train_loss: 0.2619\n",
            "185/186, train_loss: 0.4870\n",
            "186/186, train_loss: 0.2086\n",
            "epoch 1 average loss: 0.5355\n",
            "----------\n",
            "epoch 2/50\n",
            "1/186, train_loss: 0.1004\n",
            "2/186, train_loss: 0.1613\n",
            "3/186, train_loss: 0.3919\n",
            "4/186, train_loss: 0.3521\n",
            "5/186, train_loss: 0.3806\n",
            "6/186, train_loss: 0.2319\n",
            "7/186, train_loss: 0.7624\n",
            "8/186, train_loss: 0.4161\n",
            "9/186, train_loss: 0.4028\n",
            "10/186, train_loss: 0.2402\n",
            "11/186, train_loss: 0.3484\n",
            "12/186, train_loss: 1.1683\n",
            "13/186, train_loss: 0.1735\n",
            "14/186, train_loss: 0.4533\n",
            "15/186, train_loss: 0.2414\n",
            "16/186, train_loss: 0.3829\n",
            "17/186, train_loss: 1.1714\n",
            "18/186, train_loss: 0.4039\n",
            "19/186, train_loss: 0.0871\n",
            "20/186, train_loss: 0.0841\n",
            "21/186, train_loss: 0.4616\n",
            "22/186, train_loss: 0.1400\n",
            "23/186, train_loss: 0.2225\n",
            "24/186, train_loss: 0.2183\n",
            "25/186, train_loss: 0.4285\n",
            "26/186, train_loss: 0.3282\n",
            "27/186, train_loss: 1.5498\n",
            "28/186, train_loss: 0.4352\n",
            "29/186, train_loss: 0.1171\n",
            "30/186, train_loss: 0.3932\n",
            "31/186, train_loss: 0.2017\n",
            "32/186, train_loss: 0.5561\n",
            "33/186, train_loss: 0.0460\n",
            "34/186, train_loss: 0.0413\n",
            "35/186, train_loss: 0.4318\n",
            "36/186, train_loss: 0.3766\n",
            "37/186, train_loss: 0.3838\n",
            "38/186, train_loss: 0.5914\n",
            "39/186, train_loss: 0.4786\n",
            "40/186, train_loss: 1.4521\n",
            "41/186, train_loss: 0.1701\n",
            "42/186, train_loss: 1.3481\n",
            "43/186, train_loss: 0.3125\n",
            "44/186, train_loss: 0.5797\n",
            "45/186, train_loss: 0.3023\n",
            "46/186, train_loss: 0.3818\n",
            "47/186, train_loss: 0.4385\n",
            "48/186, train_loss: 0.0765\n",
            "49/186, train_loss: 0.0864\n",
            "50/186, train_loss: 0.4687\n",
            "51/186, train_loss: 0.2736\n",
            "52/186, train_loss: 0.5039\n",
            "53/186, train_loss: 0.3560\n",
            "54/186, train_loss: 0.6994\n",
            "55/186, train_loss: 0.3499\n",
            "56/186, train_loss: 0.3836\n",
            "57/186, train_loss: 0.1459\n",
            "58/186, train_loss: 1.1533\n",
            "59/186, train_loss: 0.0888\n",
            "60/186, train_loss: 0.0637\n",
            "61/186, train_loss: 0.4348\n",
            "62/186, train_loss: 0.2866\n",
            "63/186, train_loss: 0.1294\n",
            "64/186, train_loss: 0.4170\n",
            "65/186, train_loss: 0.3053\n",
            "66/186, train_loss: 0.3792\n",
            "67/186, train_loss: 0.3982\n",
            "68/186, train_loss: 0.2121\n",
            "69/186, train_loss: 0.5613\n",
            "70/186, train_loss: 0.2896\n",
            "71/186, train_loss: 0.5008\n",
            "72/186, train_loss: 1.1454\n",
            "73/186, train_loss: 1.3807\n",
            "74/186, train_loss: 0.8872\n",
            "75/186, train_loss: 0.0988\n",
            "76/186, train_loss: 0.8063\n",
            "77/186, train_loss: 0.1444\n",
            "78/186, train_loss: 0.1449\n",
            "79/186, train_loss: 0.4961\n",
            "80/186, train_loss: 0.3601\n",
            "81/186, train_loss: 0.1559\n",
            "82/186, train_loss: 0.2271\n",
            "83/186, train_loss: 0.1924\n",
            "84/186, train_loss: 0.2345\n",
            "85/186, train_loss: 0.2080\n",
            "86/186, train_loss: 0.4140\n",
            "87/186, train_loss: 0.1815\n",
            "88/186, train_loss: 0.1290\n",
            "89/186, train_loss: 0.1181\n",
            "90/186, train_loss: 1.1467\n",
            "91/186, train_loss: 0.3848\n",
            "92/186, train_loss: 0.3536\n",
            "93/186, train_loss: 0.1482\n",
            "94/186, train_loss: 0.1231\n",
            "95/186, train_loss: 0.3642\n",
            "96/186, train_loss: 0.8473\n",
            "97/186, train_loss: 0.5499\n",
            "98/186, train_loss: 0.2039\n",
            "99/186, train_loss: 0.8301\n",
            "100/186, train_loss: 0.2509\n",
            "101/186, train_loss: 0.2837\n",
            "102/186, train_loss: 0.3836\n",
            "103/186, train_loss: 0.3671\n",
            "104/186, train_loss: 0.4195\n",
            "105/186, train_loss: 0.1046\n",
            "106/186, train_loss: 0.0815\n",
            "107/186, train_loss: 0.4462\n",
            "108/186, train_loss: 0.2931\n",
            "109/186, train_loss: 0.1520\n",
            "110/186, train_loss: 0.3465\n",
            "111/186, train_loss: 0.1758\n",
            "112/186, train_loss: 0.1420\n",
            "113/186, train_loss: 0.3677\n",
            "114/186, train_loss: 0.1147\n",
            "115/186, train_loss: 0.3697\n",
            "116/186, train_loss: 0.5217\n",
            "117/186, train_loss: 0.3468\n",
            "118/186, train_loss: 0.4078\n",
            "119/186, train_loss: 0.4982\n",
            "120/186, train_loss: 1.4062\n",
            "121/186, train_loss: 0.4740\n",
            "122/186, train_loss: 1.4856\n",
            "123/186, train_loss: 1.1680\n",
            "124/186, train_loss: 0.5153\n",
            "125/186, train_loss: 0.3568\n",
            "126/186, train_loss: 1.4437\n",
            "127/186, train_loss: 1.7010\n",
            "128/186, train_loss: 0.0449\n",
            "129/186, train_loss: 0.1046\n",
            "130/186, train_loss: 1.3905\n",
            "131/186, train_loss: 0.0719\n",
            "132/186, train_loss: 0.7781\n",
            "133/186, train_loss: 0.3702\n",
            "134/186, train_loss: 0.1087\n",
            "135/186, train_loss: 0.3579\n",
            "136/186, train_loss: 1.0192\n",
            "137/186, train_loss: 0.0393\n",
            "138/186, train_loss: 0.4858\n",
            "139/186, train_loss: 0.5226\n",
            "140/186, train_loss: 0.2469\n",
            "141/186, train_loss: 0.2086\n",
            "142/186, train_loss: 0.4161\n",
            "143/186, train_loss: 0.2022\n",
            "144/186, train_loss: 0.3547\n",
            "145/186, train_loss: 0.3829\n",
            "146/186, train_loss: 0.1744\n",
            "147/186, train_loss: 1.2469\n",
            "148/186, train_loss: 0.2003\n",
            "149/186, train_loss: 0.4615\n",
            "150/186, train_loss: 0.4041\n",
            "151/186, train_loss: 0.1158\n",
            "152/186, train_loss: 0.0669\n",
            "153/186, train_loss: 0.4306\n",
            "154/186, train_loss: 0.0941\n",
            "155/186, train_loss: 1.1292\n",
            "156/186, train_loss: 0.0519\n",
            "157/186, train_loss: 0.3622\n",
            "158/186, train_loss: 0.2380\n",
            "159/186, train_loss: 0.4500\n",
            "160/186, train_loss: 0.0675\n",
            "161/186, train_loss: 0.5348\n",
            "162/186, train_loss: 1.5423\n",
            "163/186, train_loss: 0.4328\n",
            "164/186, train_loss: 0.2483\n",
            "165/186, train_loss: 0.0782\n",
            "166/186, train_loss: 0.4366\n",
            "167/186, train_loss: 0.6485\n",
            "168/186, train_loss: 1.2684\n",
            "169/186, train_loss: 0.3862\n",
            "170/186, train_loss: 0.5941\n",
            "171/186, train_loss: 0.4442\n",
            "172/186, train_loss: 1.1652\n",
            "173/186, train_loss: 1.1171\n",
            "174/186, train_loss: 0.8146\n",
            "175/186, train_loss: 0.4384\n",
            "176/186, train_loss: 1.1842\n",
            "177/186, train_loss: 0.4045\n",
            "178/186, train_loss: 0.3885\n",
            "179/186, train_loss: 0.5383\n",
            "180/186, train_loss: 0.3680\n",
            "181/186, train_loss: 0.0713\n",
            "182/186, train_loss: 0.3672\n",
            "183/186, train_loss: 0.3614\n",
            "184/186, train_loss: 0.3717\n",
            "185/186, train_loss: 0.2052\n",
            "186/186, train_loss: 0.0860\n",
            "epoch 2 average loss: 0.4457\n",
            "saved new best metric model\n",
            "current epoch: 2 current accuracy: 0.7957 best accuracy: 0.7957 at epoch 2\n",
            "----------\n",
            "epoch 3/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/186, train_loss: 0.3823\n",
            "2/186, train_loss: 0.0967\n",
            "3/186, train_loss: 1.1972\n",
            "4/186, train_loss: 0.3662\n",
            "5/186, train_loss: 0.1959\n",
            "6/186, train_loss: 0.2370\n",
            "7/186, train_loss: 0.4371\n",
            "8/186, train_loss: 0.3544\n",
            "9/186, train_loss: 0.3604\n",
            "10/186, train_loss: 0.4106\n",
            "11/186, train_loss: 0.4770\n",
            "12/186, train_loss: 0.3669\n",
            "13/186, train_loss: 0.3913\n",
            "14/186, train_loss: 0.4242\n",
            "15/186, train_loss: 0.1340\n",
            "16/186, train_loss: 0.3368\n",
            "17/186, train_loss: 0.3649\n",
            "18/186, train_loss: 0.3651\n",
            "19/186, train_loss: 0.6975\n",
            "20/186, train_loss: 1.2448\n",
            "21/186, train_loss: 0.8582\n",
            "22/186, train_loss: 1.2289\n",
            "23/186, train_loss: 1.2702\n",
            "24/186, train_loss: 1.2038\n",
            "25/186, train_loss: 0.3502\n",
            "26/186, train_loss: 0.3391\n",
            "27/186, train_loss: 1.7953\n",
            "28/186, train_loss: 0.3252\n",
            "29/186, train_loss: 1.2156\n",
            "30/186, train_loss: 0.4407\n",
            "31/186, train_loss: 0.3515\n",
            "32/186, train_loss: 0.2347\n",
            "33/186, train_loss: 1.1561\n",
            "34/186, train_loss: 0.1340\n",
            "35/186, train_loss: 0.3079\n",
            "36/186, train_loss: 0.3289\n",
            "37/186, train_loss: 0.1793\n",
            "38/186, train_loss: 1.1633\n",
            "39/186, train_loss: 0.2288\n",
            "40/186, train_loss: 0.2964\n",
            "41/186, train_loss: 0.3521\n",
            "42/186, train_loss: 1.3641\n",
            "43/186, train_loss: 0.3718\n",
            "44/186, train_loss: 1.1727\n",
            "45/186, train_loss: 0.3808\n",
            "46/186, train_loss: 0.5776\n",
            "47/186, train_loss: 1.3442\n",
            "48/186, train_loss: 0.1083\n",
            "49/186, train_loss: 1.1771\n",
            "50/186, train_loss: 0.4555\n",
            "51/186, train_loss: 0.3404\n",
            "52/186, train_loss: 0.3305\n",
            "53/186, train_loss: 0.0697\n",
            "54/186, train_loss: 1.1486\n",
            "55/186, train_loss: 0.1712\n",
            "56/186, train_loss: 0.3896\n",
            "57/186, train_loss: 1.6214\n",
            "58/186, train_loss: 1.1804\n",
            "59/186, train_loss: 0.9182\n",
            "60/186, train_loss: 1.1386\n",
            "61/186, train_loss: 0.3620\n",
            "62/186, train_loss: 1.1347\n",
            "63/186, train_loss: 0.2377\n",
            "64/186, train_loss: 0.3517\n",
            "65/186, train_loss: 1.2913\n",
            "66/186, train_loss: 0.2975\n",
            "67/186, train_loss: 0.4907\n",
            "68/186, train_loss: 0.3793\n",
            "69/186, train_loss: 1.0068\n",
            "70/186, train_loss: 0.5501\n",
            "71/186, train_loss: 0.1008\n",
            "72/186, train_loss: 0.3825\n",
            "73/186, train_loss: 0.4368\n",
            "74/186, train_loss: 0.4012\n",
            "75/186, train_loss: 0.8130\n",
            "76/186, train_loss: 0.4166\n",
            "77/186, train_loss: 0.1778\n",
            "78/186, train_loss: 0.2258\n",
            "79/186, train_loss: 0.3507\n",
            "80/186, train_loss: 1.1712\n",
            "81/186, train_loss: 0.0896\n",
            "82/186, train_loss: 0.4497\n",
            "83/186, train_loss: 0.3437\n",
            "84/186, train_loss: 0.3033\n",
            "85/186, train_loss: 0.3178\n",
            "86/186, train_loss: 1.3616\n",
            "87/186, train_loss: 0.3534\n",
            "88/186, train_loss: 0.3914\n",
            "89/186, train_loss: 0.3587\n",
            "90/186, train_loss: 0.4046\n",
            "91/186, train_loss: 0.3954\n",
            "92/186, train_loss: 0.0608\n",
            "93/186, train_loss: 0.2760\n",
            "94/186, train_loss: 0.1904\n",
            "95/186, train_loss: 0.4324\n",
            "96/186, train_loss: 0.2616\n",
            "97/186, train_loss: 0.2808\n",
            "98/186, train_loss: 0.4266\n",
            "99/186, train_loss: 0.1021\n",
            "100/186, train_loss: 0.1527\n",
            "101/186, train_loss: 0.4461\n",
            "102/186, train_loss: 1.2133\n",
            "103/186, train_loss: 1.1651\n",
            "104/186, train_loss: 0.1831\n",
            "105/186, train_loss: 0.3997\n",
            "106/186, train_loss: 0.2239\n",
            "107/186, train_loss: 0.3482\n",
            "108/186, train_loss: 0.0685\n",
            "109/186, train_loss: 0.3612\n",
            "110/186, train_loss: 0.0470\n",
            "111/186, train_loss: 0.3985\n",
            "112/186, train_loss: 0.0518\n",
            "113/186, train_loss: 0.4699\n",
            "114/186, train_loss: 0.6715\n",
            "115/186, train_loss: 1.1242\n",
            "116/186, train_loss: 0.5828\n",
            "117/186, train_loss: 0.0718\n",
            "118/186, train_loss: 0.1337\n",
            "119/186, train_loss: 1.1477\n",
            "120/186, train_loss: 0.3544\n",
            "121/186, train_loss: 0.3646\n",
            "122/186, train_loss: 0.1384\n",
            "123/186, train_loss: 1.1140\n",
            "124/186, train_loss: 0.1247\n",
            "125/186, train_loss: 0.2853\n",
            "126/186, train_loss: 0.3469\n",
            "127/186, train_loss: 1.1509\n",
            "128/186, train_loss: 0.4389\n",
            "129/186, train_loss: 0.2719\n",
            "130/186, train_loss: 0.3867\n",
            "131/186, train_loss: 0.1727\n",
            "132/186, train_loss: 1.1396\n",
            "133/186, train_loss: 0.3881\n",
            "134/186, train_loss: 0.8637\n",
            "135/186, train_loss: 0.3969\n",
            "136/186, train_loss: 0.4805\n",
            "137/186, train_loss: 0.4693\n",
            "138/186, train_loss: 0.4071\n",
            "139/186, train_loss: 0.3548\n",
            "140/186, train_loss: 0.3804\n",
            "141/186, train_loss: 0.3758\n",
            "142/186, train_loss: 0.0730\n",
            "143/186, train_loss: 0.2141\n",
            "144/186, train_loss: 0.0938\n",
            "145/186, train_loss: 0.4222\n",
            "146/186, train_loss: 0.3544\n",
            "147/186, train_loss: 0.3645\n",
            "148/186, train_loss: 0.6305\n",
            "149/186, train_loss: 0.4258\n",
            "150/186, train_loss: 0.3866\n",
            "151/186, train_loss: 0.6965\n",
            "152/186, train_loss: 0.2078\n",
            "153/186, train_loss: 0.3121\n",
            "154/186, train_loss: 0.6157\n",
            "155/186, train_loss: 0.3310\n",
            "156/186, train_loss: 0.3379\n",
            "157/186, train_loss: 0.0861\n",
            "158/186, train_loss: 0.0753\n",
            "159/186, train_loss: 0.3817\n",
            "160/186, train_loss: 0.1732\n",
            "161/186, train_loss: 0.1345\n",
            "162/186, train_loss: 0.3859\n",
            "163/186, train_loss: 0.3252\n",
            "164/186, train_loss: 0.0784\n",
            "165/186, train_loss: 0.8177\n",
            "166/186, train_loss: 0.6206\n",
            "167/186, train_loss: 0.0285\n",
            "168/186, train_loss: 0.2768\n",
            "169/186, train_loss: 0.1896\n",
            "170/186, train_loss: 1.2150\n",
            "171/186, train_loss: 0.5300\n",
            "172/186, train_loss: 0.0839\n",
            "173/186, train_loss: 1.1430\n",
            "174/186, train_loss: 0.7240\n",
            "175/186, train_loss: 2.0821\n",
            "176/186, train_loss: 0.1151\n",
            "177/186, train_loss: 0.6051\n",
            "178/186, train_loss: 0.1218\n",
            "179/186, train_loss: 0.2974\n",
            "180/186, train_loss: 0.5869\n",
            "181/186, train_loss: 1.3933\n",
            "182/186, train_loss: 0.2277\n",
            "183/186, train_loss: 0.0404\n",
            "184/186, train_loss: 0.0746\n",
            "185/186, train_loss: 0.2793\n",
            "186/186, train_loss: 0.5280\n",
            "epoch 3 average loss: 0.5000\n",
            "----------\n",
            "epoch 4/50\n",
            "1/186, train_loss: 0.2153\n",
            "2/186, train_loss: 0.3903\n",
            "3/186, train_loss: 0.0489\n",
            "4/186, train_loss: 0.3291\n",
            "5/186, train_loss: 0.3172\n",
            "6/186, train_loss: 0.3283\n",
            "7/186, train_loss: 0.0973\n",
            "8/186, train_loss: 0.4229\n",
            "9/186, train_loss: 0.3900\n",
            "10/186, train_loss: 0.0901\n",
            "11/186, train_loss: 0.3410\n",
            "12/186, train_loss: 0.3272\n",
            "13/186, train_loss: 0.0956\n",
            "14/186, train_loss: 0.3445\n",
            "15/186, train_loss: 0.6240\n",
            "16/186, train_loss: 0.2604\n",
            "17/186, train_loss: 0.3492\n",
            "18/186, train_loss: 0.3180\n",
            "19/186, train_loss: 1.8570\n",
            "20/186, train_loss: 0.0864\n",
            "21/186, train_loss: 0.4650\n",
            "22/186, train_loss: 0.3924\n",
            "23/186, train_loss: 0.3324\n",
            "24/186, train_loss: 0.3602\n",
            "25/186, train_loss: 0.0716\n",
            "26/186, train_loss: 0.3632\n",
            "27/186, train_loss: 0.2926\n",
            "28/186, train_loss: 0.0617\n",
            "29/186, train_loss: 1.1581\n",
            "30/186, train_loss: 0.0480\n",
            "31/186, train_loss: 0.0640\n",
            "32/186, train_loss: 0.1026\n",
            "33/186, train_loss: 0.4977\n",
            "34/186, train_loss: 0.4059\n",
            "35/186, train_loss: 1.1981\n",
            "36/186, train_loss: 0.3163\n",
            "37/186, train_loss: 0.3296\n",
            "38/186, train_loss: 0.1567\n",
            "39/186, train_loss: 0.1285\n",
            "40/186, train_loss: 1.0552\n",
            "41/186, train_loss: 0.0903\n",
            "42/186, train_loss: 0.4011\n",
            "43/186, train_loss: 0.0404\n",
            "44/186, train_loss: 1.1917\n",
            "45/186, train_loss: 0.4157\n",
            "46/186, train_loss: 0.4297\n",
            "47/186, train_loss: 0.3517\n",
            "48/186, train_loss: 0.1642\n",
            "49/186, train_loss: 0.3636\n",
            "50/186, train_loss: 0.2565\n",
            "51/186, train_loss: 0.0406\n",
            "52/186, train_loss: 0.0352\n",
            "53/186, train_loss: 0.3481\n",
            "54/186, train_loss: 0.0806\n",
            "55/186, train_loss: 0.7491\n",
            "56/186, train_loss: 0.3102\n",
            "57/186, train_loss: 0.3595\n",
            "58/186, train_loss: 1.4194\n",
            "59/186, train_loss: 0.3235\n",
            "60/186, train_loss: 0.3102\n",
            "61/186, train_loss: 0.0714\n",
            "62/186, train_loss: 0.3662\n",
            "63/186, train_loss: 0.9313\n",
            "64/186, train_loss: 0.2963\n",
            "65/186, train_loss: 0.3859\n",
            "66/186, train_loss: 0.3195\n",
            "67/186, train_loss: 0.1707\n",
            "68/186, train_loss: 0.0703\n",
            "69/186, train_loss: 1.2425\n",
            "70/186, train_loss: 0.2990\n",
            "71/186, train_loss: 0.2407\n",
            "72/186, train_loss: 0.0460\n",
            "73/186, train_loss: 0.3543\n",
            "74/186, train_loss: 0.3789\n",
            "75/186, train_loss: 0.4884\n",
            "76/186, train_loss: 0.2472\n",
            "77/186, train_loss: 0.3632\n",
            "78/186, train_loss: 0.4267\n",
            "79/186, train_loss: 0.0660\n",
            "80/186, train_loss: 0.4134\n",
            "81/186, train_loss: 1.2700\n",
            "82/186, train_loss: 0.2286\n",
            "83/186, train_loss: 0.2304\n",
            "84/186, train_loss: 0.3811\n",
            "85/186, train_loss: 0.7702\n",
            "86/186, train_loss: 0.3120\n",
            "87/186, train_loss: 1.4716\n",
            "88/186, train_loss: 0.1096\n",
            "89/186, train_loss: 0.0654\n",
            "90/186, train_loss: 0.1156\n",
            "91/186, train_loss: 0.3169\n",
            "92/186, train_loss: 0.2487\n",
            "93/186, train_loss: 0.4925\n",
            "94/186, train_loss: 0.3052\n",
            "95/186, train_loss: 0.6793\n",
            "96/186, train_loss: 0.1684\n",
            "97/186, train_loss: 1.2130\n",
            "98/186, train_loss: 0.2015\n",
            "99/186, train_loss: 1.2191\n",
            "100/186, train_loss: 1.2038\n",
            "101/186, train_loss: 0.0591\n",
            "102/186, train_loss: 0.1746\n",
            "103/186, train_loss: 0.3649\n",
            "104/186, train_loss: 0.3058\n",
            "105/186, train_loss: 0.0855\n",
            "106/186, train_loss: 1.1863\n",
            "107/186, train_loss: 0.0749\n",
            "108/186, train_loss: 1.3300\n",
            "109/186, train_loss: 0.3369\n",
            "110/186, train_loss: 1.2533\n",
            "111/186, train_loss: 0.1988\n",
            "112/186, train_loss: 0.2445\n",
            "113/186, train_loss: 0.2260\n",
            "114/186, train_loss: 0.1366\n",
            "115/186, train_loss: 0.0529\n",
            "116/186, train_loss: 0.1629\n",
            "117/186, train_loss: 0.3708\n",
            "118/186, train_loss: 0.3719\n",
            "119/186, train_loss: 0.3663\n",
            "120/186, train_loss: 0.2132\n",
            "121/186, train_loss: 0.6255\n",
            "122/186, train_loss: 0.0360\n",
            "123/186, train_loss: 0.9161\n",
            "124/186, train_loss: 0.1578\n",
            "125/186, train_loss: 1.1802\n",
            "126/186, train_loss: 0.8726\n",
            "127/186, train_loss: 0.1383\n",
            "128/186, train_loss: 0.1322\n",
            "129/186, train_loss: 0.3723\n",
            "130/186, train_loss: 0.6835\n",
            "131/186, train_loss: 0.4235\n",
            "132/186, train_loss: 0.0670\n",
            "133/186, train_loss: 1.1839\n",
            "134/186, train_loss: 0.6921\n",
            "135/186, train_loss: 0.1025\n",
            "136/186, train_loss: 0.0680\n",
            "137/186, train_loss: 0.2427\n",
            "138/186, train_loss: 0.1996\n",
            "139/186, train_loss: 0.4322\n",
            "140/186, train_loss: 0.3771\n",
            "141/186, train_loss: 0.4360\n",
            "142/186, train_loss: 0.0482\n",
            "143/186, train_loss: 0.3956\n",
            "144/186, train_loss: 0.1675\n",
            "145/186, train_loss: 0.2049\n",
            "146/186, train_loss: 1.1302\n",
            "147/186, train_loss: 0.2298\n",
            "148/186, train_loss: 0.4533\n",
            "149/186, train_loss: 0.4348\n",
            "150/186, train_loss: 0.4538\n",
            "151/186, train_loss: 0.3481\n",
            "152/186, train_loss: 0.9182\n",
            "153/186, train_loss: 0.1534\n",
            "154/186, train_loss: 1.8201\n",
            "155/186, train_loss: 1.4575\n",
            "156/186, train_loss: 0.0655\n",
            "157/186, train_loss: 0.4583\n",
            "158/186, train_loss: 0.3794\n",
            "159/186, train_loss: 1.3180\n",
            "160/186, train_loss: 0.5424\n",
            "161/186, train_loss: 0.3464\n",
            "162/186, train_loss: 0.3701\n",
            "163/186, train_loss: 0.1399\n",
            "164/186, train_loss: 0.4531\n",
            "165/186, train_loss: 0.3509\n",
            "166/186, train_loss: 0.5763\n",
            "167/186, train_loss: 0.5794\n",
            "168/186, train_loss: 0.1791\n",
            "169/186, train_loss: 0.3205\n",
            "170/186, train_loss: 0.4298\n",
            "171/186, train_loss: 0.3585\n",
            "172/186, train_loss: 0.1387\n",
            "173/186, train_loss: 0.0733\n",
            "174/186, train_loss: 0.3513\n",
            "175/186, train_loss: 1.1606\n",
            "176/186, train_loss: 0.2995\n",
            "177/186, train_loss: 0.1245\n",
            "178/186, train_loss: 0.2697\n",
            "179/186, train_loss: 0.1190\n",
            "180/186, train_loss: 1.1781\n",
            "181/186, train_loss: 0.3524\n",
            "182/186, train_loss: 0.0862\n",
            "183/186, train_loss: 0.3458\n",
            "184/186, train_loss: 0.2900\n",
            "185/186, train_loss: 0.3142\n",
            "186/186, train_loss: 0.9643\n",
            "epoch 4 average loss: 0.4242\n",
            "saved new best metric model\n",
            "current epoch: 4 current accuracy: 0.8172 best accuracy: 0.8172 at epoch 4\n",
            "----------\n",
            "epoch 5/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/186, train_loss: 1.3677\n",
            "2/186, train_loss: 0.3520\n",
            "3/186, train_loss: 0.3128\n",
            "4/186, train_loss: 0.0814\n",
            "5/186, train_loss: 0.3658\n",
            "6/186, train_loss: 0.3527\n",
            "7/186, train_loss: 0.6713\n",
            "8/186, train_loss: 0.1006\n",
            "9/186, train_loss: 0.5354\n",
            "10/186, train_loss: 0.3629\n",
            "11/186, train_loss: 0.4363\n",
            "12/186, train_loss: 0.6864\n",
            "13/186, train_loss: 0.3871\n",
            "14/186, train_loss: 0.3827\n",
            "15/186, train_loss: 0.4027\n",
            "16/186, train_loss: 0.1871\n",
            "17/186, train_loss: 0.1342\n",
            "18/186, train_loss: 0.1798\n",
            "19/186, train_loss: 0.0637\n",
            "20/186, train_loss: 0.3459\n",
            "21/186, train_loss: 0.2480\n",
            "22/186, train_loss: 0.3612\n",
            "23/186, train_loss: 0.3643\n",
            "24/186, train_loss: 0.3440\n",
            "25/186, train_loss: 0.3479\n",
            "26/186, train_loss: 0.2595\n",
            "27/186, train_loss: 0.4071\n",
            "28/186, train_loss: 0.0474\n",
            "29/186, train_loss: 0.6399\n",
            "30/186, train_loss: 0.3672\n",
            "31/186, train_loss: 1.1911\n",
            "32/186, train_loss: 0.3168\n",
            "33/186, train_loss: 0.3119\n",
            "34/186, train_loss: 0.1410\n",
            "35/186, train_loss: 0.3350\n",
            "36/186, train_loss: 0.3053\n",
            "37/186, train_loss: 0.2642\n",
            "38/186, train_loss: 2.3546\n",
            "39/186, train_loss: 0.0748\n",
            "40/186, train_loss: 0.4868\n",
            "41/186, train_loss: 0.1793\n",
            "42/186, train_loss: 0.3256\n",
            "43/186, train_loss: 0.0657\n",
            "44/186, train_loss: 0.1039\n",
            "45/186, train_loss: 0.1352\n",
            "46/186, train_loss: 0.2279\n",
            "47/186, train_loss: 0.0712\n",
            "48/186, train_loss: 0.1023\n",
            "49/186, train_loss: 0.3118\n",
            "50/186, train_loss: 1.2380\n",
            "51/186, train_loss: 0.3489\n",
            "52/186, train_loss: 0.3500\n",
            "53/186, train_loss: 0.3231\n",
            "54/186, train_loss: 0.2312\n",
            "55/186, train_loss: 1.3951\n",
            "56/186, train_loss: 0.5154\n",
            "57/186, train_loss: 0.4650\n",
            "58/186, train_loss: 0.3505\n",
            "59/186, train_loss: 0.4681\n",
            "60/186, train_loss: 1.6728\n",
            "61/186, train_loss: 0.2758\n",
            "62/186, train_loss: 0.3450\n",
            "63/186, train_loss: 1.1958\n",
            "64/186, train_loss: 0.0408\n",
            "65/186, train_loss: 0.2961\n",
            "66/186, train_loss: 0.1016\n",
            "67/186, train_loss: 0.3480\n",
            "68/186, train_loss: 0.1656\n",
            "69/186, train_loss: 0.1089\n",
            "70/186, train_loss: 1.2137\n",
            "71/186, train_loss: 0.5931\n",
            "72/186, train_loss: 0.0852\n",
            "73/186, train_loss: 0.3654\n",
            "74/186, train_loss: 0.2186\n",
            "75/186, train_loss: 0.2257\n",
            "76/186, train_loss: 0.4114\n",
            "77/186, train_loss: 0.1799\n",
            "78/186, train_loss: 0.1958\n",
            "79/186, train_loss: 0.0937\n",
            "80/186, train_loss: 0.3743\n",
            "81/186, train_loss: 0.1293\n",
            "82/186, train_loss: 0.3171\n",
            "83/186, train_loss: 1.1880\n",
            "84/186, train_loss: 0.2440\n",
            "85/186, train_loss: 1.1580\n",
            "86/186, train_loss: 0.2718\n",
            "87/186, train_loss: 0.0976\n",
            "88/186, train_loss: 0.0936\n",
            "89/186, train_loss: 0.3927\n",
            "90/186, train_loss: 0.0555\n",
            "91/186, train_loss: 0.0337\n",
            "92/186, train_loss: 0.0709\n",
            "93/186, train_loss: 0.0239\n",
            "94/186, train_loss: 0.2857\n",
            "95/186, train_loss: 0.0629\n",
            "96/186, train_loss: 0.3227\n",
            "97/186, train_loss: 0.0820\n",
            "98/186, train_loss: 1.1446\n",
            "99/186, train_loss: 0.2959\n",
            "100/186, train_loss: 1.2475\n",
            "101/186, train_loss: 0.1118\n",
            "102/186, train_loss: 0.2695\n",
            "103/186, train_loss: 0.3701\n",
            "104/186, train_loss: 0.1303\n",
            "105/186, train_loss: 1.1557\n",
            "106/186, train_loss: 0.3000\n",
            "107/186, train_loss: 0.3958\n",
            "108/186, train_loss: 0.1071\n",
            "109/186, train_loss: 0.0429\n",
            "110/186, train_loss: 0.2878\n",
            "111/186, train_loss: 0.2797\n",
            "112/186, train_loss: 1.2945\n",
            "113/186, train_loss: 0.0698\n",
            "114/186, train_loss: 0.3837\n",
            "115/186, train_loss: 0.1149\n",
            "116/186, train_loss: 0.0139\n",
            "117/186, train_loss: 0.0341\n",
            "118/186, train_loss: 0.0900\n",
            "119/186, train_loss: 0.5304\n",
            "120/186, train_loss: 0.6790\n",
            "121/186, train_loss: 0.2842\n",
            "122/186, train_loss: 0.1240\n",
            "123/186, train_loss: 0.1392\n",
            "124/186, train_loss: 1.6196\n",
            "125/186, train_loss: 0.0340\n",
            "126/186, train_loss: 0.0645\n",
            "127/186, train_loss: 0.4838\n",
            "128/186, train_loss: 1.3248\n",
            "129/186, train_loss: 0.7272\n",
            "130/186, train_loss: 0.2931\n",
            "131/186, train_loss: 0.0506\n",
            "132/186, train_loss: 0.5726\n",
            "133/186, train_loss: 0.2955\n",
            "134/186, train_loss: 0.3837\n",
            "135/186, train_loss: 0.0874\n",
            "136/186, train_loss: 0.1261\n",
            "137/186, train_loss: 0.1554\n",
            "138/186, train_loss: 0.2969\n",
            "139/186, train_loss: 0.1645\n",
            "140/186, train_loss: 1.2841\n",
            "141/186, train_loss: 0.3798\n",
            "142/186, train_loss: 0.3743\n",
            "143/186, train_loss: 0.4693\n",
            "144/186, train_loss: 1.2382\n",
            "145/186, train_loss: 0.3026\n",
            "146/186, train_loss: 0.3836\n",
            "147/186, train_loss: 0.3450\n",
            "148/186, train_loss: 0.0666\n",
            "149/186, train_loss: 0.3302\n",
            "150/186, train_loss: 0.3396\n",
            "151/186, train_loss: 0.3726\n",
            "152/186, train_loss: 0.0304\n",
            "153/186, train_loss: 0.2856\n",
            "154/186, train_loss: 1.1646\n",
            "155/186, train_loss: 0.2151\n",
            "156/186, train_loss: 0.2896\n",
            "157/186, train_loss: 1.1832\n",
            "158/186, train_loss: 0.3835\n",
            "159/186, train_loss: 0.8275\n",
            "160/186, train_loss: 1.1674\n",
            "161/186, train_loss: 0.0701\n",
            "162/186, train_loss: 0.0707\n",
            "163/186, train_loss: 0.1663\n",
            "164/186, train_loss: 0.3346\n",
            "165/186, train_loss: 0.8574\n",
            "166/186, train_loss: 0.3391\n",
            "167/186, train_loss: 0.3042\n",
            "168/186, train_loss: 0.1360\n",
            "169/186, train_loss: 0.1384\n",
            "170/186, train_loss: 0.3152\n",
            "171/186, train_loss: 2.1312\n",
            "172/186, train_loss: 0.3071\n",
            "173/186, train_loss: 0.0471\n",
            "174/186, train_loss: 0.3036\n",
            "175/186, train_loss: 0.3370\n",
            "176/186, train_loss: 0.0470\n",
            "177/186, train_loss: 0.2816\n",
            "178/186, train_loss: 1.1567\n",
            "179/186, train_loss: 0.7633\n",
            "180/186, train_loss: 0.1175\n",
            "181/186, train_loss: 0.3363\n",
            "182/186, train_loss: 1.1668\n",
            "183/186, train_loss: 0.0520\n",
            "184/186, train_loss: 0.0875\n",
            "185/186, train_loss: 0.3487\n",
            "186/186, train_loss: 0.2088\n",
            "epoch 5 average loss: 0.4078\n",
            "----------\n",
            "epoch 6/50\n",
            "1/186, train_loss: 0.0697\n",
            "2/186, train_loss: 0.3526\n",
            "3/186, train_loss: 0.0573\n",
            "4/186, train_loss: 0.2305\n",
            "5/186, train_loss: 0.8451\n",
            "6/186, train_loss: 0.2433\n",
            "7/186, train_loss: 0.1154\n",
            "8/186, train_loss: 0.4499\n",
            "9/186, train_loss: 0.3794\n",
            "10/186, train_loss: 0.0529\n",
            "11/186, train_loss: 1.4209\n",
            "12/186, train_loss: 0.1326\n",
            "13/186, train_loss: 0.3281\n",
            "14/186, train_loss: 0.1125\n",
            "15/186, train_loss: 1.2806\n",
            "16/186, train_loss: 0.3249\n",
            "17/186, train_loss: 0.0718\n",
            "18/186, train_loss: 0.2065\n",
            "19/186, train_loss: 0.2590\n",
            "20/186, train_loss: 0.1478\n",
            "21/186, train_loss: 0.4825\n",
            "22/186, train_loss: 0.3201\n",
            "23/186, train_loss: 0.2796\n",
            "24/186, train_loss: 0.2743\n",
            "25/186, train_loss: 0.4570\n",
            "26/186, train_loss: 0.3310\n",
            "27/186, train_loss: 0.1667\n",
            "28/186, train_loss: 0.1876\n",
            "29/186, train_loss: 0.3077\n",
            "30/186, train_loss: 0.8001\n",
            "31/186, train_loss: 0.1770\n",
            "32/186, train_loss: 0.0594\n",
            "33/186, train_loss: 0.3250\n",
            "34/186, train_loss: 0.3625\n",
            "35/186, train_loss: 0.2157\n",
            "36/186, train_loss: 0.1894\n",
            "37/186, train_loss: 0.1979\n",
            "38/186, train_loss: 0.0327\n",
            "39/186, train_loss: 1.4262\n",
            "40/186, train_loss: 1.1627\n",
            "41/186, train_loss: 0.3878\n",
            "42/186, train_loss: 0.2679\n",
            "43/186, train_loss: 0.0751\n",
            "44/186, train_loss: 0.5304\n",
            "45/186, train_loss: 0.2829\n",
            "46/186, train_loss: 0.1040\n",
            "47/186, train_loss: 0.3849\n",
            "48/186, train_loss: 0.0227\n",
            "49/186, train_loss: 0.1250\n",
            "50/186, train_loss: 0.0697\n",
            "51/186, train_loss: 0.3453\n",
            "52/186, train_loss: 0.2905\n",
            "53/186, train_loss: 0.0239\n",
            "54/186, train_loss: 0.0970\n",
            "55/186, train_loss: 0.3499\n",
            "56/186, train_loss: 0.3774\n",
            "57/186, train_loss: 0.3455\n",
            "58/186, train_loss: 0.0448\n",
            "59/186, train_loss: 0.0256\n",
            "60/186, train_loss: 0.3316\n",
            "61/186, train_loss: 0.3682\n",
            "62/186, train_loss: 0.3286\n",
            "63/186, train_loss: 0.0720\n",
            "64/186, train_loss: 0.2631\n",
            "65/186, train_loss: 0.0768\n",
            "66/186, train_loss: 0.2741\n",
            "67/186, train_loss: 0.4772\n",
            "68/186, train_loss: 2.4633\n",
            "69/186, train_loss: 1.1724\n",
            "70/186, train_loss: 0.2995\n",
            "71/186, train_loss: 0.0564\n",
            "72/186, train_loss: 0.3444\n",
            "73/186, train_loss: 0.1514\n",
            "74/186, train_loss: 0.2698\n",
            "75/186, train_loss: 0.0992\n",
            "76/186, train_loss: 0.3218\n",
            "77/186, train_loss: 0.2297\n",
            "78/186, train_loss: 0.0711\n",
            "79/186, train_loss: 0.1332\n",
            "80/186, train_loss: 0.2620\n",
            "81/186, train_loss: 0.1857\n",
            "82/186, train_loss: 0.0568\n",
            "83/186, train_loss: 0.4687\n",
            "84/186, train_loss: 1.1782\n",
            "85/186, train_loss: 0.3681\n",
            "86/186, train_loss: 0.2065\n",
            "87/186, train_loss: 0.2198\n",
            "88/186, train_loss: 0.2566\n",
            "89/186, train_loss: 0.1827\n",
            "90/186, train_loss: 0.2012\n",
            "91/186, train_loss: 0.0516\n",
            "92/186, train_loss: 0.1847\n",
            "93/186, train_loss: 0.0515\n",
            "94/186, train_loss: 0.2435\n",
            "95/186, train_loss: 0.2009\n",
            "96/186, train_loss: 0.4065\n",
            "97/186, train_loss: 0.0442\n",
            "98/186, train_loss: 0.0563\n",
            "99/186, train_loss: 0.1560\n",
            "100/186, train_loss: 0.3070\n",
            "101/186, train_loss: 0.0292\n",
            "102/186, train_loss: 0.0211\n",
            "103/186, train_loss: 0.2704\n",
            "104/186, train_loss: 1.2001\n",
            "105/186, train_loss: 0.0364\n",
            "106/186, train_loss: 1.1809\n",
            "107/186, train_loss: 0.1825\n",
            "108/186, train_loss: 1.2127\n",
            "109/186, train_loss: 0.2482\n",
            "110/186, train_loss: 0.2981\n",
            "111/186, train_loss: 0.0428\n",
            "112/186, train_loss: 0.3618\n",
            "113/186, train_loss: 0.2545\n",
            "114/186, train_loss: 1.2159\n",
            "115/186, train_loss: 0.6092\n",
            "116/186, train_loss: 0.7568\n",
            "117/186, train_loss: 0.4156\n",
            "118/186, train_loss: 0.2419\n",
            "119/186, train_loss: 0.5729\n",
            "120/186, train_loss: 0.2667\n",
            "121/186, train_loss: 0.2289\n",
            "122/186, train_loss: 0.6627\n",
            "123/186, train_loss: 0.1481\n",
            "124/186, train_loss: 0.2783\n",
            "125/186, train_loss: 1.1431\n",
            "126/186, train_loss: 1.2722\n",
            "127/186, train_loss: 1.2030\n",
            "128/186, train_loss: 0.2794\n",
            "129/186, train_loss: 0.2857\n",
            "130/186, train_loss: 0.5392\n",
            "131/186, train_loss: 0.3429\n",
            "132/186, train_loss: 0.3897\n",
            "133/186, train_loss: 1.2369\n",
            "134/186, train_loss: 0.2212\n",
            "135/186, train_loss: 0.3583\n",
            "136/186, train_loss: 0.1766\n",
            "137/186, train_loss: 0.0451\n",
            "138/186, train_loss: 0.1855\n",
            "139/186, train_loss: 0.2256\n",
            "140/186, train_loss: 0.4246\n",
            "141/186, train_loss: 0.4452\n",
            "142/186, train_loss: 0.0686\n",
            "143/186, train_loss: 0.3831\n",
            "144/186, train_loss: 0.1847\n",
            "145/186, train_loss: 0.1256\n",
            "146/186, train_loss: 0.2627\n",
            "147/186, train_loss: 0.1928\n",
            "148/186, train_loss: 0.0520\n",
            "149/186, train_loss: 1.7512\n",
            "150/186, train_loss: 0.0611\n",
            "151/186, train_loss: 0.1508\n",
            "152/186, train_loss: 1.1422\n",
            "153/186, train_loss: 0.0444\n",
            "154/186, train_loss: 1.3895\n",
            "155/186, train_loss: 0.2384\n",
            "156/186, train_loss: 1.1675\n",
            "157/186, train_loss: 0.0665\n",
            "158/186, train_loss: 0.3482\n",
            "159/186, train_loss: 0.1032\n",
            "160/186, train_loss: 0.0345\n",
            "161/186, train_loss: 0.3974\n",
            "162/186, train_loss: 0.8438\n",
            "163/186, train_loss: 0.3614\n",
            "164/186, train_loss: 0.2223\n",
            "165/186, train_loss: 0.3418\n",
            "166/186, train_loss: 0.0801\n",
            "167/186, train_loss: 0.3331\n",
            "168/186, train_loss: 0.0526\n",
            "169/186, train_loss: 0.2856\n",
            "170/186, train_loss: 0.2353\n",
            "171/186, train_loss: 0.0805\n",
            "172/186, train_loss: 0.0376\n",
            "173/186, train_loss: 0.6883\n",
            "174/186, train_loss: 0.0682\n",
            "175/186, train_loss: 0.1989\n",
            "176/186, train_loss: 0.3200\n",
            "177/186, train_loss: 0.2553\n",
            "178/186, train_loss: 0.0362\n",
            "179/186, train_loss: 0.2783\n",
            "180/186, train_loss: 0.1687\n",
            "181/186, train_loss: 0.0277\n",
            "182/186, train_loss: 0.3625\n",
            "183/186, train_loss: 0.1060\n",
            "184/186, train_loss: 0.1208\n",
            "185/186, train_loss: 0.1123\n",
            "186/186, train_loss: 0.2521\n",
            "epoch 6 average loss: 0.3528\n",
            "current epoch: 6 current accuracy: 0.8172 best accuracy: 0.8172 at epoch 4\n",
            "----------\n",
            "epoch 7/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/186, train_loss: 0.3273\n",
            "2/186, train_loss: 1.2247\n",
            "3/186, train_loss: 0.1292\n",
            "4/186, train_loss: 0.5898\n",
            "5/186, train_loss: 0.0759\n",
            "6/186, train_loss: 0.0868\n",
            "7/186, train_loss: 0.2807\n",
            "8/186, train_loss: 0.4035\n",
            "9/186, train_loss: 0.2465\n",
            "10/186, train_loss: 1.1208\n",
            "11/186, train_loss: 1.3905\n",
            "12/186, train_loss: 0.0231\n",
            "13/186, train_loss: 0.6310\n",
            "14/186, train_loss: 0.0416\n",
            "15/186, train_loss: 0.2826\n",
            "16/186, train_loss: 1.3719\n",
            "17/186, train_loss: 0.2613\n",
            "18/186, train_loss: 2.4411\n",
            "19/186, train_loss: 0.0853\n",
            "20/186, train_loss: 0.1029\n",
            "21/186, train_loss: 0.1970\n",
            "22/186, train_loss: 0.4054\n",
            "23/186, train_loss: 0.3931\n",
            "24/186, train_loss: 0.2823\n",
            "25/186, train_loss: 0.0771\n",
            "26/186, train_loss: 0.0338\n",
            "27/186, train_loss: 0.1920\n",
            "28/186, train_loss: 0.2827\n",
            "29/186, train_loss: 0.3601\n",
            "30/186, train_loss: 0.1049\n",
            "31/186, train_loss: 0.1772\n",
            "32/186, train_loss: 0.1961\n",
            "33/186, train_loss: 1.1506\n",
            "34/186, train_loss: 0.0262\n",
            "35/186, train_loss: 1.3981\n",
            "36/186, train_loss: 0.2182\n",
            "37/186, train_loss: 0.1965\n",
            "38/186, train_loss: 0.0427\n",
            "39/186, train_loss: 0.0569\n",
            "40/186, train_loss: 0.2255\n",
            "41/186, train_loss: 0.4398\n",
            "42/186, train_loss: 0.0813\n",
            "43/186, train_loss: 0.4689\n",
            "44/186, train_loss: 0.0641\n",
            "45/186, train_loss: 0.3058\n",
            "46/186, train_loss: 0.2832\n",
            "47/186, train_loss: 0.7745\n",
            "48/186, train_loss: 0.0589\n",
            "49/186, train_loss: 0.2013\n",
            "50/186, train_loss: 0.0816\n",
            "51/186, train_loss: 0.2592\n",
            "52/186, train_loss: 0.0252\n",
            "53/186, train_loss: 0.0241\n",
            "54/186, train_loss: 1.1210\n",
            "55/186, train_loss: 0.2330\n",
            "56/186, train_loss: 0.4637\n",
            "57/186, train_loss: 0.4778\n",
            "58/186, train_loss: 1.2932\n",
            "59/186, train_loss: 0.1190\n",
            "60/186, train_loss: 0.9684\n",
            "61/186, train_loss: 0.3215\n",
            "62/186, train_loss: 0.6475\n",
            "63/186, train_loss: 0.0153\n",
            "64/186, train_loss: 0.0226\n",
            "65/186, train_loss: 0.0371\n",
            "66/186, train_loss: 0.0913\n",
            "67/186, train_loss: 0.1232\n",
            "68/186, train_loss: 0.0562\n",
            "69/186, train_loss: 0.1429\n",
            "70/186, train_loss: 0.6643\n",
            "71/186, train_loss: 0.0555\n",
            "72/186, train_loss: 0.0546\n",
            "73/186, train_loss: 0.1097\n",
            "74/186, train_loss: 0.2296\n",
            "75/186, train_loss: 0.3124\n",
            "76/186, train_loss: 0.3598\n",
            "77/186, train_loss: 0.6835\n",
            "78/186, train_loss: 0.0736\n",
            "79/186, train_loss: 0.2041\n",
            "80/186, train_loss: 0.2042\n",
            "81/186, train_loss: 0.1167\n",
            "82/186, train_loss: 0.0357\n",
            "83/186, train_loss: 0.2504\n",
            "84/186, train_loss: 1.2037\n",
            "85/186, train_loss: 0.2619\n",
            "86/186, train_loss: 0.0278\n",
            "87/186, train_loss: 0.0359\n",
            "88/186, train_loss: 0.0455\n",
            "89/186, train_loss: 0.0123\n",
            "90/186, train_loss: 0.0322\n",
            "91/186, train_loss: 0.3628\n",
            "92/186, train_loss: 0.0300\n",
            "93/186, train_loss: 0.1866\n",
            "94/186, train_loss: 0.2225\n",
            "95/186, train_loss: 0.2572\n",
            "96/186, train_loss: 0.1397\n",
            "97/186, train_loss: 0.1789\n",
            "98/186, train_loss: 0.3083\n",
            "99/186, train_loss: 0.4160\n",
            "100/186, train_loss: 0.1732\n",
            "101/186, train_loss: 1.4201\n",
            "102/186, train_loss: 0.0448\n",
            "103/186, train_loss: 0.2216\n",
            "104/186, train_loss: 0.3794\n",
            "105/186, train_loss: 0.1570\n",
            "106/186, train_loss: 0.0550\n",
            "107/186, train_loss: 0.0902\n",
            "108/186, train_loss: 0.1291\n",
            "109/186, train_loss: 0.3093\n",
            "110/186, train_loss: 0.2265\n",
            "111/186, train_loss: 0.0910\n",
            "112/186, train_loss: 0.0312\n",
            "113/186, train_loss: 0.0365\n",
            "114/186, train_loss: 0.0321\n",
            "115/186, train_loss: 0.1874\n",
            "116/186, train_loss: 0.1287\n",
            "117/186, train_loss: 0.0741\n",
            "118/186, train_loss: 0.4025\n",
            "119/186, train_loss: 0.3896\n",
            "120/186, train_loss: 1.1909\n",
            "121/186, train_loss: 1.1092\n",
            "122/186, train_loss: 0.0483\n",
            "123/186, train_loss: 0.0990\n",
            "124/186, train_loss: 0.0307\n",
            "125/186, train_loss: 0.0160\n",
            "126/186, train_loss: 0.1998\n",
            "127/186, train_loss: 0.0367\n",
            "128/186, train_loss: 0.2619\n",
            "129/186, train_loss: 1.2547\n",
            "130/186, train_loss: 0.0250\n",
            "131/186, train_loss: 0.3111\n",
            "132/186, train_loss: 0.2003\n",
            "133/186, train_loss: 0.1352\n",
            "134/186, train_loss: 0.0177\n",
            "135/186, train_loss: 1.2603\n",
            "136/186, train_loss: 0.6229\n",
            "137/186, train_loss: 0.3801\n",
            "138/186, train_loss: 0.0212\n",
            "139/186, train_loss: 0.0226\n",
            "140/186, train_loss: 0.3324\n",
            "141/186, train_loss: 0.2479\n",
            "142/186, train_loss: 0.0686\n",
            "143/186, train_loss: 0.1108\n",
            "144/186, train_loss: 0.8159\n",
            "145/186, train_loss: 0.0934\n",
            "146/186, train_loss: 0.1928\n",
            "147/186, train_loss: 1.1812\n",
            "148/186, train_loss: 0.0437\n",
            "149/186, train_loss: 0.0982\n",
            "150/186, train_loss: 0.0503\n",
            "151/186, train_loss: 0.0192\n",
            "152/186, train_loss: 0.2291\n",
            "153/186, train_loss: 0.0631\n",
            "154/186, train_loss: 0.3604\n",
            "155/186, train_loss: 0.2848\n",
            "156/186, train_loss: 0.1672\n",
            "157/186, train_loss: 0.2689\n",
            "158/186, train_loss: 0.2478\n",
            "159/186, train_loss: 0.2550\n",
            "160/186, train_loss: 0.0179\n",
            "161/186, train_loss: 0.2192\n",
            "162/186, train_loss: 1.2091\n",
            "163/186, train_loss: 0.2716\n",
            "164/186, train_loss: 0.2344\n",
            "165/186, train_loss: 0.2342\n",
            "166/186, train_loss: 0.2981\n",
            "167/186, train_loss: 0.1306\n",
            "168/186, train_loss: 0.1207\n",
            "169/186, train_loss: 0.2778\n",
            "170/186, train_loss: 0.2276\n",
            "171/186, train_loss: 0.2340\n",
            "172/186, train_loss: 0.2129\n",
            "173/186, train_loss: 0.1593\n",
            "174/186, train_loss: 0.2074\n",
            "175/186, train_loss: 0.0163\n",
            "176/186, train_loss: 0.0243\n",
            "177/186, train_loss: 0.0172\n",
            "178/186, train_loss: 0.3745\n",
            "179/186, train_loss: 0.1783\n",
            "180/186, train_loss: 0.2188\n",
            "181/186, train_loss: 0.0154\n",
            "182/186, train_loss: 0.0567\n",
            "183/186, train_loss: 0.3151\n",
            "184/186, train_loss: 0.3075\n",
            "185/186, train_loss: 1.8210\n",
            "186/186, train_loss: 1.1896\n",
            "epoch 7 average loss: 0.3169\n",
            "----------\n",
            "epoch 8/50\n",
            "1/186, train_loss: 0.0635\n",
            "2/186, train_loss: 2.2297\n",
            "3/186, train_loss: 0.1915\n",
            "4/186, train_loss: 0.0527\n",
            "5/186, train_loss: 0.4553\n",
            "6/186, train_loss: 0.3573\n",
            "7/186, train_loss: 0.0242\n",
            "8/186, train_loss: 1.1899\n",
            "9/186, train_loss: 0.3191\n",
            "10/186, train_loss: 0.0600\n",
            "11/186, train_loss: 0.1562\n",
            "12/186, train_loss: 0.1855\n",
            "13/186, train_loss: 0.0128\n",
            "14/186, train_loss: 0.3072\n",
            "15/186, train_loss: 1.1505\n",
            "16/186, train_loss: 0.1054\n",
            "17/186, train_loss: 0.2812\n",
            "18/186, train_loss: 0.0386\n",
            "19/186, train_loss: 0.2150\n",
            "20/186, train_loss: 0.5403\n",
            "21/186, train_loss: 0.0157\n",
            "22/186, train_loss: 0.2444\n",
            "23/186, train_loss: 0.0306\n",
            "24/186, train_loss: 0.3107\n",
            "25/186, train_loss: 0.2656\n",
            "26/186, train_loss: 0.0704\n",
            "27/186, train_loss: 2.5528\n",
            "28/186, train_loss: 0.1913\n",
            "29/186, train_loss: 0.0864\n",
            "30/186, train_loss: 0.0940\n",
            "31/186, train_loss: 0.0127\n",
            "32/186, train_loss: 0.0433\n",
            "33/186, train_loss: 0.3248\n",
            "34/186, train_loss: 1.4204\n",
            "35/186, train_loss: 0.2215\n",
            "36/186, train_loss: 0.0441\n",
            "37/186, train_loss: 0.0486\n",
            "38/186, train_loss: 0.0690\n",
            "39/186, train_loss: 0.1986\n",
            "40/186, train_loss: 0.0191\n",
            "41/186, train_loss: 0.0241\n",
            "42/186, train_loss: 0.1907\n",
            "43/186, train_loss: 1.1795\n",
            "44/186, train_loss: 0.3634\n",
            "45/186, train_loss: 0.1731\n",
            "46/186, train_loss: 0.2034\n",
            "47/186, train_loss: 1.1592\n",
            "48/186, train_loss: 1.1713\n",
            "49/186, train_loss: 0.0266\n",
            "50/186, train_loss: 0.1183\n",
            "51/186, train_loss: 0.0332\n",
            "52/186, train_loss: 0.1838\n",
            "53/186, train_loss: 0.2592\n",
            "54/186, train_loss: 0.1766\n",
            "55/186, train_loss: 0.1979\n",
            "56/186, train_loss: 0.1756\n",
            "57/186, train_loss: 0.4033\n",
            "58/186, train_loss: 0.2094\n",
            "59/186, train_loss: 0.3311\n",
            "60/186, train_loss: 0.2635\n",
            "61/186, train_loss: 0.1655\n",
            "62/186, train_loss: 1.2267\n",
            "63/186, train_loss: 0.0238\n",
            "64/186, train_loss: 1.2177\n",
            "65/186, train_loss: 0.0199\n",
            "66/186, train_loss: 0.0108\n",
            "67/186, train_loss: 0.1579\n",
            "68/186, train_loss: 0.0257\n",
            "69/186, train_loss: 0.2915\n",
            "70/186, train_loss: 0.1513\n",
            "71/186, train_loss: 1.2340\n",
            "72/186, train_loss: 0.5725\n",
            "73/186, train_loss: 1.3609\n",
            "74/186, train_loss: 0.2690\n",
            "75/186, train_loss: 0.3131\n",
            "76/186, train_loss: 0.0162\n",
            "77/186, train_loss: 0.0506\n",
            "78/186, train_loss: 0.2554\n",
            "79/186, train_loss: 0.0356\n",
            "80/186, train_loss: 0.0564\n",
            "81/186, train_loss: 1.4450\n",
            "82/186, train_loss: 1.0209\n",
            "83/186, train_loss: 0.1615\n",
            "84/186, train_loss: 0.0905\n",
            "85/186, train_loss: 0.5251\n",
            "86/186, train_loss: 1.1901\n",
            "87/186, train_loss: 0.1116\n",
            "88/186, train_loss: 0.0463\n",
            "89/186, train_loss: 0.0529\n",
            "90/186, train_loss: 0.1270\n",
            "91/186, train_loss: 0.4350\n",
            "92/186, train_loss: 0.2203\n",
            "93/186, train_loss: 0.3014\n",
            "94/186, train_loss: 0.1032\n",
            "95/186, train_loss: 1.4656\n",
            "96/186, train_loss: 0.0523\n",
            "97/186, train_loss: 0.1580\n",
            "98/186, train_loss: 0.2342\n",
            "99/186, train_loss: 0.2019\n",
            "100/186, train_loss: 0.0344\n",
            "101/186, train_loss: 0.0425\n",
            "102/186, train_loss: 0.3636\n",
            "103/186, train_loss: 0.2926\n",
            "104/186, train_loss: 0.1928\n",
            "105/186, train_loss: 0.3532\n",
            "106/186, train_loss: 0.2415\n",
            "107/186, train_loss: 0.0172\n",
            "108/186, train_loss: 0.1507\n",
            "109/186, train_loss: 0.0800\n",
            "110/186, train_loss: 0.5801\n",
            "111/186, train_loss: 0.3346\n",
            "112/186, train_loss: 0.0183\n",
            "113/186, train_loss: 1.1473\n",
            "114/186, train_loss: 0.2078\n",
            "115/186, train_loss: 0.1441\n",
            "116/186, train_loss: 0.2512\n",
            "117/186, train_loss: 0.1266\n",
            "118/186, train_loss: 1.1346\n",
            "119/186, train_loss: 0.3248\n",
            "120/186, train_loss: 0.5038\n",
            "121/186, train_loss: 0.0150\n",
            "122/186, train_loss: 0.0347\n",
            "123/186, train_loss: 0.2817\n",
            "124/186, train_loss: 1.1565\n",
            "125/186, train_loss: 0.2523\n",
            "126/186, train_loss: 0.0207\n",
            "127/186, train_loss: 0.1735\n",
            "128/186, train_loss: 0.3777\n",
            "129/186, train_loss: 0.7431\n",
            "130/186, train_loss: 0.1725\n",
            "131/186, train_loss: 0.0678\n",
            "132/186, train_loss: 0.0328\n",
            "133/186, train_loss: 0.0733\n",
            "134/186, train_loss: 0.3330\n",
            "135/186, train_loss: 0.2056\n",
            "136/186, train_loss: 0.1656\n",
            "137/186, train_loss: 1.1535\n",
            "138/186, train_loss: 0.2731\n",
            "139/186, train_loss: 0.2882\n",
            "140/186, train_loss: 0.8370\n",
            "141/186, train_loss: 1.1004\n",
            "142/186, train_loss: 0.1591\n",
            "143/186, train_loss: 1.1478\n",
            "144/186, train_loss: 0.0555\n",
            "145/186, train_loss: 0.2914\n",
            "146/186, train_loss: 0.3044\n",
            "147/186, train_loss: 0.1759\n",
            "148/186, train_loss: 0.2433\n",
            "149/186, train_loss: 0.2675\n",
            "150/186, train_loss: 0.1539\n",
            "151/186, train_loss: 0.0798\n",
            "152/186, train_loss: 0.7147\n",
            "153/186, train_loss: 0.2130\n",
            "154/186, train_loss: 0.2360\n",
            "155/186, train_loss: 0.1026\n",
            "156/186, train_loss: 1.2371\n",
            "157/186, train_loss: 0.0679\n",
            "158/186, train_loss: 0.0589\n",
            "159/186, train_loss: 0.1426\n",
            "160/186, train_loss: 0.0535\n",
            "161/186, train_loss: 0.0227\n",
            "162/186, train_loss: 0.1124\n",
            "163/186, train_loss: 0.2167\n",
            "164/186, train_loss: 0.4510\n",
            "165/186, train_loss: 0.0408\n",
            "166/186, train_loss: 0.0480\n",
            "167/186, train_loss: 0.1846\n",
            "168/186, train_loss: 1.4727\n",
            "169/186, train_loss: 0.1881\n",
            "170/186, train_loss: 0.0282\n",
            "171/186, train_loss: 0.1651\n",
            "172/186, train_loss: 1.2121\n",
            "173/186, train_loss: 0.1713\n",
            "174/186, train_loss: 0.0249\n",
            "175/186, train_loss: 0.0443\n",
            "176/186, train_loss: 0.3337\n",
            "177/186, train_loss: 0.1787\n",
            "178/186, train_loss: 0.0818\n",
            "179/186, train_loss: 0.2576\n",
            "180/186, train_loss: 0.0703\n",
            "181/186, train_loss: 0.1754\n",
            "182/186, train_loss: 0.1637\n",
            "183/186, train_loss: 0.1398\n",
            "184/186, train_loss: 0.3653\n",
            "185/186, train_loss: 0.1780\n",
            "186/186, train_loss: 0.1501\n",
            "epoch 8 average loss: 0.3383\n",
            "saved new best metric model\n",
            "current epoch: 8 current accuracy: 0.8817 best accuracy: 0.8817 at epoch 8\n",
            "----------\n",
            "epoch 9/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/186, train_loss: 0.4117\n",
            "2/186, train_loss: 0.1808\n",
            "3/186, train_loss: 0.0076\n",
            "4/186, train_loss: 0.2326\n",
            "5/186, train_loss: 1.1679\n",
            "6/186, train_loss: 1.2998\n",
            "7/186, train_loss: 0.2036\n",
            "8/186, train_loss: 0.1834\n",
            "9/186, train_loss: 0.0069\n",
            "10/186, train_loss: 0.0446\n",
            "11/186, train_loss: 0.3943\n",
            "12/186, train_loss: 1.2994\n",
            "13/186, train_loss: 1.0913\n",
            "14/186, train_loss: 0.0670\n",
            "15/186, train_loss: 1.4371\n",
            "16/186, train_loss: 0.2521\n",
            "17/186, train_loss: 0.2946\n",
            "18/186, train_loss: 0.1207\n",
            "19/186, train_loss: 1.2620\n",
            "20/186, train_loss: 0.0089\n",
            "21/186, train_loss: 0.2161\n",
            "22/186, train_loss: 0.1535\n",
            "23/186, train_loss: 0.2449\n",
            "24/186, train_loss: 0.3922\n",
            "25/186, train_loss: 0.1120\n",
            "26/186, train_loss: 0.2214\n",
            "27/186, train_loss: 0.1519\n",
            "28/186, train_loss: 0.1292\n",
            "29/186, train_loss: 0.1243\n",
            "30/186, train_loss: 0.1990\n",
            "31/186, train_loss: 1.2447\n",
            "32/186, train_loss: 0.1419\n",
            "33/186, train_loss: 0.5977\n",
            "34/186, train_loss: 0.0185\n",
            "35/186, train_loss: 0.0423\n",
            "36/186, train_loss: 0.8703\n",
            "37/186, train_loss: 0.0090\n",
            "38/186, train_loss: 0.0648\n",
            "39/186, train_loss: 1.1248\n",
            "40/186, train_loss: 0.1376\n",
            "41/186, train_loss: 0.1278\n",
            "42/186, train_loss: 0.3922\n",
            "43/186, train_loss: 0.3064\n",
            "44/186, train_loss: 0.3110\n",
            "45/186, train_loss: 0.1335\n",
            "46/186, train_loss: 0.1982\n",
            "47/186, train_loss: 0.0771\n",
            "48/186, train_loss: 0.1081\n",
            "49/186, train_loss: 0.0244\n",
            "50/186, train_loss: 0.0244\n",
            "51/186, train_loss: 0.1625\n",
            "52/186, train_loss: 0.0708\n",
            "53/186, train_loss: 0.0339\n",
            "54/186, train_loss: 0.3012\n",
            "55/186, train_loss: 1.0543\n",
            "56/186, train_loss: 0.1494\n",
            "57/186, train_loss: 0.1621\n",
            "58/186, train_loss: 1.1260\n",
            "59/186, train_loss: 0.0313\n",
            "60/186, train_loss: 0.2180\n",
            "61/186, train_loss: 0.1498\n",
            "62/186, train_loss: 1.1111\n",
            "63/186, train_loss: 0.1426\n",
            "64/186, train_loss: 0.3660\n",
            "65/186, train_loss: 0.0185\n",
            "66/186, train_loss: 0.0356\n",
            "67/186, train_loss: 0.1645\n",
            "68/186, train_loss: 0.0170\n",
            "69/186, train_loss: 1.1229\n",
            "70/186, train_loss: 0.3628\n",
            "71/186, train_loss: 0.0537\n",
            "72/186, train_loss: 0.1518\n",
            "73/186, train_loss: 0.1385\n",
            "74/186, train_loss: 1.0845\n",
            "75/186, train_loss: 1.3641\n",
            "76/186, train_loss: 0.0222\n",
            "77/186, train_loss: 0.3377\n",
            "78/186, train_loss: 0.0327\n",
            "79/186, train_loss: 0.2355\n",
            "80/186, train_loss: 0.1544\n",
            "81/186, train_loss: 0.0661\n",
            "82/186, train_loss: 0.2099\n",
            "83/186, train_loss: 0.0576\n",
            "84/186, train_loss: 0.1859\n",
            "85/186, train_loss: 0.1829\n",
            "86/186, train_loss: 0.3334\n",
            "87/186, train_loss: 0.0461\n",
            "88/186, train_loss: 1.0258\n",
            "89/186, train_loss: 0.0315\n",
            "90/186, train_loss: 1.2150\n",
            "91/186, train_loss: 0.0359\n",
            "92/186, train_loss: 1.5367\n",
            "93/186, train_loss: 0.3781\n",
            "94/186, train_loss: 0.0218\n",
            "95/186, train_loss: 0.0135\n",
            "96/186, train_loss: 0.1281\n",
            "97/186, train_loss: 0.3385\n",
            "98/186, train_loss: 0.1723\n",
            "99/186, train_loss: 1.0221\n",
            "100/186, train_loss: 0.0100\n",
            "101/186, train_loss: 0.6314\n",
            "102/186, train_loss: 0.0253\n",
            "103/186, train_loss: 0.1491\n",
            "104/186, train_loss: 0.0073\n",
            "105/186, train_loss: 0.0408\n",
            "106/186, train_loss: 0.0611\n",
            "107/186, train_loss: 0.0084\n",
            "108/186, train_loss: 0.0621\n",
            "109/186, train_loss: 0.0158\n",
            "110/186, train_loss: 0.1383\n",
            "111/186, train_loss: 1.3064\n",
            "112/186, train_loss: 0.0207\n",
            "113/186, train_loss: 0.0770\n",
            "114/186, train_loss: 0.3498\n",
            "115/186, train_loss: 1.0790\n",
            "116/186, train_loss: 0.3256\n",
            "117/186, train_loss: 0.1657\n",
            "118/186, train_loss: 0.8164\n",
            "119/186, train_loss: 0.0567\n",
            "120/186, train_loss: 0.4073\n",
            "121/186, train_loss: 0.0890\n",
            "122/186, train_loss: 0.0289\n",
            "123/186, train_loss: 0.1424\n",
            "124/186, train_loss: 1.0261\n",
            "125/186, train_loss: 0.3242\n",
            "126/186, train_loss: 0.0480\n",
            "127/186, train_loss: 0.0316\n",
            "128/186, train_loss: 0.0478\n",
            "129/186, train_loss: 0.1812\n",
            "130/186, train_loss: 0.0280\n",
            "131/186, train_loss: 0.0295\n",
            "132/186, train_loss: 1.2824\n",
            "133/186, train_loss: 0.1436\n",
            "134/186, train_loss: 0.1689\n",
            "135/186, train_loss: 0.4292\n",
            "136/186, train_loss: 0.2804\n",
            "137/186, train_loss: 0.1801\n",
            "138/186, train_loss: 0.2483\n",
            "139/186, train_loss: 0.0461\n",
            "140/186, train_loss: 0.1209\n",
            "141/186, train_loss: 0.7497\n",
            "142/186, train_loss: 1.5308\n",
            "143/186, train_loss: 0.3766\n",
            "144/186, train_loss: 0.2952\n",
            "145/186, train_loss: 0.3497\n",
            "146/186, train_loss: 0.2086\n",
            "147/186, train_loss: 0.0213\n",
            "148/186, train_loss: 0.2398\n",
            "149/186, train_loss: 0.1694\n",
            "150/186, train_loss: 0.2651\n",
            "151/186, train_loss: 0.1255\n",
            "152/186, train_loss: 0.4641\n",
            "153/186, train_loss: 0.0465\n",
            "154/186, train_loss: 0.1493\n",
            "155/186, train_loss: 0.2225\n",
            "156/186, train_loss: 1.1742\n",
            "157/186, train_loss: 0.1309\n",
            "158/186, train_loss: 0.4866\n",
            "159/186, train_loss: 0.0843\n",
            "160/186, train_loss: 0.3600\n",
            "161/186, train_loss: 0.3767\n",
            "162/186, train_loss: 0.3803\n",
            "163/186, train_loss: 0.0832\n",
            "164/186, train_loss: 0.0622\n",
            "165/186, train_loss: 0.0410\n",
            "166/186, train_loss: 0.1531\n",
            "167/186, train_loss: 0.3208\n",
            "168/186, train_loss: 0.1895\n",
            "169/186, train_loss: 0.1274\n",
            "170/186, train_loss: 1.0615\n",
            "171/186, train_loss: 1.7423\n",
            "172/186, train_loss: 0.0096\n",
            "173/186, train_loss: 0.6118\n",
            "174/186, train_loss: 0.1551\n",
            "175/186, train_loss: 0.3962\n",
            "176/186, train_loss: 0.4894\n",
            "177/186, train_loss: 0.1373\n",
            "178/186, train_loss: 0.0315\n",
            "179/186, train_loss: 0.2439\n",
            "180/186, train_loss: 1.3511\n",
            "181/186, train_loss: 0.3599\n",
            "182/186, train_loss: 1.4481\n",
            "183/186, train_loss: 1.0587\n",
            "184/186, train_loss: 0.0288\n",
            "185/186, train_loss: 0.1663\n",
            "186/186, train_loss: 0.2565\n",
            "epoch 9 average loss: 0.3473\n",
            "----------\n",
            "epoch 10/50\n",
            "1/186, train_loss: 0.2578\n",
            "2/186, train_loss: 0.2848\n",
            "3/186, train_loss: 0.0561\n",
            "4/186, train_loss: 0.2046\n",
            "5/186, train_loss: 0.2149\n",
            "6/186, train_loss: 0.5814\n",
            "7/186, train_loss: 0.2033\n",
            "8/186, train_loss: 0.1262\n",
            "9/186, train_loss: 0.5544\n",
            "10/186, train_loss: 0.2730\n",
            "11/186, train_loss: 1.6119\n",
            "12/186, train_loss: 0.0563\n",
            "13/186, train_loss: 0.0168\n",
            "14/186, train_loss: 0.1966\n",
            "15/186, train_loss: 0.0325\n",
            "16/186, train_loss: 0.3442\n",
            "17/186, train_loss: 0.0496\n",
            "18/186, train_loss: 1.0994\n",
            "19/186, train_loss: 0.1099\n",
            "20/186, train_loss: 0.1481\n",
            "21/186, train_loss: 0.0869\n",
            "22/186, train_loss: 0.2350\n",
            "23/186, train_loss: 0.3465\n",
            "24/186, train_loss: 0.0442\n",
            "25/186, train_loss: 0.5827\n",
            "26/186, train_loss: 1.4282\n",
            "27/186, train_loss: 1.3363\n",
            "28/186, train_loss: 1.0597\n",
            "29/186, train_loss: 0.1409\n",
            "30/186, train_loss: 0.1151\n",
            "31/186, train_loss: 0.0413\n",
            "32/186, train_loss: 0.0382\n",
            "33/186, train_loss: 0.0136\n",
            "34/186, train_loss: 0.0547\n",
            "35/186, train_loss: 0.4156\n",
            "36/186, train_loss: 0.0275\n",
            "37/186, train_loss: 0.0121\n",
            "38/186, train_loss: 0.1391\n",
            "39/186, train_loss: 0.1273\n",
            "40/186, train_loss: 0.5457\n",
            "41/186, train_loss: 0.0528\n",
            "42/186, train_loss: 0.1059\n",
            "43/186, train_loss: 0.4357\n",
            "44/186, train_loss: 0.0066\n",
            "45/186, train_loss: 0.6047\n",
            "46/186, train_loss: 0.1531\n",
            "47/186, train_loss: 1.0591\n",
            "48/186, train_loss: 0.0175\n",
            "49/186, train_loss: 0.1616\n",
            "50/186, train_loss: 0.0244\n",
            "51/186, train_loss: 1.2617\n",
            "52/186, train_loss: 0.1149\n",
            "53/186, train_loss: 0.0152\n",
            "54/186, train_loss: 0.1372\n",
            "55/186, train_loss: 0.1724\n",
            "56/186, train_loss: 0.0144\n",
            "57/186, train_loss: 0.0245\n",
            "58/186, train_loss: 0.0059\n",
            "59/186, train_loss: 0.4985\n",
            "60/186, train_loss: 0.2785\n",
            "61/186, train_loss: 0.0546\n",
            "62/186, train_loss: 0.0203\n",
            "63/186, train_loss: 0.4908\n",
            "64/186, train_loss: 0.3453\n",
            "65/186, train_loss: 0.0185\n",
            "66/186, train_loss: 1.5121\n",
            "67/186, train_loss: 0.0685\n",
            "68/186, train_loss: 1.3346\n",
            "69/186, train_loss: 0.2319\n",
            "70/186, train_loss: 0.4932\n",
            "71/186, train_loss: 0.4176\n",
            "72/186, train_loss: 0.0279\n",
            "73/186, train_loss: 0.0211\n",
            "74/186, train_loss: 0.4603\n",
            "75/186, train_loss: 0.1530\n",
            "76/186, train_loss: 0.1890\n",
            "77/186, train_loss: 0.3562\n",
            "78/186, train_loss: 1.4015\n",
            "79/186, train_loss: 0.0504\n",
            "80/186, train_loss: 0.0542\n",
            "81/186, train_loss: 0.1084\n",
            "82/186, train_loss: 1.2156\n",
            "83/186, train_loss: 0.1327\n",
            "84/186, train_loss: 0.1979\n",
            "85/186, train_loss: 1.1470\n",
            "86/186, train_loss: 0.0652\n",
            "87/186, train_loss: 0.4047\n",
            "88/186, train_loss: 0.1066\n",
            "89/186, train_loss: 0.1286\n",
            "90/186, train_loss: 0.0373\n",
            "91/186, train_loss: 0.1492\n",
            "92/186, train_loss: 1.0851\n",
            "93/186, train_loss: 0.1350\n",
            "94/186, train_loss: 0.0216\n",
            "95/186, train_loss: 0.3535\n",
            "96/186, train_loss: 1.1480\n",
            "97/186, train_loss: 1.3066\n",
            "98/186, train_loss: 0.0502\n",
            "99/186, train_loss: 0.2378\n",
            "100/186, train_loss: 1.0380\n",
            "101/186, train_loss: 0.0261\n",
            "102/186, train_loss: 0.0168\n",
            "103/186, train_loss: 0.0913\n",
            "104/186, train_loss: 1.0868\n",
            "105/186, train_loss: 0.1852\n",
            "106/186, train_loss: 1.0131\n",
            "107/186, train_loss: 1.2553\n",
            "108/186, train_loss: 0.0656\n",
            "109/186, train_loss: 0.3303\n",
            "110/186, train_loss: 1.4838\n",
            "111/186, train_loss: 0.3235\n",
            "112/186, train_loss: 0.6362\n",
            "113/186, train_loss: 0.3151\n",
            "114/186, train_loss: 0.1251\n",
            "115/186, train_loss: 0.0307\n",
            "116/186, train_loss: 0.0595\n",
            "117/186, train_loss: 0.1063\n",
            "118/186, train_loss: 0.1942\n",
            "119/186, train_loss: 0.1211\n",
            "120/186, train_loss: 0.3960\n",
            "121/186, train_loss: 0.0413\n",
            "122/186, train_loss: 0.0077\n",
            "123/186, train_loss: 1.0774\n",
            "124/186, train_loss: 0.0592\n",
            "125/186, train_loss: 0.1305\n",
            "126/186, train_loss: 0.0101\n",
            "127/186, train_loss: 1.5329\n",
            "128/186, train_loss: 0.0067\n",
            "129/186, train_loss: 0.0114\n",
            "130/186, train_loss: 0.0548\n",
            "131/186, train_loss: 0.3037\n",
            "132/186, train_loss: 0.0087\n",
            "133/186, train_loss: 0.1740\n",
            "134/186, train_loss: 0.3993\n",
            "135/186, train_loss: 0.1287\n",
            "136/186, train_loss: 0.0078\n",
            "137/186, train_loss: 0.0113\n",
            "138/186, train_loss: 0.2198\n",
            "139/186, train_loss: 0.0277\n",
            "140/186, train_loss: 0.8338\n",
            "141/186, train_loss: 0.3527\n",
            "142/186, train_loss: 0.0316\n",
            "143/186, train_loss: 0.0099\n",
            "144/186, train_loss: 0.1529\n",
            "145/186, train_loss: 1.0088\n",
            "146/186, train_loss: 1.2940\n",
            "147/186, train_loss: 0.1400\n",
            "148/186, train_loss: 0.0158\n",
            "149/186, train_loss: 0.4631\n",
            "150/186, train_loss: 0.1481\n",
            "151/186, train_loss: 0.4577\n",
            "152/186, train_loss: 0.2292\n",
            "153/186, train_loss: 1.1133\n",
            "154/186, train_loss: 0.0095\n",
            "155/186, train_loss: 0.0265\n",
            "156/186, train_loss: 0.1462\n",
            "157/186, train_loss: 0.0782\n",
            "158/186, train_loss: 0.2824\n",
            "159/186, train_loss: 0.3395\n",
            "160/186, train_loss: 0.3190\n",
            "161/186, train_loss: 0.2303\n",
            "162/186, train_loss: 0.0325\n",
            "163/186, train_loss: 0.1678\n",
            "164/186, train_loss: 0.2417\n",
            "165/186, train_loss: 0.1923\n",
            "166/186, train_loss: 0.1239\n",
            "167/186, train_loss: 0.0392\n",
            "168/186, train_loss: 1.0384\n",
            "169/186, train_loss: 0.0327\n",
            "170/186, train_loss: 0.0356\n",
            "171/186, train_loss: 0.0740\n",
            "172/186, train_loss: 0.9893\n",
            "173/186, train_loss: 0.3542\n",
            "174/186, train_loss: 0.2969\n",
            "175/186, train_loss: 0.3837\n",
            "176/186, train_loss: 0.1175\n",
            "177/186, train_loss: 0.1159\n",
            "178/186, train_loss: 0.3019\n",
            "179/186, train_loss: 0.3361\n",
            "180/186, train_loss: 0.4952\n",
            "181/186, train_loss: 0.1572\n",
            "182/186, train_loss: 0.1151\n",
            "183/186, train_loss: 0.1898\n",
            "184/186, train_loss: 0.0343\n",
            "185/186, train_loss: 0.1813\n",
            "186/186, train_loss: 0.0425\n",
            "epoch 10 average loss: 0.3278\n",
            "current epoch: 10 current accuracy: 0.8710 best accuracy: 0.8817 at epoch 8\n",
            "----------\n",
            "epoch 11/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/186, train_loss: 1.6090\n",
            "2/186, train_loss: 0.0222\n",
            "3/186, train_loss: 0.1280\n",
            "4/186, train_loss: 0.1998\n",
            "5/186, train_loss: 1.3983\n",
            "6/186, train_loss: 0.0589\n",
            "7/186, train_loss: 0.1669\n",
            "8/186, train_loss: 0.2475\n",
            "9/186, train_loss: 0.9963\n",
            "10/186, train_loss: 0.3502\n",
            "11/186, train_loss: 0.2826\n",
            "12/186, train_loss: 0.0045\n",
            "13/186, train_loss: 0.3769\n",
            "14/186, train_loss: 0.0285\n",
            "15/186, train_loss: 0.2204\n",
            "16/186, train_loss: 0.0051\n",
            "17/186, train_loss: 0.1347\n",
            "18/186, train_loss: 0.1398\n",
            "19/186, train_loss: 0.1509\n",
            "20/186, train_loss: 0.2994\n",
            "21/186, train_loss: 0.0734\n",
            "22/186, train_loss: 0.4413\n",
            "23/186, train_loss: 1.7349\n",
            "24/186, train_loss: 0.0519\n",
            "25/186, train_loss: 0.0121\n",
            "26/186, train_loss: 0.1069\n",
            "27/186, train_loss: 0.6105\n",
            "28/186, train_loss: 0.1253\n",
            "29/186, train_loss: 1.0371\n",
            "30/186, train_loss: 0.4667\n",
            "31/186, train_loss: 0.0906\n",
            "32/186, train_loss: 0.3957\n",
            "33/186, train_loss: 0.1942\n",
            "34/186, train_loss: 0.1433\n",
            "35/186, train_loss: 0.4180\n",
            "36/186, train_loss: 1.0603\n",
            "37/186, train_loss: 0.1396\n",
            "38/186, train_loss: 0.0064\n",
            "39/186, train_loss: 0.0064\n",
            "40/186, train_loss: 1.0966\n",
            "41/186, train_loss: 0.0613\n",
            "42/186, train_loss: 0.0921\n",
            "43/186, train_loss: 0.9499\n",
            "44/186, train_loss: 0.1382\n",
            "45/186, train_loss: 0.1788\n",
            "46/186, train_loss: 0.4037\n",
            "47/186, train_loss: 0.1867\n",
            "48/186, train_loss: 0.0976\n",
            "49/186, train_loss: 0.5734\n",
            "50/186, train_loss: 1.0429\n",
            "51/186, train_loss: 1.0319\n",
            "52/186, train_loss: 0.1098\n",
            "53/186, train_loss: 0.0409\n",
            "54/186, train_loss: 0.0296\n",
            "55/186, train_loss: 0.2733\n",
            "56/186, train_loss: 0.1460\n",
            "57/186, train_loss: 0.0221\n",
            "58/186, train_loss: 0.1316\n",
            "59/186, train_loss: 0.2416\n",
            "60/186, train_loss: 0.1432\n",
            "61/186, train_loss: 1.0545\n",
            "62/186, train_loss: 0.1721\n",
            "63/186, train_loss: 0.1292\n",
            "64/186, train_loss: 0.1482\n",
            "65/186, train_loss: 0.0447\n",
            "66/186, train_loss: 0.1916\n",
            "67/186, train_loss: 0.4491\n",
            "68/186, train_loss: 0.0155\n",
            "69/186, train_loss: 0.1347\n",
            "70/186, train_loss: 0.4305\n",
            "71/186, train_loss: 0.2503\n",
            "72/186, train_loss: 0.3319\n",
            "73/186, train_loss: 0.1923\n",
            "74/186, train_loss: 0.1268\n",
            "75/186, train_loss: 0.0213\n",
            "76/186, train_loss: 1.0092\n",
            "77/186, train_loss: 0.4342\n",
            "78/186, train_loss: 0.0653\n",
            "79/186, train_loss: 0.2262\n",
            "80/186, train_loss: 0.4641\n",
            "81/186, train_loss: 0.3853\n",
            "82/186, train_loss: 0.0197\n",
            "83/186, train_loss: 0.0141\n",
            "84/186, train_loss: 0.1149\n",
            "85/186, train_loss: 0.1529\n",
            "86/186, train_loss: 0.1732\n",
            "87/186, train_loss: 0.1232\n",
            "88/186, train_loss: 0.0940\n",
            "89/186, train_loss: 0.0857\n",
            "90/186, train_loss: 0.9754\n",
            "91/186, train_loss: 0.1366\n",
            "92/186, train_loss: 0.0919\n",
            "93/186, train_loss: 0.0286\n",
            "94/186, train_loss: 0.1018\n",
            "95/186, train_loss: 0.0301\n",
            "96/186, train_loss: 0.4371\n",
            "97/186, train_loss: 0.0275\n",
            "98/186, train_loss: 0.1438\n",
            "99/186, train_loss: 0.0385\n",
            "100/186, train_loss: 0.0369\n",
            "101/186, train_loss: 0.2905\n",
            "102/186, train_loss: 0.2611\n",
            "103/186, train_loss: 0.2100\n",
            "104/186, train_loss: 0.0336\n",
            "105/186, train_loss: 0.0735\n",
            "106/186, train_loss: 0.0165\n",
            "107/186, train_loss: 0.2048\n",
            "108/186, train_loss: 0.2376\n",
            "109/186, train_loss: 0.0292\n",
            "110/186, train_loss: 0.3969\n",
            "111/186, train_loss: 0.0475\n",
            "112/186, train_loss: 0.0109\n",
            "113/186, train_loss: 0.3609\n",
            "114/186, train_loss: 0.0051\n",
            "115/186, train_loss: 0.9596\n",
            "116/186, train_loss: 0.0195\n",
            "117/186, train_loss: 0.0109\n",
            "118/186, train_loss: 0.1406\n",
            "119/186, train_loss: 1.0147\n",
            "120/186, train_loss: 0.0297\n",
            "121/186, train_loss: 0.0169\n",
            "122/186, train_loss: 0.4536\n",
            "123/186, train_loss: 0.9974\n",
            "124/186, train_loss: 0.0942\n",
            "125/186, train_loss: 0.0117\n",
            "126/186, train_loss: 0.3009\n",
            "127/186, train_loss: 0.2111\n",
            "128/186, train_loss: 0.9765\n",
            "129/186, train_loss: 0.3136\n",
            "130/186, train_loss: 0.4376\n",
            "131/186, train_loss: 0.0055\n",
            "132/186, train_loss: 0.5079\n",
            "133/186, train_loss: 1.4392\n",
            "134/186, train_loss: 1.2347\n",
            "135/186, train_loss: 0.0432\n",
            "136/186, train_loss: 0.0060\n",
            "137/186, train_loss: 0.1408\n",
            "138/186, train_loss: 0.1619\n",
            "139/186, train_loss: 1.0443\n",
            "140/186, train_loss: 0.2574\n",
            "141/186, train_loss: 0.2054\n",
            "142/186, train_loss: 0.0854\n",
            "143/186, train_loss: 0.0419\n",
            "144/186, train_loss: 0.4509\n",
            "145/186, train_loss: 0.1393\n",
            "146/186, train_loss: 0.1863\n",
            "147/186, train_loss: 0.1521\n",
            "148/186, train_loss: 0.0425\n",
            "149/186, train_loss: 0.2334\n",
            "150/186, train_loss: 0.5499\n",
            "151/186, train_loss: 0.1461\n",
            "152/186, train_loss: 1.2987\n",
            "153/186, train_loss: 0.5300\n",
            "154/186, train_loss: 0.1069\n",
            "155/186, train_loss: 0.1324\n",
            "156/186, train_loss: 0.1673\n",
            "157/186, train_loss: 0.5441\n",
            "158/186, train_loss: 0.1294\n",
            "159/186, train_loss: 0.9489\n",
            "160/186, train_loss: 0.0095\n",
            "161/186, train_loss: 1.0334\n",
            "162/186, train_loss: 0.0269\n",
            "163/186, train_loss: 0.0561\n",
            "164/186, train_loss: 0.0486\n",
            "165/186, train_loss: 0.7057\n",
            "166/186, train_loss: 0.2214\n",
            "167/186, train_loss: 0.0274\n",
            "168/186, train_loss: 0.2299\n",
            "169/186, train_loss: 0.3021\n",
            "170/186, train_loss: 0.0103\n",
            "171/186, train_loss: 0.2876\n",
            "172/186, train_loss: 1.0517\n",
            "173/186, train_loss: 0.2271\n",
            "174/186, train_loss: 0.4125\n",
            "175/186, train_loss: 0.2743\n",
            "176/186, train_loss: 0.0073\n",
            "177/186, train_loss: 0.0079\n",
            "178/186, train_loss: 0.0032\n",
            "179/186, train_loss: 0.2241\n",
            "180/186, train_loss: 0.0149\n",
            "181/186, train_loss: 0.3592\n",
            "182/186, train_loss: 0.1780\n",
            "183/186, train_loss: 0.0197\n",
            "184/186, train_loss: 1.0300\n",
            "185/186, train_loss: 0.0209\n",
            "186/186, train_loss: 0.0288\n",
            "epoch 11 average loss: 0.3008\n",
            "----------\n",
            "epoch 12/50\n",
            "1/186, train_loss: 0.0442\n",
            "2/186, train_loss: 0.9575\n",
            "3/186, train_loss: 1.6387\n",
            "4/186, train_loss: 0.0052\n",
            "5/186, train_loss: 1.0314\n",
            "6/186, train_loss: 0.1628\n",
            "7/186, train_loss: 0.0053\n",
            "8/186, train_loss: 0.2571\n",
            "9/186, train_loss: 0.0077\n",
            "10/186, train_loss: 0.0609\n",
            "11/186, train_loss: 0.0167\n",
            "12/186, train_loss: 0.3441\n",
            "13/186, train_loss: 0.0832\n",
            "14/186, train_loss: 0.0244\n",
            "15/186, train_loss: 0.1196\n",
            "16/186, train_loss: 0.0119\n",
            "17/186, train_loss: 0.1297\n",
            "18/186, train_loss: 1.4802\n",
            "19/186, train_loss: 1.1221\n",
            "20/186, train_loss: 0.1391\n",
            "21/186, train_loss: 0.0253\n",
            "22/186, train_loss: 0.2287\n",
            "23/186, train_loss: 0.1496\n",
            "24/186, train_loss: 0.0365\n",
            "25/186, train_loss: 0.0127\n",
            "26/186, train_loss: 0.1907\n",
            "27/186, train_loss: 0.0830\n",
            "28/186, train_loss: 0.1098\n",
            "29/186, train_loss: 0.1870\n",
            "30/186, train_loss: 0.4540\n",
            "31/186, train_loss: 0.1319\n",
            "32/186, train_loss: 0.1247\n",
            "33/186, train_loss: 1.1786\n",
            "34/186, train_loss: 0.0162\n",
            "35/186, train_loss: 0.1480\n",
            "36/186, train_loss: 0.2268\n",
            "37/186, train_loss: 0.2234\n",
            "38/186, train_loss: 0.0125\n",
            "39/186, train_loss: 0.1014\n",
            "40/186, train_loss: 0.1665\n",
            "41/186, train_loss: 0.1076\n",
            "42/186, train_loss: 0.1825\n",
            "43/186, train_loss: 0.1242\n",
            "44/186, train_loss: 0.6170\n",
            "45/186, train_loss: 0.0268\n",
            "46/186, train_loss: 0.7154\n",
            "47/186, train_loss: 0.0263\n",
            "48/186, train_loss: 0.0959\n",
            "49/186, train_loss: 0.0305\n",
            "50/186, train_loss: 0.1952\n",
            "51/186, train_loss: 0.0544\n",
            "52/186, train_loss: 0.1139\n",
            "53/186, train_loss: 0.2471\n",
            "54/186, train_loss: 0.4785\n",
            "55/186, train_loss: 0.1153\n",
            "56/186, train_loss: 0.2987\n",
            "57/186, train_loss: 0.0301\n",
            "58/186, train_loss: 0.1440\n",
            "59/186, train_loss: 0.0378\n",
            "60/186, train_loss: 0.9987\n",
            "61/186, train_loss: 0.0760\n",
            "62/186, train_loss: 0.0663\n",
            "63/186, train_loss: 0.7573\n",
            "64/186, train_loss: 0.0408\n",
            "65/186, train_loss: 0.0145\n",
            "66/186, train_loss: 0.1079\n",
            "67/186, train_loss: 1.2341\n",
            "68/186, train_loss: 0.3394\n",
            "69/186, train_loss: 0.3918\n",
            "70/186, train_loss: 0.1924\n",
            "71/186, train_loss: 0.0141\n",
            "72/186, train_loss: 0.3099\n",
            "73/186, train_loss: 1.1240\n",
            "74/186, train_loss: 0.0917\n",
            "75/186, train_loss: 0.3572\n",
            "76/186, train_loss: 0.1270\n",
            "77/186, train_loss: 0.3090\n",
            "78/186, train_loss: 0.0266\n",
            "79/186, train_loss: 0.2817\n",
            "80/186, train_loss: 0.1512\n",
            "81/186, train_loss: 0.0276\n",
            "82/186, train_loss: 0.3393\n",
            "83/186, train_loss: 1.2373\n",
            "84/186, train_loss: 0.1014\n",
            "85/186, train_loss: 0.1481\n",
            "86/186, train_loss: 1.1461\n",
            "87/186, train_loss: 0.1236\n",
            "88/186, train_loss: 0.1791\n",
            "89/186, train_loss: 0.1217\n",
            "90/186, train_loss: 1.0021\n",
            "91/186, train_loss: 0.3745\n",
            "92/186, train_loss: 0.0331\n",
            "93/186, train_loss: 0.1773\n",
            "94/186, train_loss: 1.0271\n",
            "95/186, train_loss: 0.0210\n",
            "96/186, train_loss: 0.2570\n",
            "97/186, train_loss: 0.0955\n",
            "98/186, train_loss: 0.1270\n",
            "99/186, train_loss: 0.0150\n",
            "100/186, train_loss: 2.4504\n",
            "101/186, train_loss: 0.3824\n",
            "102/186, train_loss: 0.0256\n",
            "103/186, train_loss: 0.3442\n",
            "104/186, train_loss: 0.1042\n",
            "105/186, train_loss: 0.0701\n",
            "106/186, train_loss: 0.2228\n",
            "107/186, train_loss: 0.1225\n",
            "108/186, train_loss: 0.3953\n",
            "109/186, train_loss: 0.0812\n",
            "110/186, train_loss: 0.0329\n",
            "111/186, train_loss: 1.0850\n",
            "112/186, train_loss: 0.1111\n",
            "113/186, train_loss: 0.4354\n",
            "114/186, train_loss: 0.1244\n",
            "115/186, train_loss: 0.0599\n",
            "116/186, train_loss: 0.0304\n",
            "117/186, train_loss: 0.5487\n",
            "118/186, train_loss: 0.0688\n",
            "119/186, train_loss: 0.9676\n",
            "120/186, train_loss: 1.6600\n",
            "121/186, train_loss: 0.1314\n",
            "122/186, train_loss: 0.2302\n",
            "123/186, train_loss: 0.0795\n",
            "124/186, train_loss: 0.0553\n",
            "125/186, train_loss: 1.4148\n",
            "126/186, train_loss: 0.3010\n",
            "127/186, train_loss: 0.1415\n",
            "128/186, train_loss: 0.0707\n",
            "129/186, train_loss: 0.0230\n",
            "130/186, train_loss: 1.3910\n",
            "131/186, train_loss: 0.1613\n",
            "132/186, train_loss: 0.0884\n",
            "133/186, train_loss: 0.0099\n",
            "134/186, train_loss: 0.0064\n",
            "135/186, train_loss: 0.0096\n",
            "136/186, train_loss: 0.1392\n",
            "137/186, train_loss: 0.0171\n",
            "138/186, train_loss: 0.1269\n",
            "139/186, train_loss: 0.9766\n",
            "140/186, train_loss: 0.1213\n",
            "141/186, train_loss: 0.0234\n",
            "142/186, train_loss: 0.0125\n",
            "143/186, train_loss: 0.0254\n",
            "144/186, train_loss: 0.0193\n",
            "145/186, train_loss: 0.9974\n",
            "146/186, train_loss: 0.0247\n",
            "147/186, train_loss: 0.0118\n",
            "148/186, train_loss: 0.0063\n",
            "149/186, train_loss: 0.0058\n",
            "150/186, train_loss: 0.0186\n",
            "151/186, train_loss: 0.2765\n",
            "152/186, train_loss: 0.0155\n",
            "153/186, train_loss: 0.1096\n",
            "154/186, train_loss: 0.1260\n",
            "155/186, train_loss: 0.4384\n",
            "156/186, train_loss: 0.0370\n",
            "157/186, train_loss: 0.0210\n",
            "158/186, train_loss: 0.1367\n",
            "159/186, train_loss: 0.1819\n",
            "160/186, train_loss: 1.7085\n",
            "161/186, train_loss: 0.0110\n",
            "162/186, train_loss: 0.6927\n",
            "163/186, train_loss: 0.9578\n",
            "164/186, train_loss: 0.0266\n",
            "165/186, train_loss: 0.0045\n",
            "166/186, train_loss: 1.6631\n",
            "167/186, train_loss: 0.0079\n",
            "168/186, train_loss: 0.1065\n",
            "169/186, train_loss: 0.1606\n",
            "170/186, train_loss: 0.1354\n",
            "171/186, train_loss: 0.0621\n",
            "172/186, train_loss: 0.1478\n",
            "173/186, train_loss: 0.1014\n",
            "174/186, train_loss: 0.0144\n",
            "175/186, train_loss: 0.7360\n",
            "176/186, train_loss: 0.1596\n",
            "177/186, train_loss: 0.4074\n",
            "178/186, train_loss: 0.1769\n",
            "179/186, train_loss: 0.9000\n",
            "180/186, train_loss: 0.1013\n",
            "181/186, train_loss: 0.0603\n",
            "182/186, train_loss: 0.0649\n",
            "183/186, train_loss: 0.0038\n",
            "184/186, train_loss: 0.1073\n",
            "185/186, train_loss: 0.3860\n",
            "186/186, train_loss: 0.9571\n",
            "epoch 12 average loss: 0.3001\n",
            "current epoch: 12 current accuracy: 0.7849 best accuracy: 0.8817 at epoch 8\n",
            "----------\n",
            "epoch 13/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/186, train_loss: 0.0200\n",
            "2/186, train_loss: 0.2110\n",
            "3/186, train_loss: 0.1428\n",
            "4/186, train_loss: 0.1895\n",
            "5/186, train_loss: 0.1211\n",
            "6/186, train_loss: 0.1279\n",
            "7/186, train_loss: 0.0112\n",
            "8/186, train_loss: 0.0754\n",
            "9/186, train_loss: 0.1400\n",
            "10/186, train_loss: 0.1086\n",
            "11/186, train_loss: 0.0116\n",
            "12/186, train_loss: 0.4775\n",
            "13/186, train_loss: 0.0353\n",
            "14/186, train_loss: 0.1070\n",
            "15/186, train_loss: 0.0140\n",
            "16/186, train_loss: 0.6664\n",
            "17/186, train_loss: 0.4604\n",
            "18/186, train_loss: 0.0404\n",
            "19/186, train_loss: 0.2490\n",
            "20/186, train_loss: 0.1059\n",
            "21/186, train_loss: 0.0186\n",
            "22/186, train_loss: 1.0355\n",
            "23/186, train_loss: 0.1439\n",
            "24/186, train_loss: 0.0135\n",
            "25/186, train_loss: 0.4645\n",
            "26/186, train_loss: 0.2003\n",
            "27/186, train_loss: 1.0445\n",
            "28/186, train_loss: 0.0142\n",
            "29/186, train_loss: 0.9616\n",
            "30/186, train_loss: 0.1360\n",
            "31/186, train_loss: 0.0177\n",
            "32/186, train_loss: 0.1637\n",
            "33/186, train_loss: 0.0133\n",
            "34/186, train_loss: 0.0672\n",
            "35/186, train_loss: 0.0292\n",
            "36/186, train_loss: 0.4173\n",
            "37/186, train_loss: 0.0921\n",
            "38/186, train_loss: 0.0338\n",
            "39/186, train_loss: 0.5948\n",
            "40/186, train_loss: 0.2396\n",
            "41/186, train_loss: 0.0467\n",
            "42/186, train_loss: 0.1083\n",
            "43/186, train_loss: 0.0324\n",
            "44/186, train_loss: 0.0770\n",
            "45/186, train_loss: 0.9663\n",
            "46/186, train_loss: 0.4129\n",
            "47/186, train_loss: 0.2479\n",
            "48/186, train_loss: 0.1386\n",
            "49/186, train_loss: 1.0829\n",
            "50/186, train_loss: 0.1139\n",
            "51/186, train_loss: 0.2162\n",
            "52/186, train_loss: 0.2366\n",
            "53/186, train_loss: 0.4077\n",
            "54/186, train_loss: 0.0862\n",
            "55/186, train_loss: 0.4415\n",
            "56/186, train_loss: 0.0884\n",
            "57/186, train_loss: 0.9512\n",
            "58/186, train_loss: 0.2535\n",
            "59/186, train_loss: 0.1015\n",
            "60/186, train_loss: 0.9892\n",
            "61/186, train_loss: 0.1267\n",
            "62/186, train_loss: 1.1139\n",
            "63/186, train_loss: 0.0490\n",
            "64/186, train_loss: 0.0070\n",
            "65/186, train_loss: 0.1408\n",
            "66/186, train_loss: 0.2378\n",
            "67/186, train_loss: 0.3607\n",
            "68/186, train_loss: 0.8717\n",
            "69/186, train_loss: 0.0388\n",
            "70/186, train_loss: 0.7303\n",
            "71/186, train_loss: 0.1497\n",
            "72/186, train_loss: 0.0223\n",
            "73/186, train_loss: 1.2198\n",
            "74/186, train_loss: 0.0375\n",
            "75/186, train_loss: 0.1099\n",
            "76/186, train_loss: 2.1893\n",
            "77/186, train_loss: 0.1453\n",
            "78/186, train_loss: 0.5555\n",
            "79/186, train_loss: 0.0237\n",
            "80/186, train_loss: 0.3727\n",
            "81/186, train_loss: 1.2495\n",
            "82/186, train_loss: 1.1240\n",
            "83/186, train_loss: 0.0079\n",
            "84/186, train_loss: 0.4939\n",
            "85/186, train_loss: 0.0820\n",
            "86/186, train_loss: 0.1576\n",
            "87/186, train_loss: 0.3973\n",
            "88/186, train_loss: 0.1751\n",
            "89/186, train_loss: 0.2701\n",
            "90/186, train_loss: 0.8434\n",
            "91/186, train_loss: 0.0213\n",
            "92/186, train_loss: 0.9100\n",
            "93/186, train_loss: 0.0117\n",
            "94/186, train_loss: 0.3254\n",
            "95/186, train_loss: 0.1366\n",
            "96/186, train_loss: 0.3921\n",
            "97/186, train_loss: 0.9510\n",
            "98/186, train_loss: 0.9773\n",
            "99/186, train_loss: 0.8968\n",
            "100/186, train_loss: 0.1094\n",
            "101/186, train_loss: 0.9061\n",
            "102/186, train_loss: 0.2592\n",
            "103/186, train_loss: 1.0538\n",
            "104/186, train_loss: 0.1808\n",
            "105/186, train_loss: 0.1726\n",
            "106/186, train_loss: 0.0239\n",
            "107/186, train_loss: 0.0390\n",
            "108/186, train_loss: 0.1127\n",
            "109/186, train_loss: 0.5326\n",
            "110/186, train_loss: 0.0233\n",
            "111/186, train_loss: 0.0499\n",
            "112/186, train_loss: 0.0949\n",
            "113/186, train_loss: 0.0843\n",
            "114/186, train_loss: 0.1172\n",
            "115/186, train_loss: 0.1267\n",
            "116/186, train_loss: 0.1243\n",
            "117/186, train_loss: 1.4651\n",
            "118/186, train_loss: 0.0190\n",
            "119/186, train_loss: 0.0645\n",
            "120/186, train_loss: 0.1110\n",
            "121/186, train_loss: 0.1342\n",
            "122/186, train_loss: 0.1100\n",
            "123/186, train_loss: 0.1770\n",
            "124/186, train_loss: 0.1439\n",
            "125/186, train_loss: 1.3847\n",
            "126/186, train_loss: 0.8629\n",
            "127/186, train_loss: 0.1223\n",
            "128/186, train_loss: 0.0206\n",
            "129/186, train_loss: 0.8221\n",
            "130/186, train_loss: 0.0371\n",
            "131/186, train_loss: 0.2985\n",
            "132/186, train_loss: 0.0311\n",
            "133/186, train_loss: 0.0312\n",
            "134/186, train_loss: 0.0459\n",
            "135/186, train_loss: 0.0445\n",
            "136/186, train_loss: 0.3844\n",
            "137/186, train_loss: 0.1294\n",
            "138/186, train_loss: 0.0672\n",
            "139/186, train_loss: 0.8717\n",
            "140/186, train_loss: 0.1722\n",
            "141/186, train_loss: 0.1221\n",
            "142/186, train_loss: 0.7541\n",
            "143/186, train_loss: 0.1418\n",
            "144/186, train_loss: 0.1565\n",
            "145/186, train_loss: 0.0812\n",
            "146/186, train_loss: 0.0646\n",
            "147/186, train_loss: 0.7955\n",
            "148/186, train_loss: 0.1132\n",
            "149/186, train_loss: 0.1335\n",
            "150/186, train_loss: 0.1225\n",
            "151/186, train_loss: 0.7987\n",
            "152/186, train_loss: 0.1760\n",
            "153/186, train_loss: 0.0197\n",
            "154/186, train_loss: 0.0899\n",
            "155/186, train_loss: 0.1802\n",
            "156/186, train_loss: 0.0100\n",
            "157/186, train_loss: 0.1202\n",
            "158/186, train_loss: 0.0090\n",
            "159/186, train_loss: 0.9249\n",
            "160/186, train_loss: 0.0594\n",
            "161/186, train_loss: 0.7837\n",
            "162/186, train_loss: 0.8486\n",
            "163/186, train_loss: 0.0925\n",
            "164/186, train_loss: 0.1143\n",
            "165/186, train_loss: 0.8800\n",
            "166/186, train_loss: 0.6059\n",
            "167/186, train_loss: 0.0024\n",
            "168/186, train_loss: 0.0079\n",
            "169/186, train_loss: 1.0953\n",
            "170/186, train_loss: 0.0068\n",
            "171/186, train_loss: 0.0297\n",
            "172/186, train_loss: 0.7382\n",
            "173/186, train_loss: 0.0228\n",
            "174/186, train_loss: 0.2383\n",
            "175/186, train_loss: 0.9297\n",
            "176/186, train_loss: 0.0802\n",
            "177/186, train_loss: 0.1087\n",
            "178/186, train_loss: 0.1036\n",
            "179/186, train_loss: 0.1518\n",
            "180/186, train_loss: 0.1563\n",
            "181/186, train_loss: 0.0621\n",
            "182/186, train_loss: 0.0865\n",
            "183/186, train_loss: 0.1385\n",
            "184/186, train_loss: 0.1108\n",
            "185/186, train_loss: 0.1635\n",
            "186/186, train_loss: 0.0196\n",
            "epoch 13 average loss: 0.3116\n",
            "----------\n",
            "epoch 14/50\n",
            "1/186, train_loss: 0.5301\n",
            "2/186, train_loss: 0.1127\n",
            "3/186, train_loss: 0.2354\n",
            "4/186, train_loss: 0.7984\n",
            "5/186, train_loss: 0.2836\n",
            "6/186, train_loss: 0.0382\n",
            "7/186, train_loss: 0.0227\n",
            "8/186, train_loss: 0.0082\n",
            "9/186, train_loss: 0.0083\n",
            "10/186, train_loss: 0.0317\n",
            "11/186, train_loss: 0.6421\n",
            "12/186, train_loss: 0.2111\n",
            "13/186, train_loss: 0.0102\n",
            "14/186, train_loss: 0.7845\n",
            "15/186, train_loss: 0.0044\n",
            "16/186, train_loss: 0.0205\n",
            "17/186, train_loss: 0.4918\n",
            "18/186, train_loss: 0.2052\n",
            "19/186, train_loss: 1.1642\n",
            "20/186, train_loss: 0.4655\n",
            "21/186, train_loss: 0.0403\n",
            "22/186, train_loss: 0.0170\n",
            "23/186, train_loss: 0.3074\n",
            "24/186, train_loss: 0.3785\n",
            "25/186, train_loss: 0.5853\n",
            "26/186, train_loss: 0.3443\n",
            "27/186, train_loss: 2.0407\n",
            "28/186, train_loss: 0.0194\n",
            "29/186, train_loss: 0.3501\n",
            "30/186, train_loss: 0.1295\n",
            "31/186, train_loss: 0.0711\n",
            "32/186, train_loss: 1.2770\n",
            "33/186, train_loss: 0.7846\n",
            "34/186, train_loss: 0.3071\n",
            "35/186, train_loss: 0.0865\n",
            "36/186, train_loss: 0.1317\n",
            "37/186, train_loss: 0.0949\n",
            "38/186, train_loss: 0.0077\n",
            "39/186, train_loss: 0.0572\n",
            "40/186, train_loss: 0.0533\n",
            "41/186, train_loss: 0.1183\n",
            "42/186, train_loss: 0.2493\n",
            "43/186, train_loss: 0.5665\n",
            "44/186, train_loss: 0.1518\n",
            "45/186, train_loss: 1.1510\n",
            "46/186, train_loss: 0.2073\n",
            "47/186, train_loss: 0.1010\n",
            "48/186, train_loss: 0.1360\n",
            "49/186, train_loss: 0.0233\n",
            "50/186, train_loss: 0.0845\n",
            "51/186, train_loss: 0.3755\n",
            "52/186, train_loss: 0.1120\n",
            "53/186, train_loss: 0.0206\n",
            "54/186, train_loss: 0.0726\n",
            "55/186, train_loss: 0.3790\n",
            "56/186, train_loss: 0.1097\n",
            "57/186, train_loss: 0.1585\n",
            "58/186, train_loss: 0.0117\n",
            "59/186, train_loss: 0.1147\n",
            "60/186, train_loss: 0.0828\n",
            "61/186, train_loss: 0.2068\n",
            "62/186, train_loss: 0.0935\n",
            "63/186, train_loss: 0.0261\n",
            "64/186, train_loss: 0.0480\n",
            "65/186, train_loss: 0.4516\n",
            "66/186, train_loss: 0.1494\n",
            "67/186, train_loss: 0.4020\n",
            "68/186, train_loss: 0.1551\n",
            "69/186, train_loss: 0.0129\n",
            "70/186, train_loss: 0.2126\n",
            "71/186, train_loss: 0.0255\n",
            "72/186, train_loss: 0.1017\n",
            "73/186, train_loss: 1.0608\n",
            "74/186, train_loss: 0.0082\n",
            "75/186, train_loss: 0.3658\n",
            "76/186, train_loss: 0.0434\n",
            "77/186, train_loss: 0.0084\n",
            "78/186, train_loss: 0.3131\n",
            "79/186, train_loss: 0.2575\n",
            "80/186, train_loss: 0.1160\n",
            "81/186, train_loss: 0.0240\n",
            "82/186, train_loss: 1.3518\n",
            "83/186, train_loss: 0.0287\n",
            "84/186, train_loss: 0.1049\n",
            "85/186, train_loss: 0.0367\n",
            "86/186, train_loss: 0.0040\n",
            "87/186, train_loss: 0.0190\n",
            "88/186, train_loss: 0.0402\n",
            "89/186, train_loss: 0.0864\n",
            "90/186, train_loss: 0.0991\n",
            "91/186, train_loss: 0.1254\n",
            "92/186, train_loss: 0.8520\n",
            "93/186, train_loss: 0.4475\n",
            "94/186, train_loss: 0.0035\n",
            "95/186, train_loss: 0.7839\n",
            "96/186, train_loss: 0.8111\n",
            "97/186, train_loss: 0.1340\n",
            "98/186, train_loss: 0.8903\n",
            "99/186, train_loss: 0.1183\n",
            "100/186, train_loss: 0.8382\n",
            "101/186, train_loss: 0.1140\n",
            "102/186, train_loss: 0.0463\n",
            "103/186, train_loss: 2.1391\n",
            "104/186, train_loss: 0.3200\n",
            "105/186, train_loss: 0.1457\n",
            "106/186, train_loss: 1.4854\n",
            "107/186, train_loss: 0.1753\n",
            "108/186, train_loss: 0.3550\n",
            "109/186, train_loss: 0.2008\n",
            "110/186, train_loss: 0.0072\n",
            "111/186, train_loss: 0.0116\n",
            "112/186, train_loss: 0.1417\n",
            "113/186, train_loss: 0.1739\n",
            "114/186, train_loss: 0.3005\n",
            "115/186, train_loss: 0.1933\n",
            "116/186, train_loss: 0.6434\n",
            "117/186, train_loss: 0.9795\n",
            "118/186, train_loss: 0.1383\n",
            "119/186, train_loss: 0.0721\n",
            "120/186, train_loss: 0.0079\n",
            "121/186, train_loss: 0.0153\n",
            "122/186, train_loss: 0.7771\n",
            "123/186, train_loss: 0.1248\n",
            "124/186, train_loss: 0.9261\n",
            "125/186, train_loss: 0.2644\n",
            "126/186, train_loss: 0.3574\n",
            "127/186, train_loss: 0.0479\n",
            "128/186, train_loss: 0.1355\n",
            "129/186, train_loss: 0.0419\n",
            "130/186, train_loss: 0.5155\n",
            "131/186, train_loss: 0.0287\n",
            "132/186, train_loss: 0.0910\n",
            "133/186, train_loss: 0.1313\n",
            "134/186, train_loss: 0.1584\n",
            "135/186, train_loss: 0.0056\n",
            "136/186, train_loss: 0.3833\n",
            "137/186, train_loss: 0.0464\n",
            "138/186, train_loss: 0.2589\n",
            "139/186, train_loss: 0.4502\n",
            "140/186, train_loss: 0.5610\n",
            "141/186, train_loss: 0.7591\n",
            "142/186, train_loss: 0.0033\n",
            "143/186, train_loss: 0.0607\n",
            "144/186, train_loss: 0.0376\n",
            "145/186, train_loss: 0.0128\n",
            "146/186, train_loss: 0.5823\n",
            "147/186, train_loss: 0.3012\n",
            "148/186, train_loss: 0.0277\n",
            "149/186, train_loss: 0.1454\n",
            "150/186, train_loss: 0.2566\n",
            "151/186, train_loss: 0.0692\n",
            "152/186, train_loss: 0.0323\n",
            "153/186, train_loss: 0.0293\n",
            "154/186, train_loss: 0.2051\n",
            "155/186, train_loss: 0.0350\n",
            "156/186, train_loss: 0.8528\n",
            "157/186, train_loss: 0.1236\n",
            "158/186, train_loss: 0.1027\n",
            "159/186, train_loss: 0.1943\n",
            "160/186, train_loss: 0.0030\n",
            "161/186, train_loss: 0.0037\n",
            "162/186, train_loss: 0.0058\n",
            "163/186, train_loss: 0.7704\n",
            "164/186, train_loss: 0.1175\n",
            "165/186, train_loss: 0.1639\n",
            "166/186, train_loss: 3.1666\n",
            "167/186, train_loss: 0.6585\n",
            "168/186, train_loss: 0.9011\n",
            "169/186, train_loss: 0.1097\n",
            "170/186, train_loss: 0.6615\n",
            "171/186, train_loss: 0.0923\n",
            "172/186, train_loss: 0.0029\n",
            "173/186, train_loss: 0.0585\n",
            "174/186, train_loss: 0.0288\n",
            "175/186, train_loss: 0.0116\n",
            "176/186, train_loss: 0.8021\n",
            "177/186, train_loss: 0.0041\n",
            "178/186, train_loss: 0.1699\n",
            "179/186, train_loss: 0.7029\n",
            "180/186, train_loss: 0.0888\n",
            "181/186, train_loss: 0.0981\n",
            "182/186, train_loss: 0.2539\n",
            "183/186, train_loss: 0.0773\n",
            "184/186, train_loss: 0.0559\n",
            "185/186, train_loss: 0.0872\n",
            "186/186, train_loss: 0.0663\n",
            "epoch 14 average loss: 0.2914\n",
            "current epoch: 14 current accuracy: 0.8280 best accuracy: 0.8817 at epoch 8\n",
            "----------\n",
            "epoch 15/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/186, train_loss: 1.1492\n",
            "2/186, train_loss: 0.1893\n",
            "3/186, train_loss: 0.1434\n",
            "4/186, train_loss: 0.0165\n",
            "5/186, train_loss: 0.6372\n",
            "6/186, train_loss: 0.0696\n",
            "7/186, train_loss: 0.0162\n",
            "8/186, train_loss: 0.0537\n",
            "9/186, train_loss: 0.1317\n",
            "10/186, train_loss: 0.4773\n",
            "11/186, train_loss: 0.1207\n",
            "12/186, train_loss: 0.0920\n",
            "13/186, train_loss: 0.4198\n",
            "14/186, train_loss: 0.0946\n",
            "15/186, train_loss: 0.1222\n",
            "16/186, train_loss: 0.2838\n",
            "17/186, train_loss: 0.2764\n",
            "18/186, train_loss: 0.2873\n",
            "19/186, train_loss: 0.1164\n",
            "20/186, train_loss: 0.1035\n",
            "21/186, train_loss: 0.0805\n",
            "22/186, train_loss: 0.0198\n",
            "23/186, train_loss: 1.0705\n",
            "24/186, train_loss: 0.1494\n",
            "25/186, train_loss: 0.0833\n",
            "26/186, train_loss: 0.0514\n",
            "27/186, train_loss: 0.0309\n",
            "28/186, train_loss: 0.1255\n",
            "29/186, train_loss: 0.8801\n",
            "30/186, train_loss: 0.1097\n",
            "31/186, train_loss: 0.0585\n",
            "32/186, train_loss: 0.0114\n",
            "33/186, train_loss: 0.0276\n",
            "34/186, train_loss: 0.0251\n",
            "35/186, train_loss: 0.0191\n",
            "36/186, train_loss: 0.0537\n",
            "37/186, train_loss: 0.1782\n",
            "38/186, train_loss: 0.0199\n",
            "39/186, train_loss: 0.0643\n",
            "40/186, train_loss: 0.1422\n",
            "41/186, train_loss: 0.2192\n",
            "42/186, train_loss: 0.1068\n",
            "43/186, train_loss: 0.3294\n",
            "44/186, train_loss: 1.1115\n",
            "45/186, train_loss: 0.0168\n",
            "46/186, train_loss: 0.0169\n",
            "47/186, train_loss: 0.1281\n",
            "48/186, train_loss: 0.3864\n",
            "49/186, train_loss: 0.8566\n",
            "50/186, train_loss: 0.3651\n",
            "51/186, train_loss: 1.3522\n",
            "52/186, train_loss: 0.0878\n",
            "53/186, train_loss: 0.7802\n",
            "54/186, train_loss: 0.0055\n",
            "55/186, train_loss: 1.2410\n",
            "56/186, train_loss: 0.1395\n",
            "57/186, train_loss: 1.2622\n",
            "58/186, train_loss: 0.0534\n",
            "59/186, train_loss: 0.0158\n",
            "60/186, train_loss: 0.0151\n",
            "61/186, train_loss: 0.7966\n",
            "62/186, train_loss: 0.1356\n",
            "63/186, train_loss: 0.0866\n",
            "64/186, train_loss: 0.8146\n",
            "65/186, train_loss: 0.0348\n",
            "66/186, train_loss: 0.3342\n",
            "67/186, train_loss: 0.0714\n",
            "68/186, train_loss: 2.5678\n",
            "69/186, train_loss: 0.1480\n",
            "70/186, train_loss: 0.8667\n",
            "71/186, train_loss: 0.3457\n",
            "72/186, train_loss: 0.1517\n",
            "73/186, train_loss: 0.0900\n",
            "74/186, train_loss: 0.1263\n",
            "75/186, train_loss: 0.0119\n",
            "76/186, train_loss: 0.2068\n",
            "77/186, train_loss: 0.7643\n",
            "78/186, train_loss: 0.1211\n",
            "79/186, train_loss: 0.5440\n",
            "80/186, train_loss: 0.1860\n",
            "81/186, train_loss: 0.9200\n",
            "82/186, train_loss: 0.9738\n",
            "83/186, train_loss: 0.0778\n",
            "84/186, train_loss: 0.0092\n",
            "85/186, train_loss: 0.0166\n",
            "86/186, train_loss: 0.7172\n",
            "87/186, train_loss: 0.9537\n",
            "88/186, train_loss: 0.0142\n",
            "89/186, train_loss: 0.0102\n",
            "90/186, train_loss: 1.0867\n",
            "91/186, train_loss: 0.0262\n",
            "92/186, train_loss: 0.1060\n",
            "93/186, train_loss: 0.0820\n",
            "94/186, train_loss: 0.0670\n",
            "95/186, train_loss: 0.2536\n",
            "96/186, train_loss: 0.1320\n",
            "97/186, train_loss: 0.0770\n",
            "98/186, train_loss: 0.1371\n",
            "99/186, train_loss: 0.2309\n",
            "100/186, train_loss: 0.0788\n",
            "101/186, train_loss: 0.5994\n",
            "102/186, train_loss: 0.1064\n",
            "103/186, train_loss: 0.0095\n",
            "104/186, train_loss: 0.0749\n",
            "105/186, train_loss: 0.0225\n",
            "106/186, train_loss: 0.0958\n",
            "107/186, train_loss: 0.0463\n",
            "108/186, train_loss: 0.8332\n",
            "109/186, train_loss: 0.0606\n",
            "110/186, train_loss: 0.0400\n",
            "111/186, train_loss: 0.0579\n",
            "112/186, train_loss: 0.6639\n",
            "113/186, train_loss: 0.6171\n",
            "114/186, train_loss: 0.0226\n",
            "115/186, train_loss: 0.5829\n",
            "116/186, train_loss: 0.7894\n",
            "117/186, train_loss: 0.0085\n",
            "118/186, train_loss: 0.0188\n",
            "119/186, train_loss: 0.0090\n",
            "120/186, train_loss: 0.0040\n",
            "121/186, train_loss: 0.0200\n",
            "122/186, train_loss: 0.0221\n",
            "123/186, train_loss: 0.0873\n",
            "124/186, train_loss: 0.0518\n",
            "125/186, train_loss: 0.0597\n",
            "126/186, train_loss: 0.7056\n",
            "127/186, train_loss: 0.0041\n",
            "128/186, train_loss: 0.6949\n",
            "129/186, train_loss: 0.0060\n",
            "130/186, train_loss: 0.3896\n",
            "131/186, train_loss: 0.2392\n",
            "132/186, train_loss: 0.0119\n",
            "133/186, train_loss: 0.0083\n",
            "134/186, train_loss: 0.0240\n",
            "135/186, train_loss: 0.1276\n",
            "136/186, train_loss: 0.1003\n",
            "137/186, train_loss: 0.1233\n",
            "138/186, train_loss: 0.0117\n",
            "139/186, train_loss: 0.0122\n",
            "140/186, train_loss: 0.1433\n",
            "141/186, train_loss: 0.0125\n",
            "142/186, train_loss: 0.0117\n",
            "143/186, train_loss: 0.0025\n",
            "144/186, train_loss: 0.0025\n",
            "145/186, train_loss: 0.1568\n",
            "146/186, train_loss: 0.2561\n",
            "147/186, train_loss: 0.5330\n",
            "148/186, train_loss: 0.1071\n",
            "149/186, train_loss: 0.7359\n",
            "150/186, train_loss: 0.1255\n",
            "151/186, train_loss: 0.4793\n",
            "152/186, train_loss: 0.0051\n",
            "153/186, train_loss: 1.3736\n",
            "154/186, train_loss: 0.0413\n",
            "155/186, train_loss: 0.0253\n",
            "156/186, train_loss: 0.1723\n",
            "157/186, train_loss: 0.0118\n",
            "158/186, train_loss: 0.0618\n",
            "159/186, train_loss: 0.2636\n",
            "160/186, train_loss: 1.1708\n",
            "161/186, train_loss: 0.1088\n",
            "162/186, train_loss: 0.0348\n",
            "163/186, train_loss: 0.9276\n",
            "164/186, train_loss: 0.5727\n",
            "165/186, train_loss: 0.0602\n",
            "166/186, train_loss: 0.0282\n",
            "167/186, train_loss: 0.0628\n",
            "168/186, train_loss: 0.3221\n",
            "169/186, train_loss: 0.0819\n",
            "170/186, train_loss: 0.0609\n",
            "171/186, train_loss: 0.1151\n",
            "172/186, train_loss: 0.0884\n",
            "173/186, train_loss: 0.0898\n",
            "174/186, train_loss: 0.0170\n",
            "175/186, train_loss: 0.0192\n",
            "176/186, train_loss: 0.0602\n",
            "177/186, train_loss: 0.0996\n",
            "178/186, train_loss: 0.1975\n",
            "179/186, train_loss: 0.1287\n",
            "180/186, train_loss: 0.0381\n",
            "181/186, train_loss: 0.4797\n",
            "182/186, train_loss: 0.0097\n",
            "183/186, train_loss: 0.1536\n",
            "184/186, train_loss: 0.6517\n",
            "185/186, train_loss: 0.1106\n",
            "186/186, train_loss: 0.0835\n",
            "epoch 15 average loss: 0.2609\n",
            "----------\n",
            "epoch 16/50\n",
            "1/186, train_loss: 0.1931\n",
            "2/186, train_loss: 0.0147\n",
            "3/186, train_loss: 0.7088\n",
            "4/186, train_loss: 0.0202\n",
            "5/186, train_loss: 0.0834\n",
            "6/186, train_loss: 0.0109\n",
            "7/186, train_loss: 0.0628\n",
            "8/186, train_loss: 0.0148\n",
            "9/186, train_loss: 0.0363\n",
            "10/186, train_loss: 0.0245\n",
            "11/186, train_loss: 0.0182\n",
            "12/186, train_loss: 0.8967\n",
            "13/186, train_loss: 0.7959\n",
            "14/186, train_loss: 0.0888\n",
            "15/186, train_loss: 0.1291\n",
            "16/186, train_loss: 0.0135\n",
            "17/186, train_loss: 0.0196\n",
            "18/186, train_loss: 0.0197\n",
            "19/186, train_loss: 0.4620\n",
            "20/186, train_loss: 0.0785\n",
            "21/186, train_loss: 0.5440\n",
            "22/186, train_loss: 0.0235\n",
            "23/186, train_loss: 0.2635\n",
            "24/186, train_loss: 0.7548\n",
            "25/186, train_loss: 0.0040\n",
            "26/186, train_loss: 0.0812\n",
            "27/186, train_loss: 0.0119\n",
            "28/186, train_loss: 0.2916\n",
            "29/186, train_loss: 0.0831\n",
            "30/186, train_loss: 0.1977\n",
            "31/186, train_loss: 0.2729\n",
            "32/186, train_loss: 0.0206\n",
            "33/186, train_loss: 0.0087\n",
            "34/186, train_loss: 0.3544\n",
            "35/186, train_loss: 2.0909\n",
            "36/186, train_loss: 0.0366\n",
            "37/186, train_loss: 0.0509\n",
            "38/186, train_loss: 0.1015\n",
            "39/186, train_loss: 0.7564\n",
            "40/186, train_loss: 0.0759\n",
            "41/186, train_loss: 0.7608\n",
            "42/186, train_loss: 0.0740\n",
            "43/186, train_loss: 0.1179\n",
            "44/186, train_loss: 0.0494\n",
            "45/186, train_loss: 0.0708\n",
            "46/186, train_loss: 0.0187\n",
            "47/186, train_loss: 0.0365\n",
            "48/186, train_loss: 0.7962\n",
            "49/186, train_loss: 0.0028\n",
            "50/186, train_loss: 0.0250\n",
            "51/186, train_loss: 0.7646\n",
            "52/186, train_loss: 0.3502\n",
            "53/186, train_loss: 0.0675\n",
            "54/186, train_loss: 0.0396\n",
            "55/186, train_loss: 0.0128\n",
            "56/186, train_loss: 0.0351\n",
            "57/186, train_loss: 0.0073\n",
            "58/186, train_loss: 0.7583\n",
            "59/186, train_loss: 0.0154\n",
            "60/186, train_loss: 0.2483\n",
            "61/186, train_loss: 0.7482\n",
            "62/186, train_loss: 0.0087\n",
            "63/186, train_loss: 0.0116\n",
            "64/186, train_loss: 0.2112\n",
            "65/186, train_loss: 0.0744\n",
            "66/186, train_loss: 0.0633\n",
            "67/186, train_loss: 0.8554\n",
            "68/186, train_loss: 2.4151\n",
            "69/186, train_loss: 0.1754\n",
            "70/186, train_loss: 0.0933\n",
            "71/186, train_loss: 0.0149\n",
            "72/186, train_loss: 0.0595\n",
            "73/186, train_loss: 0.0124\n",
            "74/186, train_loss: 0.0744\n",
            "75/186, train_loss: 0.1394\n",
            "76/186, train_loss: 0.0482\n",
            "77/186, train_loss: 0.2370\n",
            "78/186, train_loss: 0.0741\n",
            "79/186, train_loss: 1.2528\n",
            "80/186, train_loss: 0.0180\n",
            "81/186, train_loss: 1.4979\n",
            "82/186, train_loss: 0.4288\n",
            "83/186, train_loss: 0.0980\n",
            "84/186, train_loss: 0.1174\n",
            "85/186, train_loss: 0.1268\n",
            "86/186, train_loss: 1.4443\n",
            "87/186, train_loss: 0.0181\n",
            "88/186, train_loss: 0.0254\n",
            "89/186, train_loss: 0.0735\n",
            "90/186, train_loss: 0.0308\n",
            "91/186, train_loss: 0.1398\n",
            "92/186, train_loss: 0.1494\n",
            "93/186, train_loss: 0.0982\n",
            "94/186, train_loss: 0.8687\n",
            "95/186, train_loss: 0.1505\n",
            "96/186, train_loss: 0.3169\n",
            "97/186, train_loss: 0.0913\n",
            "98/186, train_loss: 0.0240\n",
            "99/186, train_loss: 0.1350\n",
            "100/186, train_loss: 1.7261\n",
            "101/186, train_loss: 0.6049\n",
            "102/186, train_loss: 0.0718\n",
            "103/186, train_loss: 0.7072\n",
            "104/186, train_loss: 1.0214\n",
            "105/186, train_loss: 0.7104\n",
            "106/186, train_loss: 1.2036\n",
            "107/186, train_loss: 0.0936\n",
            "108/186, train_loss: 0.0926\n",
            "109/186, train_loss: 0.0420\n",
            "110/186, train_loss: 0.7580\n",
            "111/186, train_loss: 0.1162\n",
            "112/186, train_loss: 0.1292\n",
            "113/186, train_loss: 0.0216\n",
            "114/186, train_loss: 0.2271\n",
            "115/186, train_loss: 0.2841\n",
            "116/186, train_loss: 0.6733\n",
            "117/186, train_loss: 0.1186\n",
            "118/186, train_loss: 0.0851\n",
            "119/186, train_loss: 0.0797\n",
            "120/186, train_loss: 0.0511\n",
            "121/186, train_loss: 0.0352\n",
            "122/186, train_loss: 0.0729\n",
            "123/186, train_loss: 0.0139\n",
            "124/186, train_loss: 0.0419\n",
            "125/186, train_loss: 0.0177\n",
            "126/186, train_loss: 0.8042\n",
            "127/186, train_loss: 0.4852\n",
            "128/186, train_loss: 0.1437\n",
            "129/186, train_loss: 0.0099\n",
            "130/186, train_loss: 0.6906\n",
            "131/186, train_loss: 0.0908\n",
            "132/186, train_loss: 0.1130\n",
            "133/186, train_loss: 0.1228\n",
            "134/186, train_loss: 0.0339\n",
            "135/186, train_loss: 0.0621\n",
            "136/186, train_loss: 0.0375\n",
            "137/186, train_loss: 0.1360\n",
            "138/186, train_loss: 0.0753\n",
            "139/186, train_loss: 0.0835\n",
            "140/186, train_loss: 0.0094\n",
            "141/186, train_loss: 0.1213\n",
            "142/186, train_loss: 0.2144\n",
            "143/186, train_loss: 0.0172\n",
            "144/186, train_loss: 0.0744\n",
            "145/186, train_loss: 0.0202\n",
            "146/186, train_loss: 0.0153\n",
            "147/186, train_loss: 0.3862\n",
            "148/186, train_loss: 0.0505\n",
            "149/186, train_loss: 0.0284\n",
            "150/186, train_loss: 0.0133\n",
            "151/186, train_loss: 0.3961\n",
            "152/186, train_loss: 0.0222\n",
            "153/186, train_loss: 0.5728\n",
            "154/186, train_loss: 0.2582\n",
            "155/186, train_loss: 0.1061\n",
            "156/186, train_loss: 0.0921\n",
            "157/186, train_loss: 0.1419\n",
            "158/186, train_loss: 0.0675\n",
            "159/186, train_loss: 0.1597\n",
            "160/186, train_loss: 0.1260\n",
            "161/186, train_loss: 0.0545\n",
            "162/186, train_loss: 0.0767\n",
            "163/186, train_loss: 0.0765\n",
            "164/186, train_loss: 0.0596\n",
            "165/186, train_loss: 0.0049\n",
            "166/186, train_loss: 0.9125\n",
            "167/186, train_loss: 0.2412\n",
            "168/186, train_loss: 0.7868\n",
            "169/186, train_loss: 0.7204\n",
            "170/186, train_loss: 0.1096\n",
            "171/186, train_loss: 0.0392\n",
            "172/186, train_loss: 0.0603\n",
            "173/186, train_loss: 0.0751\n",
            "174/186, train_loss: 0.0881\n",
            "175/186, train_loss: 0.0711\n",
            "176/186, train_loss: 0.5473\n",
            "177/186, train_loss: 0.0892\n",
            "178/186, train_loss: 1.1865\n",
            "179/186, train_loss: 0.0227\n",
            "180/186, train_loss: 0.0245\n",
            "181/186, train_loss: 0.0628\n",
            "182/186, train_loss: 0.0244\n",
            "183/186, train_loss: 0.0247\n",
            "184/186, train_loss: 1.7709\n",
            "185/186, train_loss: 0.0760\n",
            "186/186, train_loss: 0.1237\n",
            "epoch 16 average loss: 0.2608\n",
            "current epoch: 16 current accuracy: 0.7634 best accuracy: 0.8817 at epoch 8\n",
            "----------\n",
            "epoch 17/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/186, train_loss: 1.0131\n",
            "2/186, train_loss: 0.0235\n",
            "3/186, train_loss: 1.3618\n",
            "4/186, train_loss: 0.0110\n",
            "5/186, train_loss: 0.0592\n",
            "6/186, train_loss: 0.0068\n",
            "7/186, train_loss: 0.1487\n",
            "8/186, train_loss: 0.0842\n",
            "9/186, train_loss: 0.0583\n",
            "10/186, train_loss: 0.6620\n",
            "11/186, train_loss: 0.1275\n",
            "12/186, train_loss: 0.0271\n",
            "13/186, train_loss: 0.0941\n",
            "14/186, train_loss: 0.3353\n",
            "15/186, train_loss: 0.3630\n",
            "16/186, train_loss: 0.0413\n",
            "17/186, train_loss: 0.0280\n",
            "18/186, train_loss: 0.2860\n",
            "19/186, train_loss: 0.1655\n",
            "20/186, train_loss: 0.0405\n",
            "21/186, train_loss: 0.3003\n",
            "22/186, train_loss: 0.1822\n",
            "23/186, train_loss: 0.0615\n",
            "24/186, train_loss: 0.0941\n",
            "25/186, train_loss: 0.0492\n",
            "26/186, train_loss: 0.0136\n",
            "27/186, train_loss: 0.0201\n",
            "28/186, train_loss: 0.2782\n",
            "29/186, train_loss: 0.4848\n",
            "30/186, train_loss: 0.0161\n",
            "31/186, train_loss: 0.0096\n",
            "32/186, train_loss: 0.0104\n",
            "33/186, train_loss: 0.0043\n",
            "34/186, train_loss: 0.8529\n",
            "35/186, train_loss: 0.0776\n",
            "36/186, train_loss: 0.0619\n",
            "37/186, train_loss: 0.0934\n",
            "38/186, train_loss: 0.0597\n",
            "39/186, train_loss: 0.2406\n",
            "40/186, train_loss: 0.0225\n",
            "41/186, train_loss: 0.1712\n",
            "42/186, train_loss: 0.0068\n",
            "43/186, train_loss: 0.0023\n",
            "44/186, train_loss: 0.3165\n",
            "45/186, train_loss: 0.0128\n",
            "46/186, train_loss: 0.0235\n",
            "47/186, train_loss: 0.0032\n",
            "48/186, train_loss: 0.0053\n",
            "49/186, train_loss: 0.1160\n",
            "50/186, train_loss: 0.9774\n",
            "51/186, train_loss: 0.4680\n",
            "52/186, train_loss: 0.0675\n",
            "53/186, train_loss: 0.0695\n",
            "54/186, train_loss: 0.0815\n",
            "55/186, train_loss: 0.0212\n",
            "56/186, train_loss: 0.5379\n",
            "57/186, train_loss: 0.0214\n",
            "58/186, train_loss: 0.1526\n",
            "59/186, train_loss: 0.1177\n",
            "60/186, train_loss: 0.0260\n",
            "61/186, train_loss: 0.3006\n",
            "62/186, train_loss: 0.7900\n",
            "63/186, train_loss: 0.0105\n",
            "64/186, train_loss: 0.7120\n",
            "65/186, train_loss: 0.0706\n",
            "66/186, train_loss: 0.0393\n",
            "67/186, train_loss: 0.6411\n",
            "68/186, train_loss: 0.0013\n",
            "69/186, train_loss: 0.7145\n",
            "70/186, train_loss: 0.3198\n",
            "71/186, train_loss: 0.0023\n",
            "72/186, train_loss: 0.2301\n",
            "73/186, train_loss: 0.6001\n",
            "74/186, train_loss: 0.0152\n",
            "75/186, train_loss: 0.1276\n",
            "76/186, train_loss: 0.5157\n",
            "77/186, train_loss: 0.1156\n",
            "78/186, train_loss: 0.0029\n",
            "79/186, train_loss: 0.0177\n",
            "80/186, train_loss: 0.1730\n",
            "81/186, train_loss: 0.1560\n",
            "82/186, train_loss: 0.0689\n",
            "83/186, train_loss: 0.1202\n",
            "84/186, train_loss: 0.1097\n",
            "85/186, train_loss: 0.5382\n",
            "86/186, train_loss: 0.0044\n",
            "87/186, train_loss: 0.0610\n",
            "88/186, train_loss: 0.0139\n",
            "89/186, train_loss: 0.0021\n",
            "90/186, train_loss: 3.0366\n",
            "91/186, train_loss: 0.0163\n",
            "92/186, train_loss: 0.0040\n",
            "93/186, train_loss: 0.0337\n",
            "94/186, train_loss: 0.1398\n",
            "95/186, train_loss: 2.8315\n",
            "96/186, train_loss: 0.0134\n",
            "97/186, train_loss: 0.0702\n",
            "98/186, train_loss: 0.0097\n",
            "99/186, train_loss: 0.0076\n",
            "100/186, train_loss: 0.0108\n",
            "101/186, train_loss: 0.0645\n",
            "102/186, train_loss: 0.0727\n",
            "103/186, train_loss: 0.8001\n",
            "104/186, train_loss: 0.1226\n",
            "105/186, train_loss: 0.0811\n",
            "106/186, train_loss: 0.1098\n",
            "107/186, train_loss: 0.1048\n",
            "108/186, train_loss: 0.1219\n",
            "109/186, train_loss: 0.0302\n",
            "110/186, train_loss: 0.0372\n",
            "111/186, train_loss: 0.0205\n",
            "112/186, train_loss: 0.8203\n",
            "113/186, train_loss: 0.0595\n",
            "114/186, train_loss: 0.1415\n",
            "115/186, train_loss: 0.0111\n",
            "116/186, train_loss: 0.0574\n",
            "117/186, train_loss: 0.0933\n",
            "118/186, train_loss: 0.0114\n",
            "119/186, train_loss: 0.3011\n",
            "120/186, train_loss: 0.0703\n",
            "121/186, train_loss: 0.1931\n",
            "122/186, train_loss: 0.1411\n",
            "123/186, train_loss: 0.1035\n",
            "124/186, train_loss: 0.1316\n",
            "125/186, train_loss: 0.0887\n",
            "126/186, train_loss: 0.7671\n",
            "127/186, train_loss: 0.0088\n",
            "128/186, train_loss: 0.0144\n",
            "129/186, train_loss: 0.0111\n",
            "130/186, train_loss: 0.1300\n",
            "131/186, train_loss: 0.7884\n",
            "132/186, train_loss: 0.1285\n",
            "133/186, train_loss: 0.2779\n",
            "134/186, train_loss: 0.1067\n",
            "135/186, train_loss: 0.1050\n",
            "136/186, train_loss: 0.0408\n",
            "137/186, train_loss: 1.0358\n",
            "138/186, train_loss: 0.5696\n",
            "139/186, train_loss: 0.0719\n",
            "140/186, train_loss: 0.8523\n",
            "141/186, train_loss: 0.0460\n",
            "142/186, train_loss: 0.5360\n",
            "143/186, train_loss: 0.8156\n",
            "144/186, train_loss: 0.3590\n",
            "145/186, train_loss: 0.2685\n",
            "146/186, train_loss: 0.0192\n",
            "147/186, train_loss: 0.0815\n",
            "148/186, train_loss: 0.0218\n",
            "149/186, train_loss: 0.0060\n",
            "150/186, train_loss: 0.1241\n",
            "151/186, train_loss: 0.0214\n",
            "152/186, train_loss: 0.1113\n",
            "153/186, train_loss: 0.0625\n",
            "154/186, train_loss: 0.6496\n",
            "155/186, train_loss: 0.1208\n",
            "156/186, train_loss: 0.6721\n",
            "157/186, train_loss: 0.6794\n",
            "158/186, train_loss: 0.0125\n",
            "159/186, train_loss: 0.6794\n",
            "160/186, train_loss: 0.0716\n",
            "161/186, train_loss: 0.0186\n",
            "162/186, train_loss: 0.2431\n",
            "163/186, train_loss: 0.6835\n",
            "164/186, train_loss: 0.0695\n",
            "165/186, train_loss: 0.0812\n",
            "166/186, train_loss: 0.2271\n",
            "167/186, train_loss: 0.0588\n",
            "168/186, train_loss: 0.0684\n",
            "169/186, train_loss: 0.0586\n",
            "170/186, train_loss: 0.0069\n",
            "171/186, train_loss: 0.0360\n",
            "172/186, train_loss: 0.1665\n",
            "173/186, train_loss: 0.0149\n",
            "174/186, train_loss: 0.0145\n",
            "175/186, train_loss: 0.2874\n",
            "176/186, train_loss: 0.0052\n",
            "177/186, train_loss: 0.1386\n",
            "178/186, train_loss: 1.2056\n",
            "179/186, train_loss: 0.2044\n",
            "180/186, train_loss: 0.4302\n",
            "181/186, train_loss: 0.0950\n",
            "182/186, train_loss: 0.0221\n",
            "183/186, train_loss: 0.1313\n",
            "184/186, train_loss: 0.0152\n",
            "185/186, train_loss: 0.7388\n",
            "186/186, train_loss: 0.1323\n",
            "epoch 17 average loss: 0.2308\n",
            "----------\n",
            "epoch 18/50\n",
            "1/186, train_loss: 0.1302\n",
            "2/186, train_loss: 0.0118\n",
            "3/186, train_loss: 0.0075\n",
            "4/186, train_loss: 0.0096\n",
            "5/186, train_loss: 0.0056\n",
            "6/186, train_loss: 0.1496\n",
            "7/186, train_loss: 0.1427\n",
            "8/186, train_loss: 0.8607\n",
            "9/186, train_loss: 0.0858\n",
            "10/186, train_loss: 0.1121\n",
            "11/186, train_loss: 0.0191\n",
            "12/186, train_loss: 0.0924\n",
            "13/186, train_loss: 0.0362\n",
            "14/186, train_loss: 0.1130\n",
            "15/186, train_loss: 0.1325\n",
            "16/186, train_loss: 0.0904\n",
            "17/186, train_loss: 0.0182\n",
            "18/186, train_loss: 0.0617\n",
            "19/186, train_loss: 0.0193\n",
            "20/186, train_loss: 0.7286\n",
            "21/186, train_loss: 0.0709\n",
            "22/186, train_loss: 0.0909\n",
            "23/186, train_loss: 0.1250\n",
            "24/186, train_loss: 0.0539\n",
            "25/186, train_loss: 0.8811\n",
            "26/186, train_loss: 0.0239\n",
            "27/186, train_loss: 0.4094\n",
            "28/186, train_loss: 0.1007\n",
            "29/186, train_loss: 0.0619\n",
            "30/186, train_loss: 0.0202\n",
            "31/186, train_loss: 0.0236\n",
            "32/186, train_loss: 0.0219\n",
            "33/186, train_loss: 0.1154\n",
            "34/186, train_loss: 0.0062\n",
            "35/186, train_loss: 0.0145\n",
            "36/186, train_loss: 0.0817\n",
            "37/186, train_loss: 0.0669\n",
            "38/186, train_loss: 2.7932\n",
            "39/186, train_loss: 0.0863\n",
            "40/186, train_loss: 0.0336\n",
            "41/186, train_loss: 0.0200\n",
            "42/186, train_loss: 0.1090\n",
            "43/186, train_loss: 0.0352\n",
            "44/186, train_loss: 0.0376\n",
            "45/186, train_loss: 0.0644\n",
            "46/186, train_loss: 0.0667\n",
            "47/186, train_loss: 0.0281\n",
            "48/186, train_loss: 0.0235\n",
            "49/186, train_loss: 0.0104\n",
            "50/186, train_loss: 0.0066\n",
            "51/186, train_loss: 0.0204\n",
            "52/186, train_loss: 0.0280\n",
            "53/186, train_loss: 0.1069\n",
            "54/186, train_loss: 0.8275\n",
            "55/186, train_loss: 0.0110\n",
            "56/186, train_loss: 0.1630\n",
            "57/186, train_loss: 0.6182\n",
            "58/186, train_loss: 0.0231\n",
            "59/186, train_loss: 0.1274\n",
            "60/186, train_loss: 0.0594\n",
            "61/186, train_loss: 0.0040\n",
            "62/186, train_loss: 0.0611\n",
            "63/186, train_loss: 0.6629\n",
            "64/186, train_loss: 0.1698\n",
            "65/186, train_loss: 0.0152\n",
            "66/186, train_loss: 0.9140\n",
            "67/186, train_loss: 0.0170\n",
            "68/186, train_loss: 0.4952\n",
            "69/186, train_loss: 0.5995\n",
            "70/186, train_loss: 0.6815\n",
            "71/186, train_loss: 0.8055\n",
            "72/186, train_loss: 0.0742\n",
            "73/186, train_loss: 0.0402\n",
            "74/186, train_loss: 0.0696\n",
            "75/186, train_loss: 0.0801\n",
            "76/186, train_loss: 0.0446\n",
            "77/186, train_loss: 0.0056\n",
            "78/186, train_loss: 1.0308\n",
            "79/186, train_loss: 0.0123\n",
            "80/186, train_loss: 0.1879\n",
            "81/186, train_loss: 0.1059\n",
            "82/186, train_loss: 0.1866\n",
            "83/186, train_loss: 0.5604\n",
            "84/186, train_loss: 0.0353\n",
            "85/186, train_loss: 0.1248\n",
            "86/186, train_loss: 0.3252\n",
            "87/186, train_loss: 0.0219\n",
            "88/186, train_loss: 0.0626\n",
            "89/186, train_loss: 0.0073\n",
            "90/186, train_loss: 0.6276\n",
            "91/186, train_loss: 1.0658\n",
            "92/186, train_loss: 0.3911\n",
            "93/186, train_loss: 0.0740\n",
            "94/186, train_loss: 0.0350\n",
            "95/186, train_loss: 0.0528\n",
            "96/186, train_loss: 0.0549\n",
            "97/186, train_loss: 0.6838\n",
            "98/186, train_loss: 0.0264\n",
            "99/186, train_loss: 0.0735\n",
            "100/186, train_loss: 0.6989\n",
            "101/186, train_loss: 1.7221\n",
            "102/186, train_loss: 0.0344\n",
            "103/186, train_loss: 0.0949\n",
            "104/186, train_loss: 0.0781\n",
            "105/186, train_loss: 0.3214\n",
            "106/186, train_loss: 0.0900\n",
            "107/186, train_loss: 0.2465\n",
            "108/186, train_loss: 1.0118\n",
            "109/186, train_loss: 0.2764\n",
            "110/186, train_loss: 0.0249\n",
            "111/186, train_loss: 0.0638\n",
            "112/186, train_loss: 0.0627\n",
            "113/186, train_loss: 0.0123\n",
            "114/186, train_loss: 0.0749\n",
            "115/186, train_loss: 0.8251\n",
            "116/186, train_loss: 0.0439\n",
            "117/186, train_loss: 0.1374\n",
            "118/186, train_loss: 0.4824\n",
            "119/186, train_loss: 0.1054\n",
            "120/186, train_loss: 0.0410\n",
            "121/186, train_loss: 0.0653\n",
            "122/186, train_loss: 0.0526\n",
            "123/186, train_loss: 0.2340\n",
            "124/186, train_loss: 0.0078\n",
            "125/186, train_loss: 0.0056\n",
            "126/186, train_loss: 0.0579\n",
            "127/186, train_loss: 0.0998\n",
            "128/186, train_loss: 0.0076\n",
            "129/186, train_loss: 0.0845\n",
            "130/186, train_loss: 0.0380\n",
            "131/186, train_loss: 0.1035\n",
            "132/186, train_loss: 0.2163\n",
            "133/186, train_loss: 0.0762\n",
            "134/186, train_loss: 0.0185\n",
            "135/186, train_loss: 0.0103\n",
            "136/186, train_loss: 0.1408\n",
            "137/186, train_loss: 0.0316\n",
            "138/186, train_loss: 0.0070\n",
            "139/186, train_loss: 0.0560\n",
            "140/186, train_loss: 0.0120\n",
            "141/186, train_loss: 0.4260\n",
            "142/186, train_loss: 0.6356\n",
            "143/186, train_loss: 0.0581\n",
            "144/186, train_loss: 0.0760\n",
            "145/186, train_loss: 0.1665\n",
            "146/186, train_loss: 0.0052\n",
            "147/186, train_loss: 0.0211\n",
            "148/186, train_loss: 0.0775\n",
            "149/186, train_loss: 0.0681\n",
            "150/186, train_loss: 0.0581\n",
            "151/186, train_loss: 0.9981\n",
            "152/186, train_loss: 0.5774\n",
            "153/186, train_loss: 0.2270\n",
            "154/186, train_loss: 0.0592\n",
            "155/186, train_loss: 0.1784\n",
            "156/186, train_loss: 0.6694\n",
            "157/186, train_loss: 0.0036\n",
            "158/186, train_loss: 0.0963\n",
            "159/186, train_loss: 0.1110\n",
            "160/186, train_loss: 0.0117\n",
            "161/186, train_loss: 0.0242\n",
            "162/186, train_loss: 0.0809\n",
            "163/186, train_loss: 0.0579\n",
            "164/186, train_loss: 1.2779\n",
            "165/186, train_loss: 0.0194\n",
            "166/186, train_loss: 0.0162\n",
            "167/186, train_loss: 2.5059\n",
            "168/186, train_loss: 0.3271\n",
            "169/186, train_loss: 0.0046\n",
            "170/186, train_loss: 0.0213\n",
            "171/186, train_loss: 0.1129\n",
            "172/186, train_loss: 0.0152\n",
            "173/186, train_loss: 0.3105\n",
            "174/186, train_loss: 0.6977\n",
            "175/186, train_loss: 0.6511\n",
            "176/186, train_loss: 0.0133\n",
            "177/186, train_loss: 0.0761\n",
            "178/186, train_loss: 0.3365\n",
            "179/186, train_loss: 0.3317\n",
            "180/186, train_loss: 0.1396\n",
            "181/186, train_loss: 0.0337\n",
            "182/186, train_loss: 0.0652\n",
            "183/186, train_loss: 0.0389\n",
            "184/186, train_loss: 0.8374\n",
            "185/186, train_loss: 0.6208\n",
            "186/186, train_loss: 0.0863\n",
            "epoch 18 average loss: 0.2246\n",
            "current epoch: 18 current accuracy: 0.8065 best accuracy: 0.8817 at epoch 8\n",
            "----------\n",
            "epoch 19/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/186, train_loss: 0.2366\n",
            "2/186, train_loss: 0.0630\n",
            "3/186, train_loss: 0.5523\n",
            "4/186, train_loss: 0.0675\n",
            "5/186, train_loss: 0.0694\n",
            "6/186, train_loss: 0.3692\n",
            "7/186, train_loss: 0.1000\n",
            "8/186, train_loss: 0.6864\n",
            "9/186, train_loss: 0.0249\n",
            "10/186, train_loss: 0.0210\n",
            "11/186, train_loss: 0.6834\n",
            "12/186, train_loss: 0.0260\n",
            "13/186, train_loss: 0.0887\n",
            "14/186, train_loss: 0.6843\n",
            "15/186, train_loss: 0.0474\n",
            "16/186, train_loss: 0.0902\n",
            "17/186, train_loss: 0.0367\n",
            "18/186, train_loss: 0.6548\n",
            "19/186, train_loss: 0.3166\n",
            "20/186, train_loss: 0.0533\n",
            "21/186, train_loss: 0.2157\n",
            "22/186, train_loss: 0.0278\n",
            "23/186, train_loss: 0.0581\n",
            "24/186, train_loss: 0.0825\n",
            "25/186, train_loss: 0.0675\n",
            "26/186, train_loss: 0.0805\n",
            "27/186, train_loss: 0.7418\n",
            "28/186, train_loss: 0.1013\n",
            "29/186, train_loss: 0.2562\n",
            "30/186, train_loss: 0.0158\n",
            "31/186, train_loss: 0.0599\n",
            "32/186, train_loss: 0.0271\n",
            "33/186, train_loss: 0.1074\n",
            "34/186, train_loss: 0.0882\n",
            "35/186, train_loss: 1.0230\n",
            "36/186, train_loss: 0.0134\n",
            "37/186, train_loss: 0.0131\n",
            "38/186, train_loss: 0.0179\n",
            "39/186, train_loss: 0.2502\n",
            "40/186, train_loss: 0.4125\n",
            "41/186, train_loss: 0.0278\n",
            "42/186, train_loss: 0.0777\n",
            "43/186, train_loss: 0.1743\n",
            "44/186, train_loss: 0.8077\n",
            "45/186, train_loss: 0.0510\n",
            "46/186, train_loss: 0.8844\n",
            "47/186, train_loss: 0.5589\n",
            "48/186, train_loss: 0.0563\n",
            "49/186, train_loss: 0.6892\n",
            "50/186, train_loss: 0.0369\n",
            "51/186, train_loss: 0.2700\n",
            "52/186, train_loss: 0.0651\n",
            "53/186, train_loss: 0.0796\n",
            "54/186, train_loss: 0.0518\n",
            "55/186, train_loss: 0.0476\n",
            "56/186, train_loss: 0.5855\n",
            "57/186, train_loss: 0.0240\n",
            "58/186, train_loss: 0.0767\n",
            "59/186, train_loss: 0.0792\n",
            "60/186, train_loss: 0.1917\n",
            "61/186, train_loss: 0.0463\n",
            "62/186, train_loss: 0.6951\n",
            "63/186, train_loss: 0.0243\n",
            "64/186, train_loss: 0.0894\n",
            "65/186, train_loss: 0.0533\n",
            "66/186, train_loss: 0.0100\n",
            "67/186, train_loss: 0.0192\n",
            "68/186, train_loss: 0.0058\n",
            "69/186, train_loss: 0.0391\n",
            "70/186, train_loss: 0.1673\n",
            "71/186, train_loss: 0.0306\n",
            "72/186, train_loss: 0.3233\n",
            "73/186, train_loss: 0.3595\n",
            "74/186, train_loss: 0.0233\n",
            "75/186, train_loss: 0.1221\n",
            "76/186, train_loss: 0.0497\n",
            "77/186, train_loss: 0.0152\n",
            "78/186, train_loss: 0.6376\n",
            "79/186, train_loss: 0.0048\n",
            "80/186, train_loss: 0.0658\n",
            "81/186, train_loss: 0.1199\n",
            "82/186, train_loss: 0.0114\n",
            "83/186, train_loss: 0.1635\n",
            "84/186, train_loss: 0.1206\n",
            "85/186, train_loss: 0.0598\n",
            "86/186, train_loss: 0.6469\n",
            "87/186, train_loss: 0.0199\n",
            "88/186, train_loss: 0.0876\n",
            "89/186, train_loss: 0.0240\n",
            "90/186, train_loss: 0.0054\n",
            "91/186, train_loss: 0.0371\n",
            "92/186, train_loss: 1.1137\n",
            "93/186, train_loss: 0.0118\n",
            "94/186, train_loss: 0.0531\n",
            "95/186, train_loss: 0.0076\n",
            "96/186, train_loss: 0.2649\n",
            "97/186, train_loss: 0.9893\n",
            "98/186, train_loss: 0.0378\n",
            "99/186, train_loss: 0.9944\n",
            "100/186, train_loss: 0.5119\n",
            "101/186, train_loss: 0.0027\n",
            "102/186, train_loss: 0.0697\n",
            "103/186, train_loss: 0.0136\n",
            "104/186, train_loss: 0.0159\n",
            "105/186, train_loss: 0.0114\n",
            "106/186, train_loss: 0.0756\n",
            "107/186, train_loss: 0.0757\n",
            "108/186, train_loss: 0.7213\n",
            "109/186, train_loss: 0.0724\n",
            "110/186, train_loss: 0.6754\n",
            "111/186, train_loss: 0.5043\n",
            "112/186, train_loss: 0.1829\n",
            "113/186, train_loss: 0.0202\n",
            "114/186, train_loss: 0.1522\n",
            "115/186, train_loss: 0.0612\n",
            "116/186, train_loss: 0.0129\n",
            "117/186, train_loss: 0.0954\n",
            "118/186, train_loss: 0.0039\n",
            "119/186, train_loss: 0.5949\n",
            "120/186, train_loss: 0.5927\n",
            "121/186, train_loss: 0.0249\n",
            "122/186, train_loss: 0.1160\n",
            "123/186, train_loss: 2.5491\n",
            "124/186, train_loss: 0.0082\n",
            "125/186, train_loss: 0.3252\n",
            "126/186, train_loss: 0.0222\n",
            "127/186, train_loss: 0.6717\n",
            "128/186, train_loss: 0.0883\n",
            "129/186, train_loss: 0.0472\n",
            "130/186, train_loss: 0.7638\n",
            "131/186, train_loss: 0.0670\n",
            "132/186, train_loss: 0.0198\n",
            "133/186, train_loss: 1.4094\n",
            "134/186, train_loss: 0.0949\n",
            "135/186, train_loss: 0.1842\n",
            "136/186, train_loss: 0.6443\n",
            "137/186, train_loss: 0.1274\n",
            "138/186, train_loss: 0.0148\n",
            "139/186, train_loss: 0.0684\n",
            "140/186, train_loss: 0.0937\n",
            "141/186, train_loss: 0.6411\n",
            "142/186, train_loss: 0.0663\n",
            "143/186, train_loss: 1.0768\n",
            "144/186, train_loss: 0.0930\n",
            "145/186, train_loss: 0.1233\n",
            "146/186, train_loss: 0.6195\n",
            "147/186, train_loss: 0.0666\n",
            "148/186, train_loss: 0.1017\n",
            "149/186, train_loss: 0.0259\n",
            "150/186, train_loss: 0.1285\n",
            "151/186, train_loss: 0.0340\n",
            "152/186, train_loss: 0.0149\n",
            "153/186, train_loss: 0.2022\n",
            "154/186, train_loss: 0.0601\n",
            "155/186, train_loss: 0.0537\n",
            "156/186, train_loss: 0.0511\n",
            "157/186, train_loss: 0.0174\n",
            "158/186, train_loss: 0.0083\n",
            "159/186, train_loss: 0.1317\n",
            "160/186, train_loss: 0.0453\n",
            "161/186, train_loss: 0.0099\n",
            "162/186, train_loss: 0.2026\n",
            "163/186, train_loss: 0.0701\n",
            "164/186, train_loss: 0.6698\n",
            "165/186, train_loss: 0.2975\n",
            "166/186, train_loss: 0.0647\n",
            "167/186, train_loss: 0.0790\n",
            "168/186, train_loss: 0.0400\n",
            "169/186, train_loss: 0.0904\n",
            "170/186, train_loss: 0.0281\n",
            "171/186, train_loss: 0.0844\n",
            "172/186, train_loss: 0.0737\n",
            "173/186, train_loss: 0.0243\n",
            "174/186, train_loss: 0.0935\n",
            "175/186, train_loss: 0.3212\n",
            "176/186, train_loss: 0.0389\n",
            "177/186, train_loss: 0.3644\n",
            "178/186, train_loss: 0.0063\n",
            "179/186, train_loss: 0.6134\n",
            "180/186, train_loss: 1.6538\n",
            "181/186, train_loss: 0.0081\n",
            "182/186, train_loss: 0.9450\n",
            "183/186, train_loss: 0.1166\n",
            "184/186, train_loss: 0.0065\n",
            "185/186, train_loss: 0.0135\n",
            "186/186, train_loss: 0.9640\n",
            "epoch 19 average loss: 0.2321\n",
            "----------\n",
            "epoch 20/50\n",
            "1/186, train_loss: 2.4693\n",
            "2/186, train_loss: 0.9123\n",
            "3/186, train_loss: 0.0139\n",
            "4/186, train_loss: 0.0048\n",
            "5/186, train_loss: 0.0218\n",
            "6/186, train_loss: 0.0834\n",
            "7/186, train_loss: 0.3016\n",
            "8/186, train_loss: 0.1744\n",
            "9/186, train_loss: 0.6214\n",
            "10/186, train_loss: 0.0061\n",
            "11/186, train_loss: 0.0098\n",
            "12/186, train_loss: 0.1110\n",
            "13/186, train_loss: 1.6147\n",
            "14/186, train_loss: 0.0423\n",
            "15/186, train_loss: 0.2413\n",
            "16/186, train_loss: 0.0062\n",
            "17/186, train_loss: 0.0061\n",
            "18/186, train_loss: 0.0217\n",
            "19/186, train_loss: 0.6168\n",
            "20/186, train_loss: 0.0132\n",
            "21/186, train_loss: 0.7514\n",
            "22/186, train_loss: 0.5329\n",
            "23/186, train_loss: 0.2079\n",
            "24/186, train_loss: 0.0207\n",
            "25/186, train_loss: 0.3782\n",
            "26/186, train_loss: 0.5705\n",
            "27/186, train_loss: 0.0517\n",
            "28/186, train_loss: 0.1151\n",
            "29/186, train_loss: 0.0032\n",
            "30/186, train_loss: 0.0114\n",
            "31/186, train_loss: 0.3817\n",
            "32/186, train_loss: 0.0631\n",
            "33/186, train_loss: 0.0674\n",
            "34/186, train_loss: 0.0143\n",
            "35/186, train_loss: 0.0655\n",
            "36/186, train_loss: 0.2873\n",
            "37/186, train_loss: 0.7207\n",
            "38/186, train_loss: 0.2856\n",
            "39/186, train_loss: 0.0179\n",
            "40/186, train_loss: 0.0203\n",
            "41/186, train_loss: 0.0644\n",
            "42/186, train_loss: 0.1852\n",
            "43/186, train_loss: 0.6732\n",
            "44/186, train_loss: 0.0045\n",
            "45/186, train_loss: 0.5264\n",
            "46/186, train_loss: 0.0381\n",
            "47/186, train_loss: 0.1354\n",
            "48/186, train_loss: 0.0090\n",
            "49/186, train_loss: 0.0235\n",
            "50/186, train_loss: 0.0764\n",
            "51/186, train_loss: 0.1986\n",
            "52/186, train_loss: 0.0564\n",
            "53/186, train_loss: 0.2684\n",
            "54/186, train_loss: 0.0778\n",
            "55/186, train_loss: 0.0359\n",
            "56/186, train_loss: 0.0323\n",
            "57/186, train_loss: 0.0567\n",
            "58/186, train_loss: 0.0449\n",
            "59/186, train_loss: 0.0742\n",
            "60/186, train_loss: 0.0525\n",
            "61/186, train_loss: 0.0704\n",
            "62/186, train_loss: 0.0051\n",
            "63/186, train_loss: 0.0474\n",
            "64/186, train_loss: 0.1479\n",
            "65/186, train_loss: 1.0009\n",
            "66/186, train_loss: 0.0947\n",
            "67/186, train_loss: 0.0206\n",
            "68/186, train_loss: 0.0586\n",
            "69/186, train_loss: 0.0059\n",
            "70/186, train_loss: 0.0546\n",
            "71/186, train_loss: 0.0929\n",
            "72/186, train_loss: 0.0547\n",
            "73/186, train_loss: 0.1384\n",
            "74/186, train_loss: 0.0244\n",
            "75/186, train_loss: 1.2131\n",
            "76/186, train_loss: 0.0539\n",
            "77/186, train_loss: 0.1174\n",
            "78/186, train_loss: 0.0037\n",
            "79/186, train_loss: 0.8085\n",
            "80/186, train_loss: 0.0626\n",
            "81/186, train_loss: 0.2447\n",
            "82/186, train_loss: 0.0473\n",
            "83/186, train_loss: 0.4158\n",
            "84/186, train_loss: 0.6950\n",
            "85/186, train_loss: 0.1978\n",
            "86/186, train_loss: 0.0264\n",
            "87/186, train_loss: 0.3009\n",
            "88/186, train_loss: 0.0531\n",
            "89/186, train_loss: 0.0078\n",
            "90/186, train_loss: 0.3469\n",
            "91/186, train_loss: 0.0099\n",
            "92/186, train_loss: 0.0396\n",
            "93/186, train_loss: 1.1958\n",
            "94/186, train_loss: 0.0644\n",
            "95/186, train_loss: 0.0087\n",
            "96/186, train_loss: 0.2116\n",
            "97/186, train_loss: 0.2250\n",
            "98/186, train_loss: 0.0034\n",
            "99/186, train_loss: 0.0104\n",
            "100/186, train_loss: 0.6794\n",
            "101/186, train_loss: 0.1627\n",
            "102/186, train_loss: 0.0306\n",
            "103/186, train_loss: 0.0206\n",
            "104/186, train_loss: 0.0738\n",
            "105/186, train_loss: 0.0800\n",
            "106/186, train_loss: 0.6372\n",
            "107/186, train_loss: 0.2269\n",
            "108/186, train_loss: 0.0486\n",
            "109/186, train_loss: 0.9222\n",
            "110/186, train_loss: 0.1363\n",
            "111/186, train_loss: 0.5972\n",
            "112/186, train_loss: 0.0074\n",
            "113/186, train_loss: 0.2710\n",
            "114/186, train_loss: 0.0253\n",
            "115/186, train_loss: 0.0679\n",
            "116/186, train_loss: 0.7910\n",
            "117/186, train_loss: 0.0183\n",
            "118/186, train_loss: 0.0746\n",
            "119/186, train_loss: 0.0043\n",
            "120/186, train_loss: 0.0055\n",
            "121/186, train_loss: 0.0117\n",
            "122/186, train_loss: 0.0101\n",
            "123/186, train_loss: 0.0695\n",
            "124/186, train_loss: 0.0619\n",
            "125/186, train_loss: 0.0035\n",
            "126/186, train_loss: 0.0076\n",
            "127/186, train_loss: 0.1023\n",
            "128/186, train_loss: 0.6947\n",
            "129/186, train_loss: 0.0537\n",
            "130/186, train_loss: 0.0040\n",
            "131/186, train_loss: 0.0050\n",
            "132/186, train_loss: 0.1144\n",
            "133/186, train_loss: 0.0035\n",
            "134/186, train_loss: 0.1257\n",
            "135/186, train_loss: 1.0310\n",
            "136/186, train_loss: 0.4552\n",
            "137/186, train_loss: 0.0022\n",
            "138/186, train_loss: 0.2342\n",
            "139/186, train_loss: 0.1673\n",
            "140/186, train_loss: 0.0104\n",
            "141/186, train_loss: 0.2497\n",
            "142/186, train_loss: 0.0809\n",
            "143/186, train_loss: 0.5770\n",
            "144/186, train_loss: 0.5557\n",
            "145/186, train_loss: 0.1786\n",
            "146/186, train_loss: 0.0095\n",
            "147/186, train_loss: 0.0240\n",
            "148/186, train_loss: 0.0092\n",
            "149/186, train_loss: 0.0016\n",
            "150/186, train_loss: 0.0471\n",
            "151/186, train_loss: 0.0154\n",
            "152/186, train_loss: 1.2299\n",
            "153/186, train_loss: 0.0527\n",
            "154/186, train_loss: 0.0047\n",
            "155/186, train_loss: 0.0350\n",
            "156/186, train_loss: 2.0832\n",
            "157/186, train_loss: 0.0694\n",
            "158/186, train_loss: 0.0395\n",
            "159/186, train_loss: 0.0048\n",
            "160/186, train_loss: 0.0057\n",
            "161/186, train_loss: 0.0053\n",
            "162/186, train_loss: 0.0617\n",
            "163/186, train_loss: 0.6217\n",
            "164/186, train_loss: 0.5653\n",
            "165/186, train_loss: 0.8665\n",
            "166/186, train_loss: 0.0961\n",
            "167/186, train_loss: 0.0045\n",
            "168/186, train_loss: 0.1224\n",
            "169/186, train_loss: 0.0104\n",
            "170/186, train_loss: 0.0514\n",
            "171/186, train_loss: 0.0556\n",
            "172/186, train_loss: 0.6625\n",
            "173/186, train_loss: 0.2551\n",
            "174/186, train_loss: 0.0669\n",
            "175/186, train_loss: 0.9020\n",
            "176/186, train_loss: 0.0840\n",
            "177/186, train_loss: 0.6175\n",
            "178/186, train_loss: 1.0221\n",
            "179/186, train_loss: 0.1136\n",
            "180/186, train_loss: 0.0662\n",
            "181/186, train_loss: 0.1915\n",
            "182/186, train_loss: 0.0707\n",
            "183/186, train_loss: 0.0088\n",
            "184/186, train_loss: 0.2109\n",
            "185/186, train_loss: 0.0799\n",
            "186/186, train_loss: 0.4767\n",
            "epoch 20 average loss: 0.2327\n",
            "current epoch: 20 current accuracy: 0.8280 best accuracy: 0.8817 at epoch 8\n",
            "----------\n",
            "epoch 21/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/186, train_loss: 0.0043\n",
            "2/186, train_loss: 0.2962\n",
            "3/186, train_loss: 0.0465\n",
            "4/186, train_loss: 0.0083\n",
            "5/186, train_loss: 0.0258\n",
            "6/186, train_loss: 0.0076\n",
            "7/186, train_loss: 0.0770\n",
            "8/186, train_loss: 0.0614\n",
            "9/186, train_loss: 0.6980\n",
            "10/186, train_loss: 0.0223\n",
            "11/186, train_loss: 0.0643\n",
            "12/186, train_loss: 0.0071\n",
            "13/186, train_loss: 0.0749\n",
            "14/186, train_loss: 0.0281\n",
            "15/186, train_loss: 0.0073\n",
            "16/186, train_loss: 0.4741\n",
            "17/186, train_loss: 0.0117\n",
            "18/186, train_loss: 0.5393\n",
            "19/186, train_loss: 0.0082\n",
            "20/186, train_loss: 0.0026\n",
            "21/186, train_loss: 0.0026\n",
            "22/186, train_loss: 0.1062\n",
            "23/186, train_loss: 0.0538\n",
            "24/186, train_loss: 0.0091\n",
            "25/186, train_loss: 0.2737\n",
            "26/186, train_loss: 1.8477\n",
            "27/186, train_loss: 0.0212\n",
            "28/186, train_loss: 0.0119\n",
            "29/186, train_loss: 0.1051\n",
            "30/186, train_loss: 0.0972\n",
            "31/186, train_loss: 0.1143\n",
            "32/186, train_loss: 0.0481\n",
            "33/186, train_loss: 0.0029\n",
            "34/186, train_loss: 0.1495\n",
            "35/186, train_loss: 0.0651\n",
            "36/186, train_loss: 0.0966\n",
            "37/186, train_loss: 0.0227\n",
            "38/186, train_loss: 0.0917\n",
            "39/186, train_loss: 0.3974\n",
            "40/186, train_loss: 0.0972\n",
            "41/186, train_loss: 0.0188\n",
            "42/186, train_loss: 1.3004\n",
            "43/186, train_loss: 0.1248\n",
            "44/186, train_loss: 0.0228\n",
            "45/186, train_loss: 0.1021\n",
            "46/186, train_loss: 0.0062\n",
            "47/186, train_loss: 0.0254\n",
            "48/186, train_loss: 0.0774\n",
            "49/186, train_loss: 0.1209\n",
            "50/186, train_loss: 0.0328\n",
            "51/186, train_loss: 0.1182\n",
            "52/186, train_loss: 1.1626\n",
            "53/186, train_loss: 0.4993\n",
            "54/186, train_loss: 0.0855\n",
            "55/186, train_loss: 1.4868\n",
            "56/186, train_loss: 0.5363\n",
            "57/186, train_loss: 0.0389\n",
            "58/186, train_loss: 0.0247\n",
            "59/186, train_loss: 0.1667\n",
            "60/186, train_loss: 0.3806\n",
            "61/186, train_loss: 0.0891\n",
            "62/186, train_loss: 0.1454\n",
            "63/186, train_loss: 0.2336\n",
            "64/186, train_loss: 0.1532\n",
            "65/186, train_loss: 0.0528\n",
            "66/186, train_loss: 0.1368\n",
            "67/186, train_loss: 0.0666\n",
            "68/186, train_loss: 0.4103\n",
            "69/186, train_loss: 0.1730\n",
            "70/186, train_loss: 0.5488\n",
            "71/186, train_loss: 0.0045\n",
            "72/186, train_loss: 0.2076\n",
            "73/186, train_loss: 0.0356\n",
            "74/186, train_loss: 0.5351\n",
            "75/186, train_loss: 0.0234\n",
            "76/186, train_loss: 0.0112\n",
            "77/186, train_loss: 0.0352\n",
            "78/186, train_loss: 0.6770\n",
            "79/186, train_loss: 0.7001\n",
            "80/186, train_loss: 0.1497\n",
            "81/186, train_loss: 0.1146\n",
            "82/186, train_loss: 0.5503\n",
            "83/186, train_loss: 0.0173\n",
            "84/186, train_loss: 0.0048\n",
            "85/186, train_loss: 0.1053\n",
            "86/186, train_loss: 0.0171\n",
            "87/186, train_loss: 0.7154\n",
            "88/186, train_loss: 0.1103\n",
            "89/186, train_loss: 0.0180\n",
            "90/186, train_loss: 0.0032\n",
            "91/186, train_loss: 1.7381\n",
            "92/186, train_loss: 0.0781\n",
            "93/186, train_loss: 0.0829\n",
            "94/186, train_loss: 0.0097\n",
            "95/186, train_loss: 0.3471\n",
            "96/186, train_loss: 0.0246\n",
            "97/186, train_loss: 0.0715\n",
            "98/186, train_loss: 0.0731\n",
            "99/186, train_loss: 0.0032\n",
            "100/186, train_loss: 0.1989\n",
            "101/186, train_loss: 0.5423\n",
            "102/186, train_loss: 0.1984\n",
            "103/186, train_loss: 0.1063\n",
            "104/186, train_loss: 0.0965\n",
            "105/186, train_loss: 0.0255\n",
            "106/186, train_loss: 0.0462\n",
            "107/186, train_loss: 0.0530\n",
            "108/186, train_loss: 0.5411\n",
            "109/186, train_loss: 0.2292\n",
            "110/186, train_loss: 0.5422\n",
            "111/186, train_loss: 0.0428\n",
            "112/186, train_loss: 0.0222\n",
            "113/186, train_loss: 0.0416\n",
            "114/186, train_loss: 0.1217\n",
            "115/186, train_loss: 0.1156\n",
            "116/186, train_loss: 0.1209\n",
            "117/186, train_loss: 0.0056\n",
            "118/186, train_loss: 0.0087\n",
            "119/186, train_loss: 0.0937\n",
            "120/186, train_loss: 0.0415\n",
            "121/186, train_loss: 0.8356\n",
            "122/186, train_loss: 0.0365\n",
            "123/186, train_loss: 0.0051\n",
            "124/186, train_loss: 0.1164\n",
            "125/186, train_loss: 0.0107\n",
            "126/186, train_loss: 0.0137\n",
            "127/186, train_loss: 0.0533\n",
            "128/186, train_loss: 0.0240\n",
            "129/186, train_loss: 0.0100\n",
            "130/186, train_loss: 0.2294\n",
            "131/186, train_loss: 0.0731\n",
            "132/186, train_loss: 0.1101\n",
            "133/186, train_loss: 0.1151\n",
            "134/186, train_loss: 0.1805\n",
            "135/186, train_loss: 0.0018\n",
            "136/186, train_loss: 0.0344\n",
            "137/186, train_loss: 0.0560\n",
            "138/186, train_loss: 0.7756\n",
            "139/186, train_loss: 0.0445\n",
            "140/186, train_loss: 0.0130\n",
            "141/186, train_loss: 0.6525\n",
            "142/186, train_loss: 0.1751\n",
            "143/186, train_loss: 0.0138\n",
            "144/186, train_loss: 0.5366\n",
            "145/186, train_loss: 0.0226\n",
            "146/186, train_loss: 0.1786\n",
            "147/186, train_loss: 0.5355\n",
            "148/186, train_loss: 0.0684\n",
            "149/186, train_loss: 0.4659\n",
            "150/186, train_loss: 0.1583\n",
            "151/186, train_loss: 0.5043\n",
            "152/186, train_loss: 0.5532\n",
            "153/186, train_loss: 0.0134\n",
            "154/186, train_loss: 0.0567\n",
            "155/186, train_loss: 0.0117\n",
            "156/186, train_loss: 0.1124\n",
            "157/186, train_loss: 0.0495\n",
            "158/186, train_loss: 0.0038\n",
            "159/186, train_loss: 0.0097\n",
            "160/186, train_loss: 0.0627\n",
            "161/186, train_loss: 0.7896\n",
            "162/186, train_loss: 0.0083\n",
            "163/186, train_loss: 0.0986\n",
            "164/186, train_loss: 0.0448\n",
            "165/186, train_loss: 0.1313\n",
            "166/186, train_loss: 0.0076\n",
            "167/186, train_loss: 0.0139\n",
            "168/186, train_loss: 0.6805\n",
            "169/186, train_loss: 0.2348\n",
            "170/186, train_loss: 0.0096\n",
            "171/186, train_loss: 0.0756\n",
            "172/186, train_loss: 0.2323\n",
            "173/186, train_loss: 0.2502\n",
            "174/186, train_loss: 0.0074\n",
            "175/186, train_loss: 0.0792\n",
            "176/186, train_loss: 0.0725\n",
            "177/186, train_loss: 0.0141\n",
            "178/186, train_loss: 0.0423\n",
            "179/186, train_loss: 0.0048\n",
            "180/186, train_loss: 0.5874\n",
            "181/186, train_loss: 0.5062\n",
            "182/186, train_loss: 0.4162\n",
            "183/186, train_loss: 0.0048\n",
            "184/186, train_loss: 0.0246\n",
            "185/186, train_loss: 0.4471\n",
            "186/186, train_loss: 0.1196\n",
            "epoch 21 average loss: 0.1930\n",
            "----------\n",
            "epoch 22/50\n",
            "1/186, train_loss: 0.0152\n",
            "2/186, train_loss: 0.0207\n",
            "3/186, train_loss: 1.3465\n",
            "4/186, train_loss: 0.0309\n",
            "5/186, train_loss: 0.0402\n",
            "6/186, train_loss: 0.3746\n",
            "7/186, train_loss: 0.6082\n",
            "8/186, train_loss: 0.0082\n",
            "9/186, train_loss: 0.6943\n",
            "10/186, train_loss: 0.0475\n",
            "11/186, train_loss: 0.0258\n",
            "12/186, train_loss: 0.0110\n",
            "13/186, train_loss: 0.1653\n",
            "14/186, train_loss: 0.0223\n",
            "15/186, train_loss: 0.1204\n",
            "16/186, train_loss: 1.0567\n",
            "17/186, train_loss: 1.0053\n",
            "18/186, train_loss: 0.2202\n",
            "19/186, train_loss: 0.3970\n",
            "20/186, train_loss: 0.0333\n",
            "21/186, train_loss: 0.0172\n",
            "22/186, train_loss: 0.7395\n",
            "23/186, train_loss: 0.0727\n",
            "24/186, train_loss: 0.0760\n",
            "25/186, train_loss: 0.0075\n",
            "26/186, train_loss: 0.0086\n",
            "27/186, train_loss: 0.1977\n",
            "28/186, train_loss: 0.1038\n",
            "29/186, train_loss: 0.0082\n",
            "30/186, train_loss: 0.7052\n",
            "31/186, train_loss: 0.1483\n",
            "32/186, train_loss: 0.3246\n",
            "33/186, train_loss: 0.0775\n",
            "34/186, train_loss: 0.0931\n",
            "35/186, train_loss: 0.0225\n",
            "36/186, train_loss: 0.0021\n",
            "37/186, train_loss: 0.4667\n",
            "38/186, train_loss: 0.0130\n",
            "39/186, train_loss: 0.0148\n",
            "40/186, train_loss: 0.0379\n",
            "41/186, train_loss: 0.0858\n",
            "42/186, train_loss: 0.0549\n",
            "43/186, train_loss: 0.0065\n",
            "44/186, train_loss: 0.0030\n",
            "45/186, train_loss: 0.0061\n",
            "46/186, train_loss: 0.0021\n",
            "47/186, train_loss: 0.0163\n",
            "48/186, train_loss: 0.8373\n",
            "49/186, train_loss: 0.4039\n",
            "50/186, train_loss: 0.0052\n",
            "51/186, train_loss: 0.0126\n",
            "52/186, train_loss: 0.2064\n",
            "53/186, train_loss: 0.0142\n",
            "54/186, train_loss: 0.0192\n",
            "55/186, train_loss: 0.1477\n",
            "56/186, train_loss: 0.1498\n",
            "57/186, train_loss: 0.1126\n",
            "58/186, train_loss: 0.0937\n",
            "59/186, train_loss: 0.0706\n",
            "60/186, train_loss: 0.7100\n",
            "61/186, train_loss: 0.7458\n",
            "62/186, train_loss: 0.0100\n",
            "63/186, train_loss: 0.4557\n",
            "64/186, train_loss: 0.1396\n",
            "65/186, train_loss: 0.0492\n",
            "66/186, train_loss: 0.0106\n",
            "67/186, train_loss: 0.0590\n",
            "68/186, train_loss: 0.4818\n",
            "69/186, train_loss: 0.0520\n",
            "70/186, train_loss: 0.1612\n",
            "71/186, train_loss: 0.0095\n",
            "72/186, train_loss: 0.0199\n",
            "73/186, train_loss: 0.7626\n",
            "74/186, train_loss: 0.0060\n",
            "75/186, train_loss: 0.0789\n",
            "76/186, train_loss: 0.0705\n",
            "77/186, train_loss: 0.0946\n",
            "78/186, train_loss: 0.0560\n",
            "79/186, train_loss: 0.0209\n",
            "80/186, train_loss: 0.1590\n",
            "81/186, train_loss: 1.2553\n",
            "82/186, train_loss: 0.0642\n",
            "83/186, train_loss: 2.1384\n",
            "84/186, train_loss: 0.5094\n",
            "85/186, train_loss: 0.0719\n",
            "86/186, train_loss: 0.0699\n",
            "87/186, train_loss: 0.0074\n",
            "88/186, train_loss: 0.1171\n",
            "89/186, train_loss: 0.0442\n",
            "90/186, train_loss: 0.0137\n",
            "91/186, train_loss: 0.4807\n",
            "92/186, train_loss: 0.0699\n",
            "93/186, train_loss: 0.0590\n",
            "94/186, train_loss: 0.0640\n",
            "95/186, train_loss: 0.0658\n",
            "96/186, train_loss: 0.1325\n",
            "97/186, train_loss: 0.0775\n",
            "98/186, train_loss: 0.1134\n",
            "99/186, train_loss: 0.1117\n",
            "100/186, train_loss: 0.7429\n",
            "101/186, train_loss: 0.1298\n",
            "102/186, train_loss: 0.1085\n",
            "103/186, train_loss: 0.0169\n",
            "104/186, train_loss: 0.1998\n",
            "105/186, train_loss: 0.0965\n",
            "106/186, train_loss: 0.0315\n",
            "107/186, train_loss: 0.0781\n",
            "108/186, train_loss: 0.0845\n",
            "109/186, train_loss: 0.0068\n",
            "110/186, train_loss: 0.0063\n",
            "111/186, train_loss: 0.0031\n",
            "112/186, train_loss: 0.0042\n",
            "113/186, train_loss: 0.0040\n",
            "114/186, train_loss: 0.0100\n",
            "115/186, train_loss: 0.5362\n",
            "116/186, train_loss: 0.7911\n",
            "117/186, train_loss: 0.0543\n",
            "118/186, train_loss: 0.2207\n",
            "119/186, train_loss: 0.0094\n",
            "120/186, train_loss: 0.1066\n",
            "121/186, train_loss: 0.7470\n",
            "122/186, train_loss: 0.1225\n",
            "123/186, train_loss: 0.1241\n",
            "124/186, train_loss: 0.0432\n",
            "125/186, train_loss: 0.0119\n",
            "126/186, train_loss: 0.0306\n",
            "127/186, train_loss: 0.1043\n",
            "128/186, train_loss: 0.0096\n",
            "129/186, train_loss: 0.1233\n",
            "130/186, train_loss: 0.0023\n",
            "131/186, train_loss: 0.8023\n",
            "132/186, train_loss: 0.0032\n",
            "133/186, train_loss: 0.0031\n",
            "134/186, train_loss: 0.0670\n",
            "135/186, train_loss: 0.9617\n",
            "136/186, train_loss: 0.1073\n",
            "137/186, train_loss: 0.0543\n",
            "138/186, train_loss: 0.0257\n",
            "139/186, train_loss: 0.0251\n",
            "140/186, train_loss: 0.0268\n",
            "141/186, train_loss: 0.0179\n",
            "142/186, train_loss: 0.7101\n",
            "143/186, train_loss: 0.2158\n",
            "144/186, train_loss: 0.0887\n",
            "145/186, train_loss: 0.0142\n",
            "146/186, train_loss: 0.1528\n",
            "147/186, train_loss: 0.6188\n",
            "148/186, train_loss: 0.0057\n",
            "149/186, train_loss: 0.0111\n",
            "150/186, train_loss: 0.0718\n",
            "151/186, train_loss: 0.0709\n",
            "152/186, train_loss: 0.0107\n",
            "153/186, train_loss: 0.0102\n",
            "154/186, train_loss: 0.0054\n",
            "155/186, train_loss: 0.0733\n",
            "156/186, train_loss: 0.0252\n",
            "157/186, train_loss: 0.1019\n",
            "158/186, train_loss: 0.0398\n",
            "159/186, train_loss: 0.0258\n",
            "160/186, train_loss: 0.0542\n",
            "161/186, train_loss: 0.0464\n",
            "162/186, train_loss: 0.1826\n",
            "163/186, train_loss: 0.0721\n",
            "164/186, train_loss: 0.0842\n",
            "165/186, train_loss: 0.0534\n",
            "166/186, train_loss: 0.3937\n",
            "167/186, train_loss: 0.2936\n",
            "168/186, train_loss: 0.1775\n",
            "169/186, train_loss: 1.2864\n",
            "170/186, train_loss: 0.1022\n",
            "171/186, train_loss: 0.0635\n",
            "172/186, train_loss: 0.0189\n",
            "173/186, train_loss: 0.0608\n",
            "174/186, train_loss: 0.0588\n",
            "175/186, train_loss: 0.0680\n",
            "176/186, train_loss: 0.0825\n",
            "177/186, train_loss: 0.0247\n",
            "178/186, train_loss: 0.0047\n",
            "179/186, train_loss: 0.1414\n",
            "180/186, train_loss: 0.0619\n",
            "181/186, train_loss: 0.6713\n",
            "182/186, train_loss: 0.8978\n",
            "183/186, train_loss: 0.1126\n",
            "184/186, train_loss: 0.0053\n",
            "185/186, train_loss: 0.0629\n",
            "186/186, train_loss: 2.3709\n",
            "epoch 22 average loss: 0.2022\n",
            "current epoch: 22 current accuracy: 0.8387 best accuracy: 0.8817 at epoch 8\n",
            "----------\n",
            "epoch 23/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/186, train_loss: 1.8865\n",
            "2/186, train_loss: 0.0503\n",
            "3/186, train_loss: 0.9945\n",
            "4/186, train_loss: 0.0913\n",
            "5/186, train_loss: 0.2308\n",
            "6/186, train_loss: 0.0671\n",
            "7/186, train_loss: 0.4677\n",
            "8/186, train_loss: 0.0842\n",
            "9/186, train_loss: 0.4958\n",
            "10/186, train_loss: 0.0321\n",
            "11/186, train_loss: 0.0704\n",
            "12/186, train_loss: 0.0754\n",
            "13/186, train_loss: 0.0140\n",
            "14/186, train_loss: 0.0633\n",
            "15/186, train_loss: 1.1950\n",
            "16/186, train_loss: 0.4592\n",
            "17/186, train_loss: 0.1157\n",
            "18/186, train_loss: 0.0261\n",
            "19/186, train_loss: 0.0529\n",
            "20/186, train_loss: 0.1368\n",
            "21/186, train_loss: 0.1033\n",
            "22/186, train_loss: 0.0920\n",
            "23/186, train_loss: 0.0611\n",
            "24/186, train_loss: 0.1238\n",
            "25/186, train_loss: 1.2971\n",
            "26/186, train_loss: 0.0473\n",
            "27/186, train_loss: 0.0578\n",
            "28/186, train_loss: 1.7450\n",
            "29/186, train_loss: 0.0147\n",
            "30/186, train_loss: 0.0100\n",
            "31/186, train_loss: 0.1015\n",
            "32/186, train_loss: 0.0411\n",
            "33/186, train_loss: 0.0203\n",
            "34/186, train_loss: 0.0098\n",
            "35/186, train_loss: 0.2945\n",
            "36/186, train_loss: 0.0648\n",
            "37/186, train_loss: 0.2160\n",
            "38/186, train_loss: 0.0656\n",
            "39/186, train_loss: 0.0909\n",
            "40/186, train_loss: 0.4544\n",
            "41/186, train_loss: 0.4679\n",
            "42/186, train_loss: 0.0321\n",
            "43/186, train_loss: 0.1158\n",
            "44/186, train_loss: 0.2880\n",
            "45/186, train_loss: 0.0449\n",
            "46/186, train_loss: 0.5512\n",
            "47/186, train_loss: 1.4051\n",
            "48/186, train_loss: 0.1146\n",
            "49/186, train_loss: 2.3210\n",
            "50/186, train_loss: 0.1110\n",
            "51/186, train_loss: 0.0218\n",
            "52/186, train_loss: 0.0947\n",
            "53/186, train_loss: 0.0408\n",
            "54/186, train_loss: 0.1535\n",
            "55/186, train_loss: 0.1158\n",
            "56/186, train_loss: 0.0190\n",
            "57/186, train_loss: 0.3375\n",
            "58/186, train_loss: 0.1221\n",
            "59/186, train_loss: 0.0069\n",
            "60/186, train_loss: 0.0937\n",
            "61/186, train_loss: 0.3467\n",
            "62/186, train_loss: 0.0184\n",
            "63/186, train_loss: 0.1488\n",
            "64/186, train_loss: 0.4038\n",
            "65/186, train_loss: 0.1441\n",
            "66/186, train_loss: 0.1018\n",
            "67/186, train_loss: 0.0742\n",
            "68/186, train_loss: 0.4388\n",
            "69/186, train_loss: 0.0793\n",
            "70/186, train_loss: 0.0151\n",
            "71/186, train_loss: 0.0327\n",
            "72/186, train_loss: 0.0201\n",
            "73/186, train_loss: 0.0363\n",
            "74/186, train_loss: 0.4435\n",
            "75/186, train_loss: 0.1129\n",
            "76/186, train_loss: 0.0965\n",
            "77/186, train_loss: 0.0215\n",
            "78/186, train_loss: 0.0082\n",
            "79/186, train_loss: 0.2569\n",
            "80/186, train_loss: 0.0233\n",
            "81/186, train_loss: 0.0440\n",
            "82/186, train_loss: 0.7468\n",
            "83/186, train_loss: 0.0708\n",
            "84/186, train_loss: 0.2306\n",
            "85/186, train_loss: 0.0626\n",
            "86/186, train_loss: 0.0772\n",
            "87/186, train_loss: 0.0162\n",
            "88/186, train_loss: 0.0842\n",
            "89/186, train_loss: 0.6559\n",
            "90/186, train_loss: 0.1027\n",
            "91/186, train_loss: 0.1065\n",
            "92/186, train_loss: 0.0242\n",
            "93/186, train_loss: 0.1912\n",
            "94/186, train_loss: 0.0154\n",
            "95/186, train_loss: 0.3859\n",
            "96/186, train_loss: 1.8267\n",
            "97/186, train_loss: 0.0163\n",
            "98/186, train_loss: 0.1545\n",
            "99/186, train_loss: 0.0933\n",
            "100/186, train_loss: 0.2798\n",
            "101/186, train_loss: 0.0709\n",
            "102/186, train_loss: 0.0162\n",
            "103/186, train_loss: 0.0583\n",
            "104/186, train_loss: 0.0835\n",
            "105/186, train_loss: 0.0180\n",
            "106/186, train_loss: 0.0967\n",
            "107/186, train_loss: 0.0295\n",
            "108/186, train_loss: 0.6711\n",
            "109/186, train_loss: 0.0985\n",
            "110/186, train_loss: 0.6014\n",
            "111/186, train_loss: 0.0206\n",
            "112/186, train_loss: 0.0471\n",
            "113/186, train_loss: 0.2174\n",
            "114/186, train_loss: 0.1752\n",
            "115/186, train_loss: 0.1483\n",
            "116/186, train_loss: 0.0602\n",
            "117/186, train_loss: 0.1704\n",
            "118/186, train_loss: 0.2032\n",
            "119/186, train_loss: 0.1848\n",
            "120/186, train_loss: 0.0804\n",
            "121/186, train_loss: 0.0535\n",
            "122/186, train_loss: 0.2895\n",
            "123/186, train_loss: 0.0534\n",
            "124/186, train_loss: 0.0103\n",
            "125/186, train_loss: 0.0218\n",
            "126/186, train_loss: 0.0298\n",
            "127/186, train_loss: 0.0629\n",
            "128/186, train_loss: 0.0304\n",
            "129/186, train_loss: 0.0291\n",
            "130/186, train_loss: 0.4878\n",
            "131/186, train_loss: 0.1083\n",
            "132/186, train_loss: 0.0587\n",
            "133/186, train_loss: 0.0851\n",
            "134/186, train_loss: 0.0482\n",
            "135/186, train_loss: 0.2292\n",
            "136/186, train_loss: 0.0581\n",
            "137/186, train_loss: 0.0485\n",
            "138/186, train_loss: 0.0376\n",
            "139/186, train_loss: 0.5018\n",
            "140/186, train_loss: 0.0629\n",
            "141/186, train_loss: 0.0182\n",
            "142/186, train_loss: 0.0208\n",
            "143/186, train_loss: 0.0593\n",
            "144/186, train_loss: 0.3093\n",
            "145/186, train_loss: 0.0402\n",
            "146/186, train_loss: 0.1009\n",
            "147/186, train_loss: 0.6803\n",
            "148/186, train_loss: 0.0342\n",
            "149/186, train_loss: 0.1566\n",
            "150/186, train_loss: 0.5447\n",
            "151/186, train_loss: 0.0992\n",
            "152/186, train_loss: 0.0220\n",
            "153/186, train_loss: 0.0161\n",
            "154/186, train_loss: 0.0632\n",
            "155/186, train_loss: 0.0277\n",
            "156/186, train_loss: 0.0321\n",
            "157/186, train_loss: 1.0002\n",
            "158/186, train_loss: 0.0295\n",
            "159/186, train_loss: 0.6328\n",
            "160/186, train_loss: 0.0044\n",
            "161/186, train_loss: 0.4898\n",
            "162/186, train_loss: 0.5334\n",
            "163/186, train_loss: 0.0030\n",
            "164/186, train_loss: 0.1453\n",
            "165/186, train_loss: 0.0590\n",
            "166/186, train_loss: 0.0536\n",
            "167/186, train_loss: 0.0290\n",
            "168/186, train_loss: 0.0063\n",
            "169/186, train_loss: 0.1440\n",
            "170/186, train_loss: 0.0232\n",
            "171/186, train_loss: 0.0627\n",
            "172/186, train_loss: 0.0052\n",
            "173/186, train_loss: 0.0063\n",
            "174/186, train_loss: 0.0083\n",
            "175/186, train_loss: 0.1233\n",
            "176/186, train_loss: 0.0877\n",
            "177/186, train_loss: 0.0466\n",
            "178/186, train_loss: 0.0456\n",
            "179/186, train_loss: 0.0978\n",
            "180/186, train_loss: 1.2380\n",
            "181/186, train_loss: 0.0019\n",
            "182/186, train_loss: 0.0561\n",
            "183/186, train_loss: 0.0119\n",
            "184/186, train_loss: 0.0506\n",
            "185/186, train_loss: 0.0887\n",
            "186/186, train_loss: 0.1610\n",
            "epoch 23 average loss: 0.2087\n",
            "----------\n",
            "epoch 24/50\n",
            "1/186, train_loss: 0.0156\n",
            "2/186, train_loss: 0.0230\n",
            "3/186, train_loss: 0.0164\n",
            "4/186, train_loss: 0.0045\n",
            "5/186, train_loss: 0.0748\n",
            "6/186, train_loss: 0.0213\n",
            "7/186, train_loss: 0.1541\n",
            "8/186, train_loss: 0.0194\n",
            "9/186, train_loss: 0.4403\n",
            "10/186, train_loss: 0.0141\n",
            "11/186, train_loss: 0.0747\n",
            "12/186, train_loss: 0.0486\n",
            "13/186, train_loss: 0.0065\n",
            "14/186, train_loss: 0.0857\n",
            "15/186, train_loss: 0.0839\n",
            "16/186, train_loss: 0.0502\n",
            "17/186, train_loss: 0.0078\n",
            "18/186, train_loss: 0.7264\n",
            "19/186, train_loss: 0.7024\n",
            "20/186, train_loss: 0.0828\n",
            "21/186, train_loss: 0.0998\n",
            "22/186, train_loss: 0.0089\n",
            "23/186, train_loss: 0.0092\n",
            "24/186, train_loss: 0.4460\n",
            "25/186, train_loss: 0.1545\n",
            "26/186, train_loss: 0.0065\n",
            "27/186, train_loss: 0.0143\n",
            "28/186, train_loss: 0.0515\n",
            "29/186, train_loss: 0.0760\n",
            "30/186, train_loss: 0.0786\n",
            "31/186, train_loss: 0.0208\n",
            "32/186, train_loss: 0.0166\n",
            "33/186, train_loss: 0.0040\n",
            "34/186, train_loss: 0.0039\n",
            "35/186, train_loss: 0.4700\n",
            "36/186, train_loss: 0.1668\n",
            "37/186, train_loss: 0.0377\n",
            "38/186, train_loss: 0.0118\n",
            "39/186, train_loss: 0.0295\n",
            "40/186, train_loss: 0.0161\n",
            "41/186, train_loss: 0.0416\n",
            "42/186, train_loss: 0.5277\n",
            "43/186, train_loss: 0.0045\n",
            "44/186, train_loss: 0.0263\n",
            "45/186, train_loss: 0.0582\n",
            "46/186, train_loss: 0.0530\n",
            "47/186, train_loss: 0.0219\n",
            "48/186, train_loss: 0.1960\n",
            "49/186, train_loss: 0.0486\n",
            "50/186, train_loss: 0.0260\n",
            "51/186, train_loss: 0.0105\n",
            "52/186, train_loss: 0.0085\n",
            "53/186, train_loss: 0.1857\n",
            "54/186, train_loss: 0.0058\n",
            "55/186, train_loss: 0.2319\n",
            "56/186, train_loss: 0.0543\n",
            "57/186, train_loss: 0.0091\n",
            "58/186, train_loss: 0.6178\n",
            "59/186, train_loss: 0.0077\n",
            "60/186, train_loss: 0.1720\n",
            "61/186, train_loss: 0.0122\n",
            "62/186, train_loss: 0.0198\n",
            "63/186, train_loss: 0.1190\n",
            "64/186, train_loss: 0.0054\n",
            "65/186, train_loss: 0.0541\n",
            "66/186, train_loss: 0.1014\n",
            "67/186, train_loss: 0.2049\n",
            "68/186, train_loss: 0.2618\n",
            "69/186, train_loss: 0.0042\n",
            "70/186, train_loss: 0.0145\n",
            "71/186, train_loss: 0.0423\n",
            "72/186, train_loss: 0.0024\n",
            "73/186, train_loss: 0.0088\n",
            "74/186, train_loss: 0.0122\n",
            "75/186, train_loss: 0.0848\n",
            "76/186, train_loss: 0.6130\n",
            "77/186, train_loss: 0.0031\n",
            "78/186, train_loss: 0.0174\n",
            "79/186, train_loss: 0.0121\n",
            "80/186, train_loss: 0.1322\n",
            "81/186, train_loss: 0.0088\n",
            "82/186, train_loss: 0.1666\n",
            "83/186, train_loss: 0.0051\n",
            "84/186, train_loss: 0.1388\n",
            "85/186, train_loss: 0.0705\n",
            "86/186, train_loss: 0.0487\n",
            "87/186, train_loss: 0.1003\n",
            "88/186, train_loss: 0.1111\n",
            "89/186, train_loss: 0.0082\n",
            "90/186, train_loss: 0.1075\n",
            "91/186, train_loss: 0.0075\n",
            "92/186, train_loss: 0.0219\n",
            "93/186, train_loss: 0.0401\n",
            "94/186, train_loss: 0.2415\n",
            "95/186, train_loss: 0.0489\n",
            "96/186, train_loss: 0.0397\n",
            "97/186, train_loss: 0.0818\n",
            "98/186, train_loss: 0.4174\n",
            "99/186, train_loss: 0.3963\n",
            "100/186, train_loss: 0.0063\n",
            "101/186, train_loss: 0.0409\n",
            "102/186, train_loss: 0.9144\n",
            "103/186, train_loss: 0.0131\n",
            "104/186, train_loss: 0.0194\n",
            "105/186, train_loss: 0.1531\n",
            "106/186, train_loss: 0.1824\n",
            "107/186, train_loss: 0.0077\n",
            "108/186, train_loss: 0.0672\n",
            "109/186, train_loss: 0.4225\n",
            "110/186, train_loss: 0.0526\n",
            "111/186, train_loss: 1.4477\n",
            "112/186, train_loss: 0.0076\n",
            "113/186, train_loss: 0.0048\n",
            "114/186, train_loss: 0.0993\n",
            "115/186, train_loss: 1.0816\n",
            "116/186, train_loss: 0.0707\n",
            "117/186, train_loss: 0.0119\n",
            "118/186, train_loss: 0.0981\n",
            "119/186, train_loss: 0.0491\n",
            "120/186, train_loss: 0.0897\n",
            "121/186, train_loss: 0.0500\n",
            "122/186, train_loss: 0.7872\n",
            "123/186, train_loss: 0.0025\n",
            "124/186, train_loss: 0.0499\n",
            "125/186, train_loss: 0.2941\n",
            "126/186, train_loss: 0.0037\n",
            "127/186, train_loss: 0.0734\n",
            "128/186, train_loss: 0.0531\n",
            "129/186, train_loss: 0.9882\n",
            "130/186, train_loss: 0.0644\n",
            "131/186, train_loss: 0.8851\n",
            "132/186, train_loss: 0.0541\n",
            "133/186, train_loss: 0.0077\n",
            "134/186, train_loss: 0.0456\n",
            "135/186, train_loss: 1.1575\n",
            "136/186, train_loss: 0.4747\n",
            "137/186, train_loss: 0.0306\n",
            "138/186, train_loss: 0.0535\n",
            "139/186, train_loss: 0.0937\n",
            "140/186, train_loss: 0.4402\n",
            "141/186, train_loss: 0.5116\n",
            "142/186, train_loss: 0.0596\n",
            "143/186, train_loss: 0.1156\n",
            "144/186, train_loss: 0.1288\n",
            "145/186, train_loss: 0.0034\n",
            "146/186, train_loss: 1.3153\n",
            "147/186, train_loss: 0.0030\n",
            "148/186, train_loss: 0.1023\n",
            "149/186, train_loss: 0.0598\n",
            "150/186, train_loss: 0.1270\n",
            "151/186, train_loss: 0.3608\n",
            "152/186, train_loss: 0.0919\n",
            "153/186, train_loss: 0.3390\n",
            "154/186, train_loss: 0.0143\n",
            "155/186, train_loss: 0.1214\n",
            "156/186, train_loss: 0.0061\n",
            "157/186, train_loss: 0.0095\n",
            "158/186, train_loss: 1.7561\n",
            "159/186, train_loss: 0.0810\n",
            "160/186, train_loss: 0.6187\n",
            "161/186, train_loss: 0.0070\n",
            "162/186, train_loss: 0.0373\n",
            "163/186, train_loss: 1.2551\n",
            "164/186, train_loss: 0.0093\n",
            "165/186, train_loss: 0.0206\n",
            "166/186, train_loss: 0.1129\n",
            "167/186, train_loss: 0.6263\n",
            "168/186, train_loss: 0.0070\n",
            "169/186, train_loss: 0.3175\n",
            "170/186, train_loss: 0.0176\n",
            "171/186, train_loss: 0.0053\n",
            "172/186, train_loss: 0.0669\n",
            "173/186, train_loss: 0.5257\n",
            "174/186, train_loss: 0.1049\n",
            "175/186, train_loss: 0.0080\n",
            "176/186, train_loss: 0.0682\n",
            "177/186, train_loss: 0.0108\n",
            "178/186, train_loss: 0.1374\n",
            "179/186, train_loss: 0.0786\n",
            "180/186, train_loss: 0.1712\n",
            "181/186, train_loss: 0.0277\n",
            "182/186, train_loss: 0.8259\n",
            "183/186, train_loss: 0.0374\n",
            "184/186, train_loss: 0.1213\n",
            "185/186, train_loss: 0.0072\n",
            "186/186, train_loss: 0.0026\n",
            "epoch 24 average loss: 0.1686\n",
            "current epoch: 24 current accuracy: 0.7742 best accuracy: 0.8817 at epoch 8\n",
            "----------\n",
            "epoch 25/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/186, train_loss: 0.0980\n",
            "2/186, train_loss: 0.1474\n",
            "3/186, train_loss: 0.1160\n",
            "4/186, train_loss: 0.0353\n",
            "5/186, train_loss: 0.7153\n",
            "6/186, train_loss: 0.0108\n",
            "7/186, train_loss: 0.0642\n",
            "8/186, train_loss: 0.0148\n",
            "9/186, train_loss: 0.1567\n",
            "10/186, train_loss: 0.0665\n",
            "11/186, train_loss: 0.0197\n",
            "12/186, train_loss: 0.0095\n",
            "13/186, train_loss: 0.0052\n",
            "14/186, train_loss: 0.0683\n",
            "15/186, train_loss: 0.3537\n",
            "16/186, train_loss: 0.0204\n",
            "17/186, train_loss: 0.0098\n",
            "18/186, train_loss: 0.0039\n",
            "19/186, train_loss: 0.4234\n",
            "20/186, train_loss: 0.4413\n",
            "21/186, train_loss: 0.0468\n",
            "22/186, train_loss: 0.0137\n",
            "23/186, train_loss: 0.5189\n",
            "24/186, train_loss: 0.0746\n",
            "25/186, train_loss: 0.7595\n",
            "26/186, train_loss: 0.0045\n",
            "27/186, train_loss: 0.1483\n",
            "28/186, train_loss: 0.0203\n",
            "29/186, train_loss: 0.7385\n",
            "30/186, train_loss: 0.0521\n",
            "31/186, train_loss: 0.3620\n",
            "32/186, train_loss: 0.0926\n",
            "33/186, train_loss: 0.0905\n",
            "34/186, train_loss: 0.0642\n",
            "35/186, train_loss: 0.0185\n",
            "36/186, train_loss: 0.0051\n",
            "37/186, train_loss: 0.0044\n",
            "38/186, train_loss: 0.1518\n",
            "39/186, train_loss: 0.0143\n",
            "40/186, train_loss: 0.0063\n",
            "41/186, train_loss: 0.3425\n",
            "42/186, train_loss: 0.1921\n",
            "43/186, train_loss: 0.0825\n",
            "44/186, train_loss: 0.4005\n",
            "45/186, train_loss: 0.0156\n",
            "46/186, train_loss: 0.0893\n",
            "47/186, train_loss: 0.0463\n",
            "48/186, train_loss: 0.3058\n",
            "49/186, train_loss: 0.0198\n",
            "50/186, train_loss: 0.0651\n",
            "51/186, train_loss: 0.0408\n",
            "52/186, train_loss: 0.0033\n",
            "53/186, train_loss: 0.0497\n",
            "54/186, train_loss: 0.0274\n",
            "55/186, train_loss: 0.0130\n",
            "56/186, train_loss: 0.4623\n",
            "57/186, train_loss: 0.0923\n",
            "58/186, train_loss: 0.4195\n",
            "59/186, train_loss: 0.0365\n",
            "60/186, train_loss: 0.2052\n",
            "61/186, train_loss: 0.2282\n",
            "62/186, train_loss: 0.0325\n",
            "63/186, train_loss: 0.0891\n",
            "64/186, train_loss: 0.0439\n",
            "65/186, train_loss: 0.1295\n",
            "66/186, train_loss: 0.0113\n",
            "67/186, train_loss: 0.1059\n",
            "68/186, train_loss: 0.0039\n",
            "69/186, train_loss: 0.0153\n",
            "70/186, train_loss: 0.0048\n",
            "71/186, train_loss: 0.0591\n",
            "72/186, train_loss: 0.0101\n",
            "73/186, train_loss: 0.2035\n",
            "74/186, train_loss: 0.1061\n",
            "75/186, train_loss: 0.1002\n",
            "76/186, train_loss: 0.1621\n",
            "77/186, train_loss: 0.0488\n",
            "78/186, train_loss: 0.0188\n",
            "79/186, train_loss: 0.0852\n",
            "80/186, train_loss: 0.3697\n",
            "81/186, train_loss: 0.4631\n",
            "82/186, train_loss: 0.3559\n",
            "83/186, train_loss: 0.1112\n",
            "84/186, train_loss: 0.0511\n",
            "85/186, train_loss: 0.0595\n",
            "86/186, train_loss: 0.0146\n",
            "87/186, train_loss: 0.1081\n",
            "88/186, train_loss: 0.6932\n",
            "89/186, train_loss: 0.4261\n",
            "90/186, train_loss: 0.0386\n",
            "91/186, train_loss: 0.0029\n",
            "92/186, train_loss: 0.0108\n",
            "93/186, train_loss: 0.0239\n",
            "94/186, train_loss: 0.0504\n",
            "95/186, train_loss: 0.4833\n",
            "96/186, train_loss: 0.0502\n",
            "97/186, train_loss: 0.3315\n",
            "98/186, train_loss: 0.0857\n",
            "99/186, train_loss: 0.0266\n",
            "100/186, train_loss: 0.0073\n",
            "101/186, train_loss: 0.0161\n",
            "102/186, train_loss: 0.1076\n",
            "103/186, train_loss: 0.0538\n",
            "104/186, train_loss: 0.0456\n",
            "105/186, train_loss: 0.7894\n",
            "106/186, train_loss: 0.4585\n",
            "107/186, train_loss: 0.0424\n",
            "108/186, train_loss: 0.0132\n",
            "109/186, train_loss: 0.4687\n",
            "110/186, train_loss: 0.1924\n",
            "111/186, train_loss: 2.1111\n",
            "112/186, train_loss: 0.0545\n",
            "113/186, train_loss: 0.0472\n",
            "114/186, train_loss: 0.0144\n",
            "115/186, train_loss: 0.7375\n",
            "116/186, train_loss: 0.0114\n",
            "117/186, train_loss: 0.0404\n",
            "118/186, train_loss: 0.0989\n",
            "119/186, train_loss: 0.0666\n",
            "120/186, train_loss: 0.0331\n",
            "121/186, train_loss: 0.0424\n",
            "122/186, train_loss: 0.4110\n",
            "123/186, train_loss: 1.9192\n",
            "124/186, train_loss: 0.0593\n",
            "125/186, train_loss: 0.0499\n",
            "126/186, train_loss: 0.0583\n",
            "127/186, train_loss: 0.0494\n",
            "128/186, train_loss: 0.0865\n",
            "129/186, train_loss: 0.0476\n",
            "130/186, train_loss: 0.3636\n",
            "131/186, train_loss: 0.0073\n",
            "132/186, train_loss: 0.0121\n",
            "133/186, train_loss: 0.0138\n",
            "134/186, train_loss: 0.0589\n",
            "135/186, train_loss: 0.0559\n",
            "136/186, train_loss: 0.0492\n",
            "137/186, train_loss: 0.0510\n",
            "138/186, train_loss: 0.0530\n",
            "139/186, train_loss: 0.0358\n",
            "140/186, train_loss: 0.1003\n",
            "141/186, train_loss: 1.8698\n",
            "142/186, train_loss: 0.4105\n",
            "143/186, train_loss: 0.1072\n",
            "144/186, train_loss: 0.6590\n",
            "145/186, train_loss: 0.0295\n",
            "146/186, train_loss: 0.1025\n",
            "147/186, train_loss: 0.0660\n",
            "148/186, train_loss: 0.0781\n",
            "149/186, train_loss: 0.0872\n",
            "150/186, train_loss: 0.0568\n",
            "151/186, train_loss: 0.2423\n",
            "152/186, train_loss: 0.0528\n",
            "153/186, train_loss: 1.1842\n",
            "154/186, train_loss: 0.0233\n",
            "155/186, train_loss: 0.0456\n",
            "156/186, train_loss: 0.3244\n",
            "157/186, train_loss: 0.1257\n",
            "158/186, train_loss: 0.1048\n",
            "159/186, train_loss: 0.0209\n",
            "160/186, train_loss: 0.0256\n",
            "161/186, train_loss: 0.1583\n",
            "162/186, train_loss: 0.0498\n",
            "163/186, train_loss: 1.5605\n",
            "164/186, train_loss: 0.0524\n",
            "165/186, train_loss: 0.9763\n",
            "166/186, train_loss: 0.0560\n",
            "167/186, train_loss: 0.1009\n",
            "168/186, train_loss: 0.0532\n",
            "169/186, train_loss: 0.0250\n",
            "170/186, train_loss: 0.1695\n",
            "171/186, train_loss: 0.0069\n",
            "172/186, train_loss: 0.1586\n",
            "173/186, train_loss: 0.1036\n",
            "174/186, train_loss: 0.0416\n",
            "175/186, train_loss: 0.1023\n",
            "176/186, train_loss: 0.5899\n",
            "177/186, train_loss: 0.0297\n",
            "178/186, train_loss: 0.0978\n",
            "179/186, train_loss: 0.0185\n",
            "180/186, train_loss: 0.0748\n",
            "181/186, train_loss: 0.0216\n",
            "182/186, train_loss: 0.0172\n",
            "183/186, train_loss: 0.4280\n",
            "184/186, train_loss: 0.9371\n",
            "185/186, train_loss: 0.1234\n",
            "186/186, train_loss: 0.1757\n",
            "epoch 25 average loss: 0.1869\n",
            "----------\n",
            "epoch 26/50\n",
            "1/186, train_loss: 0.0946\n",
            "2/186, train_loss: 0.3273\n",
            "3/186, train_loss: 0.0166\n",
            "4/186, train_loss: 0.0078\n",
            "5/186, train_loss: 0.0608\n",
            "6/186, train_loss: 0.0234\n",
            "7/186, train_loss: 0.0346\n",
            "8/186, train_loss: 1.2935\n",
            "9/186, train_loss: 0.0507\n",
            "10/186, train_loss: 0.0064\n",
            "11/186, train_loss: 0.0983\n",
            "12/186, train_loss: 0.0076\n",
            "13/186, train_loss: 0.0489\n",
            "14/186, train_loss: 0.0247\n",
            "15/186, train_loss: 0.0271\n",
            "16/186, train_loss: 0.0257\n",
            "17/186, train_loss: 0.1769\n",
            "18/186, train_loss: 0.0849\n",
            "19/186, train_loss: 0.0081\n",
            "20/186, train_loss: 0.1200\n",
            "21/186, train_loss: 0.4352\n",
            "22/186, train_loss: 0.5619\n",
            "23/186, train_loss: 0.0994\n",
            "24/186, train_loss: 0.0887\n",
            "25/186, train_loss: 0.0637\n",
            "26/186, train_loss: 0.1029\n",
            "27/186, train_loss: 0.0482\n",
            "28/186, train_loss: 0.3766\n",
            "29/186, train_loss: 0.0339\n",
            "30/186, train_loss: 0.1032\n",
            "31/186, train_loss: 0.0058\n",
            "32/186, train_loss: 0.0568\n",
            "33/186, train_loss: 0.1438\n",
            "34/186, train_loss: 0.0539\n",
            "35/186, train_loss: 0.1205\n",
            "36/186, train_loss: 0.0298\n",
            "37/186, train_loss: 0.0105\n",
            "38/186, train_loss: 0.0066\n",
            "39/186, train_loss: 0.0185\n",
            "40/186, train_loss: 0.0259\n",
            "41/186, train_loss: 0.0708\n",
            "42/186, train_loss: 0.0059\n",
            "43/186, train_loss: 0.1373\n",
            "44/186, train_loss: 0.0444\n",
            "45/186, train_loss: 0.8772\n",
            "46/186, train_loss: 0.0116\n",
            "47/186, train_loss: 0.0692\n",
            "48/186, train_loss: 0.0022\n",
            "49/186, train_loss: 0.0155\n",
            "50/186, train_loss: 0.0450\n",
            "51/186, train_loss: 0.2317\n",
            "52/186, train_loss: 0.0940\n",
            "53/186, train_loss: 0.0168\n",
            "54/186, train_loss: 0.0348\n",
            "55/186, train_loss: 0.0090\n",
            "56/186, train_loss: 0.3987\n",
            "57/186, train_loss: 0.9623\n",
            "58/186, train_loss: 0.0138\n",
            "59/186, train_loss: 0.1247\n",
            "60/186, train_loss: 0.0106\n",
            "61/186, train_loss: 0.3660\n",
            "62/186, train_loss: 0.0129\n",
            "63/186, train_loss: 0.0372\n",
            "64/186, train_loss: 0.3584\n",
            "65/186, train_loss: 0.0047\n",
            "66/186, train_loss: 0.0019\n",
            "67/186, train_loss: 0.3740\n",
            "68/186, train_loss: 0.0578\n",
            "69/186, train_loss: 0.0494\n",
            "70/186, train_loss: 0.0234\n",
            "71/186, train_loss: 0.0522\n",
            "72/186, train_loss: 0.2181\n",
            "73/186, train_loss: 0.0250\n",
            "74/186, train_loss: 0.0473\n",
            "75/186, train_loss: 0.0082\n",
            "76/186, train_loss: 0.0502\n",
            "77/186, train_loss: 0.0501\n",
            "78/186, train_loss: 0.0074\n",
            "79/186, train_loss: 0.5985\n",
            "80/186, train_loss: 0.0049\n",
            "81/186, train_loss: 1.8127\n",
            "82/186, train_loss: 0.3719\n",
            "83/186, train_loss: 1.3816\n",
            "84/186, train_loss: 0.0498\n",
            "85/186, train_loss: 0.5848\n",
            "86/186, train_loss: 0.1972\n",
            "87/186, train_loss: 0.0142\n",
            "88/186, train_loss: 0.3941\n",
            "89/186, train_loss: 0.5945\n",
            "90/186, train_loss: 0.0685\n",
            "91/186, train_loss: 0.5370\n",
            "92/186, train_loss: 0.2216\n",
            "93/186, train_loss: 0.0750\n",
            "94/186, train_loss: 0.0112\n",
            "95/186, train_loss: 0.1937\n",
            "96/186, train_loss: 0.0888\n",
            "97/186, train_loss: 0.0332\n",
            "98/186, train_loss: 0.6721\n",
            "99/186, train_loss: 0.0730\n",
            "100/186, train_loss: 0.0173\n",
            "101/186, train_loss: 0.3733\n",
            "102/186, train_loss: 0.0075\n",
            "103/186, train_loss: 0.0057\n",
            "104/186, train_loss: 1.2988\n",
            "105/186, train_loss: 0.3488\n",
            "106/186, train_loss: 0.0142\n",
            "107/186, train_loss: 0.7234\n",
            "108/186, train_loss: 0.1017\n",
            "109/186, train_loss: 0.0359\n",
            "110/186, train_loss: 0.0110\n",
            "111/186, train_loss: 0.9912\n",
            "112/186, train_loss: 0.1669\n",
            "113/186, train_loss: 0.0101\n",
            "114/186, train_loss: 0.0406\n",
            "115/186, train_loss: 0.5851\n",
            "116/186, train_loss: 0.0111\n",
            "117/186, train_loss: 0.1067\n",
            "118/186, train_loss: 0.1754\n",
            "119/186, train_loss: 0.1555\n",
            "120/186, train_loss: 0.2032\n",
            "121/186, train_loss: 0.0908\n",
            "122/186, train_loss: 0.0563\n",
            "123/186, train_loss: 0.0774\n",
            "124/186, train_loss: 0.3513\n",
            "125/186, train_loss: 0.0324\n",
            "126/186, train_loss: 0.1654\n",
            "127/186, train_loss: 0.0101\n",
            "128/186, train_loss: 0.2141\n",
            "129/186, train_loss: 0.0519\n",
            "130/186, train_loss: 0.1729\n",
            "131/186, train_loss: 0.1627\n",
            "132/186, train_loss: 0.2000\n",
            "133/186, train_loss: 0.2806\n",
            "134/186, train_loss: 0.1490\n",
            "135/186, train_loss: 0.0118\n",
            "136/186, train_loss: 0.0112\n",
            "137/186, train_loss: 0.2162\n",
            "138/186, train_loss: 0.0263\n",
            "139/186, train_loss: 0.1920\n",
            "140/186, train_loss: 0.0242\n",
            "141/186, train_loss: 0.0127\n",
            "142/186, train_loss: 0.0802\n",
            "143/186, train_loss: 0.1239\n",
            "144/186, train_loss: 0.6404\n",
            "145/186, train_loss: 0.0229\n",
            "146/186, train_loss: 0.4035\n",
            "147/186, train_loss: 0.3743\n",
            "148/186, train_loss: 0.3269\n",
            "149/186, train_loss: 0.0466\n",
            "150/186, train_loss: 0.0037\n",
            "151/186, train_loss: 0.0582\n",
            "152/186, train_loss: 0.0204\n",
            "153/186, train_loss: 0.0611\n",
            "154/186, train_loss: 0.0514\n",
            "155/186, train_loss: 0.3695\n",
            "156/186, train_loss: 0.0590\n",
            "157/186, train_loss: 0.0153\n",
            "158/186, train_loss: 0.0493\n",
            "159/186, train_loss: 0.0641\n",
            "160/186, train_loss: 0.0712\n",
            "161/186, train_loss: 0.3166\n",
            "162/186, train_loss: 0.2697\n",
            "163/186, train_loss: 0.2988\n",
            "164/186, train_loss: 0.0024\n",
            "165/186, train_loss: 0.0872\n",
            "166/186, train_loss: 0.0506\n",
            "167/186, train_loss: 0.0067\n",
            "168/186, train_loss: 0.0754\n",
            "169/186, train_loss: 0.0224\n",
            "170/186, train_loss: 0.0066\n",
            "171/186, train_loss: 0.6979\n",
            "172/186, train_loss: 0.4518\n",
            "173/186, train_loss: 0.0549\n",
            "174/186, train_loss: 0.0127\n",
            "175/186, train_loss: 0.1527\n",
            "176/186, train_loss: 0.3849\n",
            "177/186, train_loss: 0.0127\n",
            "178/186, train_loss: 0.0461\n",
            "179/186, train_loss: 0.3547\n",
            "180/186, train_loss: 0.0876\n",
            "181/186, train_loss: 0.0119\n",
            "182/186, train_loss: 0.0823\n",
            "183/186, train_loss: 0.0081\n",
            "184/186, train_loss: 0.1631\n",
            "185/186, train_loss: 0.0447\n",
            "186/186, train_loss: 0.0683\n",
            "epoch 26 average loss: 0.1738\n",
            "current epoch: 26 current accuracy: 0.8495 best accuracy: 0.8817 at epoch 8\n",
            "----------\n",
            "epoch 27/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/186, train_loss: 0.0513\n",
            "2/186, train_loss: 0.0652\n",
            "3/186, train_loss: 0.0802\n",
            "4/186, train_loss: 0.1685\n",
            "5/186, train_loss: 0.1939\n",
            "6/186, train_loss: 0.1343\n",
            "7/186, train_loss: 0.0024\n",
            "8/186, train_loss: 0.0142\n",
            "9/186, train_loss: 0.0720\n",
            "10/186, train_loss: 0.0366\n",
            "11/186, train_loss: 0.0157\n",
            "12/186, train_loss: 0.0519\n",
            "13/186, train_loss: 0.0567\n",
            "14/186, train_loss: 2.6292\n",
            "15/186, train_loss: 0.1380\n",
            "16/186, train_loss: 0.2000\n",
            "17/186, train_loss: 0.0471\n",
            "18/186, train_loss: 0.3693\n",
            "19/186, train_loss: 0.0047\n",
            "20/186, train_loss: 0.0241\n",
            "21/186, train_loss: 0.0089\n",
            "22/186, train_loss: 0.1163\n",
            "23/186, train_loss: 0.1960\n",
            "24/186, train_loss: 0.0072\n",
            "25/186, train_loss: 0.0750\n",
            "26/186, train_loss: 0.0576\n",
            "27/186, train_loss: 0.0172\n",
            "28/186, train_loss: 0.0656\n",
            "29/186, train_loss: 0.0437\n",
            "30/186, train_loss: 0.0127\n",
            "31/186, train_loss: 0.0552\n",
            "32/186, train_loss: 0.0643\n",
            "33/186, train_loss: 0.0938\n",
            "34/186, train_loss: 0.1266\n",
            "35/186, train_loss: 0.1896\n",
            "36/186, train_loss: 0.0519\n",
            "37/186, train_loss: 0.0074\n",
            "38/186, train_loss: 0.1040\n",
            "39/186, train_loss: 0.0127\n",
            "40/186, train_loss: 0.1286\n",
            "41/186, train_loss: 0.0753\n",
            "42/186, train_loss: 0.0847\n",
            "43/186, train_loss: 0.0868\n",
            "44/186, train_loss: 0.2427\n",
            "45/186, train_loss: 0.0770\n",
            "46/186, train_loss: 0.0373\n",
            "47/186, train_loss: 0.1122\n",
            "48/186, train_loss: 0.0374\n",
            "49/186, train_loss: 0.0422\n",
            "50/186, train_loss: 0.0192\n",
            "51/186, train_loss: 0.4071\n",
            "52/186, train_loss: 0.0669\n",
            "53/186, train_loss: 0.0484\n",
            "54/186, train_loss: 0.0095\n",
            "55/186, train_loss: 0.0757\n",
            "56/186, train_loss: 0.2067\n",
            "57/186, train_loss: 0.6095\n",
            "58/186, train_loss: 0.0206\n",
            "59/186, train_loss: 0.0375\n",
            "60/186, train_loss: 0.0598\n",
            "61/186, train_loss: 0.0835\n",
            "62/186, train_loss: 0.0494\n",
            "63/186, train_loss: 0.3385\n",
            "64/186, train_loss: 0.3830\n",
            "65/186, train_loss: 0.0074\n",
            "66/186, train_loss: 0.0500\n",
            "67/186, train_loss: 0.0766\n",
            "68/186, train_loss: 0.0620\n",
            "69/186, train_loss: 0.0441\n",
            "70/186, train_loss: 0.1366\n",
            "71/186, train_loss: 0.0384\n",
            "72/186, train_loss: 0.0363\n",
            "73/186, train_loss: 0.0195\n",
            "74/186, train_loss: 0.2044\n",
            "75/186, train_loss: 0.0660\n",
            "76/186, train_loss: 0.7936\n",
            "77/186, train_loss: 0.0669\n",
            "78/186, train_loss: 0.0158\n",
            "79/186, train_loss: 1.5550\n",
            "80/186, train_loss: 0.0036\n",
            "81/186, train_loss: 0.3064\n",
            "82/186, train_loss: 0.0818\n",
            "83/186, train_loss: 0.0065\n",
            "84/186, train_loss: 0.3686\n",
            "85/186, train_loss: 2.0682\n",
            "86/186, train_loss: 0.0388\n",
            "87/186, train_loss: 0.0104\n",
            "88/186, train_loss: 0.1512\n",
            "89/186, train_loss: 0.4889\n",
            "90/186, train_loss: 0.1840\n",
            "91/186, train_loss: 0.3251\n",
            "92/186, train_loss: 0.0495\n",
            "93/186, train_loss: 0.0428\n",
            "94/186, train_loss: 1.4974\n",
            "95/186, train_loss: 0.0661\n",
            "96/186, train_loss: 0.8412\n",
            "97/186, train_loss: 0.1475\n",
            "98/186, train_loss: 0.1008\n",
            "99/186, train_loss: 0.3986\n",
            "100/186, train_loss: 0.4498\n",
            "101/186, train_loss: 0.0125\n",
            "102/186, train_loss: 0.0266\n",
            "103/186, train_loss: 0.0193\n",
            "104/186, train_loss: 0.1652\n",
            "105/186, train_loss: 0.0278\n",
            "106/186, train_loss: 0.1206\n",
            "107/186, train_loss: 0.8064\n",
            "108/186, train_loss: 0.2077\n",
            "109/186, train_loss: 0.0499\n",
            "110/186, train_loss: 0.1572\n",
            "111/186, train_loss: 0.1535\n",
            "112/186, train_loss: 0.1666\n",
            "113/186, train_loss: 0.0333\n",
            "114/186, train_loss: 0.0871\n",
            "115/186, train_loss: 0.0032\n",
            "116/186, train_loss: 0.0093\n",
            "117/186, train_loss: 0.4216\n",
            "118/186, train_loss: 0.2816\n",
            "119/186, train_loss: 0.0049\n",
            "120/186, train_loss: 0.0106\n",
            "121/186, train_loss: 0.0195\n",
            "122/186, train_loss: 0.5276\n",
            "123/186, train_loss: 0.0172\n",
            "124/186, train_loss: 0.0573\n",
            "125/186, train_loss: 0.0882\n",
            "126/186, train_loss: 0.0102\n",
            "127/186, train_loss: 0.0284\n",
            "128/186, train_loss: 0.0485\n",
            "129/186, train_loss: 0.0254\n",
            "130/186, train_loss: 0.0557\n",
            "131/186, train_loss: 0.0133\n",
            "132/186, train_loss: 0.0520\n",
            "133/186, train_loss: 0.7556\n",
            "134/186, train_loss: 0.0847\n",
            "135/186, train_loss: 0.0160\n",
            "136/186, train_loss: 0.0197\n",
            "137/186, train_loss: 0.0041\n",
            "138/186, train_loss: 0.3502\n",
            "139/186, train_loss: 0.3102\n",
            "140/186, train_loss: 0.0829\n",
            "141/186, train_loss: 0.0771\n",
            "142/186, train_loss: 0.0190\n",
            "143/186, train_loss: 0.1079\n",
            "144/186, train_loss: 0.6134\n",
            "145/186, train_loss: 0.0060\n",
            "146/186, train_loss: 0.0810\n",
            "147/186, train_loss: 0.0057\n",
            "148/186, train_loss: 0.0486\n",
            "149/186, train_loss: 0.1585\n",
            "150/186, train_loss: 0.1159\n",
            "151/186, train_loss: 0.0044\n",
            "152/186, train_loss: 0.0803\n",
            "153/186, train_loss: 0.4646\n",
            "154/186, train_loss: 0.0029\n",
            "155/186, train_loss: 0.2945\n",
            "156/186, train_loss: 0.0106\n",
            "157/186, train_loss: 0.0110\n",
            "158/186, train_loss: 0.0428\n",
            "159/186, train_loss: 0.0811\n",
            "160/186, train_loss: 0.0580\n",
            "161/186, train_loss: 0.0051\n",
            "162/186, train_loss: 0.0851\n",
            "163/186, train_loss: 0.0115\n",
            "164/186, train_loss: 0.0073\n",
            "165/186, train_loss: 0.0482\n",
            "166/186, train_loss: 1.6746\n",
            "167/186, train_loss: 0.0557\n",
            "168/186, train_loss: 0.4006\n",
            "169/186, train_loss: 0.1783\n",
            "170/186, train_loss: 0.0234\n",
            "171/186, train_loss: 0.3276\n",
            "172/186, train_loss: 0.0056\n",
            "173/186, train_loss: 0.0552\n",
            "174/186, train_loss: 0.0116\n",
            "175/186, train_loss: 0.3258\n",
            "176/186, train_loss: 0.2736\n",
            "177/186, train_loss: 0.0914\n",
            "178/186, train_loss: 0.0600\n",
            "179/186, train_loss: 0.0643\n",
            "180/186, train_loss: 1.1995\n",
            "181/186, train_loss: 0.0067\n",
            "182/186, train_loss: 0.0679\n",
            "183/186, train_loss: 0.0700\n",
            "184/186, train_loss: 0.0589\n",
            "185/186, train_loss: 0.0499\n",
            "186/186, train_loss: 0.8657\n",
            "epoch 27 average loss: 0.1798\n",
            "----------\n",
            "epoch 28/50\n",
            "1/186, train_loss: 0.0083\n",
            "2/186, train_loss: 0.0054\n",
            "3/186, train_loss: 0.0106\n",
            "4/186, train_loss: 0.0467\n",
            "5/186, train_loss: 0.0848\n",
            "6/186, train_loss: 0.1476\n",
            "7/186, train_loss: 0.0981\n",
            "8/186, train_loss: 0.0072\n",
            "9/186, train_loss: 0.0292\n",
            "10/186, train_loss: 0.0092\n",
            "11/186, train_loss: 0.1046\n",
            "12/186, train_loss: 0.0295\n",
            "13/186, train_loss: 0.0618\n",
            "14/186, train_loss: 0.0149\n",
            "15/186, train_loss: 0.0350\n",
            "16/186, train_loss: 0.0472\n",
            "17/186, train_loss: 0.0313\n",
            "18/186, train_loss: 0.0788\n",
            "19/186, train_loss: 0.0432\n",
            "20/186, train_loss: 0.0236\n",
            "21/186, train_loss: 0.0499\n",
            "22/186, train_loss: 1.3671\n",
            "23/186, train_loss: 0.0143\n",
            "24/186, train_loss: 0.0451\n",
            "25/186, train_loss: 0.0678\n",
            "26/186, train_loss: 0.0076\n",
            "27/186, train_loss: 0.2366\n",
            "28/186, train_loss: 0.0568\n",
            "29/186, train_loss: 0.0777\n",
            "30/186, train_loss: 0.3790\n",
            "31/186, train_loss: 0.2856\n",
            "32/186, train_loss: 0.1613\n",
            "33/186, train_loss: 0.0526\n",
            "34/186, train_loss: 0.0035\n",
            "35/186, train_loss: 0.2700\n",
            "36/186, train_loss: 0.0130\n",
            "37/186, train_loss: 0.3110\n",
            "38/186, train_loss: 0.1162\n",
            "39/186, train_loss: 0.0895\n",
            "40/186, train_loss: 1.3986\n",
            "41/186, train_loss: 0.0764\n",
            "42/186, train_loss: 0.0243\n",
            "43/186, train_loss: 0.0513\n",
            "44/186, train_loss: 0.1111\n",
            "45/186, train_loss: 0.0517\n",
            "46/186, train_loss: 0.2639\n",
            "47/186, train_loss: 0.0741\n",
            "48/186, train_loss: 0.0527\n",
            "49/186, train_loss: 0.0102\n",
            "50/186, train_loss: 0.0087\n",
            "51/186, train_loss: 0.0182\n",
            "52/186, train_loss: 0.1614\n",
            "53/186, train_loss: 0.2480\n",
            "54/186, train_loss: 0.0730\n",
            "55/186, train_loss: 0.0064\n",
            "56/186, train_loss: 0.3231\n",
            "57/186, train_loss: 0.0765\n",
            "58/186, train_loss: 0.3753\n",
            "59/186, train_loss: 0.0107\n",
            "60/186, train_loss: 0.0516\n",
            "61/186, train_loss: 0.0096\n",
            "62/186, train_loss: 0.0075\n",
            "63/186, train_loss: 0.0134\n",
            "64/186, train_loss: 0.3963\n",
            "65/186, train_loss: 0.0465\n",
            "66/186, train_loss: 0.0074\n",
            "67/186, train_loss: 0.0532\n",
            "68/186, train_loss: 0.0089\n",
            "69/186, train_loss: 0.0947\n",
            "70/186, train_loss: 0.0467\n",
            "71/186, train_loss: 0.5951\n",
            "72/186, train_loss: 0.0739\n",
            "73/186, train_loss: 0.0137\n",
            "74/186, train_loss: 0.1081\n",
            "75/186, train_loss: 0.0882\n",
            "76/186, train_loss: 0.0100\n",
            "77/186, train_loss: 0.0073\n",
            "78/186, train_loss: 0.1745\n",
            "79/186, train_loss: 0.2801\n",
            "80/186, train_loss: 0.0048\n",
            "81/186, train_loss: 0.0579\n",
            "82/186, train_loss: 0.0325\n",
            "83/186, train_loss: 0.0117\n",
            "84/186, train_loss: 0.0679\n",
            "85/186, train_loss: 0.3834\n",
            "86/186, train_loss: 0.0624\n",
            "87/186, train_loss: 0.0456\n",
            "88/186, train_loss: 0.0456\n",
            "89/186, train_loss: 0.0076\n",
            "90/186, train_loss: 0.0568\n",
            "91/186, train_loss: 0.0941\n",
            "92/186, train_loss: 0.0060\n",
            "93/186, train_loss: 0.1319\n",
            "94/186, train_loss: 0.2416\n",
            "95/186, train_loss: 0.2888\n",
            "96/186, train_loss: 0.0164\n",
            "97/186, train_loss: 0.3002\n",
            "98/186, train_loss: 0.0453\n",
            "99/186, train_loss: 0.6908\n",
            "100/186, train_loss: 0.0577\n",
            "101/186, train_loss: 0.0035\n",
            "102/186, train_loss: 0.0288\n",
            "103/186, train_loss: 0.1029\n",
            "104/186, train_loss: 0.0129\n",
            "105/186, train_loss: 0.1249\n",
            "106/186, train_loss: 0.0068\n",
            "107/186, train_loss: 0.0797\n",
            "108/186, train_loss: 0.3419\n",
            "109/186, train_loss: 0.2039\n",
            "110/186, train_loss: 0.0717\n",
            "111/186, train_loss: 0.0040\n",
            "112/186, train_loss: 0.0153\n",
            "113/186, train_loss: 0.3342\n",
            "114/186, train_loss: 0.2030\n",
            "115/186, train_loss: 0.0641\n",
            "116/186, train_loss: 0.0383\n",
            "117/186, train_loss: 1.2167\n",
            "118/186, train_loss: 0.2340\n",
            "119/186, train_loss: 0.0488\n",
            "120/186, train_loss: 0.0486\n",
            "121/186, train_loss: 0.0085\n",
            "122/186, train_loss: 0.0383\n",
            "123/186, train_loss: 0.3338\n",
            "124/186, train_loss: 0.2896\n",
            "125/186, train_loss: 0.0342\n",
            "126/186, train_loss: 0.0197\n",
            "127/186, train_loss: 0.0205\n",
            "128/186, train_loss: 0.4065\n",
            "129/186, train_loss: 0.6240\n",
            "130/186, train_loss: 0.0580\n",
            "131/186, train_loss: 1.6234\n",
            "132/186, train_loss: 0.0159\n",
            "133/186, train_loss: 0.0065\n",
            "134/186, train_loss: 0.0820\n",
            "135/186, train_loss: 0.0245\n",
            "136/186, train_loss: 0.0425\n",
            "137/186, train_loss: 0.0503\n",
            "138/186, train_loss: 0.0555\n",
            "139/186, train_loss: 0.0132\n",
            "140/186, train_loss: 0.0709\n",
            "141/186, train_loss: 0.0437\n",
            "142/186, train_loss: 0.0658\n",
            "143/186, train_loss: 0.0093\n",
            "144/186, train_loss: 0.0431\n",
            "145/186, train_loss: 0.0578\n",
            "146/186, train_loss: 0.4630\n",
            "147/186, train_loss: 0.0480\n",
            "148/186, train_loss: 0.4896\n",
            "149/186, train_loss: 0.6879\n",
            "150/186, train_loss: 0.0666\n",
            "151/186, train_loss: 0.0079\n",
            "152/186, train_loss: 0.0228\n",
            "153/186, train_loss: 0.0654\n",
            "154/186, train_loss: 0.0066\n",
            "155/186, train_loss: 0.0107\n",
            "156/186, train_loss: 0.0142\n",
            "157/186, train_loss: 0.5213\n",
            "158/186, train_loss: 0.1534\n",
            "159/186, train_loss: 0.0883\n",
            "160/186, train_loss: 0.1308\n",
            "161/186, train_loss: 0.1296\n",
            "162/186, train_loss: 0.0121\n",
            "163/186, train_loss: 0.0097\n",
            "164/186, train_loss: 0.2512\n",
            "165/186, train_loss: 0.0522\n",
            "166/186, train_loss: 0.2202\n",
            "167/186, train_loss: 0.0766\n",
            "168/186, train_loss: 0.0536\n",
            "169/186, train_loss: 2.1569\n",
            "170/186, train_loss: 0.0892\n",
            "171/186, train_loss: 0.0656\n",
            "172/186, train_loss: 0.0681\n",
            "173/186, train_loss: 0.0326\n",
            "174/186, train_loss: 0.0661\n",
            "175/186, train_loss: 0.1118\n",
            "176/186, train_loss: 0.3362\n",
            "177/186, train_loss: 0.0637\n",
            "178/186, train_loss: 0.0126\n",
            "179/186, train_loss: 0.0748\n",
            "180/186, train_loss: 0.0581\n",
            "181/186, train_loss: 0.0425\n",
            "182/186, train_loss: 0.0739\n",
            "183/186, train_loss: 0.1841\n",
            "184/186, train_loss: 0.0272\n",
            "185/186, train_loss: 0.2475\n",
            "186/186, train_loss: 0.2122\n",
            "epoch 28 average loss: 0.1473\n",
            "current epoch: 28 current accuracy: 0.7957 best accuracy: 0.8817 at epoch 8\n",
            "----------\n",
            "epoch 29/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/186, train_loss: 0.0553\n",
            "2/186, train_loss: 0.0921\n",
            "3/186, train_loss: 0.0189\n",
            "4/186, train_loss: 0.0062\n",
            "5/186, train_loss: 0.0486\n",
            "6/186, train_loss: 0.1034\n",
            "7/186, train_loss: 0.0691\n",
            "8/186, train_loss: 0.4585\n",
            "9/186, train_loss: 0.0254\n",
            "10/186, train_loss: 0.0203\n",
            "11/186, train_loss: 0.0971\n",
            "12/186, train_loss: 0.0256\n",
            "13/186, train_loss: 0.0709\n",
            "14/186, train_loss: 0.0409\n",
            "15/186, train_loss: 0.0635\n",
            "16/186, train_loss: 0.0200\n",
            "17/186, train_loss: 0.0454\n",
            "18/186, train_loss: 0.0722\n",
            "19/186, train_loss: 0.0100\n",
            "20/186, train_loss: 0.0097\n",
            "21/186, train_loss: 0.0476\n",
            "22/186, train_loss: 0.0045\n",
            "23/186, train_loss: 0.0861\n",
            "24/186, train_loss: 0.0382\n",
            "25/186, train_loss: 0.0769\n",
            "26/186, train_loss: 0.0456\n",
            "27/186, train_loss: 0.2038\n",
            "28/186, train_loss: 0.0140\n",
            "29/186, train_loss: 0.4399\n",
            "30/186, train_loss: 0.0055\n",
            "31/186, train_loss: 0.0704\n",
            "32/186, train_loss: 0.0250\n",
            "33/186, train_loss: 0.0644\n",
            "34/186, train_loss: 0.0109\n",
            "35/186, train_loss: 0.0627\n",
            "36/186, train_loss: 0.0113\n",
            "37/186, train_loss: 0.2390\n",
            "38/186, train_loss: 0.1192\n",
            "39/186, train_loss: 0.0098\n",
            "40/186, train_loss: 0.0137\n",
            "41/186, train_loss: 0.3631\n",
            "42/186, train_loss: 0.0464\n",
            "43/186, train_loss: 0.5059\n",
            "44/186, train_loss: 0.0393\n",
            "45/186, train_loss: 0.0510\n",
            "46/186, train_loss: 0.0243\n",
            "47/186, train_loss: 0.0138\n",
            "48/186, train_loss: 0.0232\n",
            "49/186, train_loss: 1.0783\n",
            "50/186, train_loss: 0.0478\n",
            "51/186, train_loss: 0.0334\n",
            "52/186, train_loss: 0.0606\n",
            "53/186, train_loss: 2.0455\n",
            "54/186, train_loss: 0.0075\n",
            "55/186, train_loss: 0.2348\n",
            "56/186, train_loss: 0.0445\n",
            "57/186, train_loss: 0.0611\n",
            "58/186, train_loss: 0.0245\n",
            "59/186, train_loss: 0.0130\n",
            "60/186, train_loss: 0.0428\n",
            "61/186, train_loss: 0.0338\n",
            "62/186, train_loss: 0.0519\n",
            "63/186, train_loss: 0.0210\n",
            "64/186, train_loss: 0.0482\n",
            "65/186, train_loss: 0.0586\n",
            "66/186, train_loss: 0.0083\n",
            "67/186, train_loss: 0.0031\n",
            "68/186, train_loss: 0.2345\n",
            "69/186, train_loss: 0.0831\n",
            "70/186, train_loss: 0.0267\n",
            "71/186, train_loss: 0.0723\n",
            "72/186, train_loss: 0.0038\n",
            "73/186, train_loss: 0.4068\n",
            "74/186, train_loss: 0.0458\n",
            "75/186, train_loss: 0.0047\n",
            "76/186, train_loss: 0.1578\n",
            "77/186, train_loss: 0.0485\n",
            "78/186, train_loss: 0.0495\n",
            "79/186, train_loss: 0.0654\n",
            "80/186, train_loss: 0.0480\n",
            "81/186, train_loss: 0.0787\n",
            "82/186, train_loss: 0.2525\n",
            "83/186, train_loss: 0.0268\n",
            "84/186, train_loss: 0.0073\n",
            "85/186, train_loss: 0.0124\n",
            "86/186, train_loss: 0.3222\n",
            "87/186, train_loss: 0.0238\n",
            "88/186, train_loss: 2.5478\n",
            "89/186, train_loss: 0.1242\n",
            "90/186, train_loss: 1.1070\n",
            "91/186, train_loss: 0.0537\n",
            "92/186, train_loss: 0.0444\n",
            "93/186, train_loss: 0.0644\n",
            "94/186, train_loss: 0.0147\n",
            "95/186, train_loss: 0.2167\n",
            "96/186, train_loss: 0.1749\n",
            "97/186, train_loss: 0.0337\n",
            "98/186, train_loss: 0.0150\n",
            "99/186, train_loss: 0.2939\n",
            "100/186, train_loss: 1.7459\n",
            "101/186, train_loss: 0.0256\n",
            "102/186, train_loss: 0.0462\n",
            "103/186, train_loss: 0.0261\n",
            "104/186, train_loss: 0.0091\n",
            "105/186, train_loss: 0.5697\n",
            "106/186, train_loss: 0.0955\n",
            "107/186, train_loss: 0.0214\n",
            "108/186, train_loss: 0.0994\n",
            "109/186, train_loss: 0.7399\n",
            "110/186, train_loss: 0.2849\n",
            "111/186, train_loss: 0.0640\n",
            "112/186, train_loss: 0.0552\n",
            "113/186, train_loss: 0.0311\n",
            "114/186, train_loss: 0.1217\n",
            "115/186, train_loss: 0.1320\n",
            "116/186, train_loss: 0.3476\n",
            "117/186, train_loss: 0.0718\n",
            "118/186, train_loss: 0.6743\n",
            "119/186, train_loss: 0.0121\n",
            "120/186, train_loss: 0.0515\n",
            "121/186, train_loss: 0.3605\n",
            "122/186, train_loss: 0.0295\n",
            "123/186, train_loss: 0.0390\n",
            "124/186, train_loss: 0.0493\n",
            "125/186, train_loss: 0.0671\n",
            "126/186, train_loss: 0.2124\n",
            "127/186, train_loss: 0.0094\n",
            "128/186, train_loss: 0.4096\n",
            "129/186, train_loss: 0.0500\n",
            "130/186, train_loss: 0.1016\n",
            "131/186, train_loss: 0.0956\n",
            "132/186, train_loss: 0.0250\n",
            "133/186, train_loss: 0.3978\n",
            "134/186, train_loss: 0.0644\n",
            "135/186, train_loss: 0.0457\n",
            "136/186, train_loss: 0.0862\n",
            "137/186, train_loss: 0.1070\n",
            "138/186, train_loss: 0.0544\n",
            "139/186, train_loss: 0.0094\n",
            "140/186, train_loss: 0.1788\n",
            "141/186, train_loss: 0.1755\n",
            "142/186, train_loss: 0.0488\n",
            "143/186, train_loss: 0.0589\n",
            "144/186, train_loss: 0.0534\n",
            "145/186, train_loss: 0.4948\n",
            "146/186, train_loss: 0.0145\n",
            "147/186, train_loss: 0.1032\n",
            "148/186, train_loss: 0.1223\n",
            "149/186, train_loss: 0.0453\n",
            "150/186, train_loss: 0.1006\n",
            "151/186, train_loss: 0.0408\n",
            "152/186, train_loss: 0.0062\n",
            "153/186, train_loss: 0.0354\n",
            "154/186, train_loss: 0.0322\n",
            "155/186, train_loss: 0.0531\n",
            "156/186, train_loss: 0.3526\n",
            "157/186, train_loss: 0.0852\n",
            "158/186, train_loss: 0.1295\n",
            "159/186, train_loss: 0.0141\n",
            "160/186, train_loss: 0.0219\n",
            "161/186, train_loss: 0.0579\n",
            "162/186, train_loss: 0.4040\n",
            "163/186, train_loss: 0.0565\n",
            "164/186, train_loss: 0.0187\n",
            "165/186, train_loss: 0.0441\n",
            "166/186, train_loss: 0.2868\n",
            "167/186, train_loss: 0.2688\n",
            "168/186, train_loss: 0.0503\n",
            "169/186, train_loss: 0.0188\n",
            "170/186, train_loss: 0.2925\n",
            "171/186, train_loss: 0.0667\n",
            "172/186, train_loss: 0.0209\n",
            "173/186, train_loss: 0.2422\n",
            "174/186, train_loss: 0.1336\n",
            "175/186, train_loss: 0.0369\n",
            "176/186, train_loss: 0.0093\n",
            "177/186, train_loss: 0.0495\n",
            "178/186, train_loss: 0.0739\n",
            "179/186, train_loss: 0.1310\n",
            "180/186, train_loss: 0.0740\n",
            "181/186, train_loss: 0.0467\n",
            "182/186, train_loss: 0.0208\n",
            "183/186, train_loss: 0.0185\n",
            "184/186, train_loss: 0.0165\n",
            "185/186, train_loss: 0.0029\n",
            "186/186, train_loss: 0.0089\n",
            "epoch 29 average loss: 0.1433\n",
            "----------\n",
            "epoch 30/50\n",
            "1/186, train_loss: 0.3079\n",
            "2/186, train_loss: 0.0377\n",
            "3/186, train_loss: 0.0288\n",
            "4/186, train_loss: 0.0057\n",
            "5/186, train_loss: 0.0205\n",
            "6/186, train_loss: 0.0338\n",
            "7/186, train_loss: 0.0448\n",
            "8/186, train_loss: 0.1395\n",
            "9/186, train_loss: 0.0789\n",
            "10/186, train_loss: 0.0706\n",
            "11/186, train_loss: 0.0171\n",
            "12/186, train_loss: 0.0500\n",
            "13/186, train_loss: 0.0479\n",
            "14/186, train_loss: 0.4491\n",
            "15/186, train_loss: 0.0105\n",
            "16/186, train_loss: 0.0202\n",
            "17/186, train_loss: 0.1116\n",
            "18/186, train_loss: 0.0845\n",
            "19/186, train_loss: 0.0492\n",
            "20/186, train_loss: 0.0031\n",
            "21/186, train_loss: 0.0423\n",
            "22/186, train_loss: 0.2444\n",
            "23/186, train_loss: 0.0123\n",
            "24/186, train_loss: 0.1584\n",
            "25/186, train_loss: 0.0036\n",
            "26/186, train_loss: 0.0557\n",
            "27/186, train_loss: 0.1592\n",
            "28/186, train_loss: 0.0210\n",
            "29/186, train_loss: 0.0512\n",
            "30/186, train_loss: 0.0670\n",
            "31/186, train_loss: 0.1806\n",
            "32/186, train_loss: 0.0792\n",
            "33/186, train_loss: 0.0456\n",
            "34/186, train_loss: 0.0222\n",
            "35/186, train_loss: 0.0676\n",
            "36/186, train_loss: 0.0873\n",
            "37/186, train_loss: 0.2342\n",
            "38/186, train_loss: 0.0398\n",
            "39/186, train_loss: 0.2144\n",
            "40/186, train_loss: 0.0405\n",
            "41/186, train_loss: 0.0367\n",
            "42/186, train_loss: 0.0661\n",
            "43/186, train_loss: 0.0451\n",
            "44/186, train_loss: 0.1233\n",
            "45/186, train_loss: 0.0417\n",
            "46/186, train_loss: 0.9910\n",
            "47/186, train_loss: 0.6475\n",
            "48/186, train_loss: 0.7268\n",
            "49/186, train_loss: 0.0346\n",
            "50/186, train_loss: 0.2177\n",
            "51/186, train_loss: 0.0133\n",
            "52/186, train_loss: 0.0644\n",
            "53/186, train_loss: 0.0208\n",
            "54/186, train_loss: 0.1544\n",
            "55/186, train_loss: 0.0398\n",
            "56/186, train_loss: 0.0984\n",
            "57/186, train_loss: 1.9787\n",
            "58/186, train_loss: 0.4127\n",
            "59/186, train_loss: 0.0780\n",
            "60/186, train_loss: 0.3078\n",
            "61/186, train_loss: 0.0372\n",
            "62/186, train_loss: 0.0230\n",
            "63/186, train_loss: 0.0153\n",
            "64/186, train_loss: 0.2613\n",
            "65/186, train_loss: 0.0390\n",
            "66/186, train_loss: 0.0391\n",
            "67/186, train_loss: 0.0407\n",
            "68/186, train_loss: 0.0045\n",
            "69/186, train_loss: 0.0855\n",
            "70/186, train_loss: 0.1864\n",
            "71/186, train_loss: 0.0444\n",
            "72/186, train_loss: 1.7467\n",
            "73/186, train_loss: 0.0801\n",
            "74/186, train_loss: 0.3798\n",
            "75/186, train_loss: 0.2646\n",
            "76/186, train_loss: 0.0489\n",
            "77/186, train_loss: 0.3782\n",
            "78/186, train_loss: 0.0540\n",
            "79/186, train_loss: 0.6849\n",
            "80/186, train_loss: 0.0060\n",
            "81/186, train_loss: 0.0672\n",
            "82/186, train_loss: 0.0664\n",
            "83/186, train_loss: 0.2305\n",
            "84/186, train_loss: 0.5124\n",
            "85/186, train_loss: 0.0317\n",
            "86/186, train_loss: 1.2539\n",
            "87/186, train_loss: 1.3651\n",
            "88/186, train_loss: 0.0463\n",
            "89/186, train_loss: 0.1013\n",
            "90/186, train_loss: 0.2809\n",
            "91/186, train_loss: 0.4877\n",
            "92/186, train_loss: 0.0113\n",
            "93/186, train_loss: 0.0153\n",
            "94/186, train_loss: 0.1223\n",
            "95/186, train_loss: 0.0455\n",
            "96/186, train_loss: 0.0751\n",
            "97/186, train_loss: 0.0406\n",
            "98/186, train_loss: 0.0484\n",
            "99/186, train_loss: 0.0212\n",
            "100/186, train_loss: 0.1072\n",
            "101/186, train_loss: 0.2059\n",
            "102/186, train_loss: 0.0040\n",
            "103/186, train_loss: 0.6227\n",
            "104/186, train_loss: 0.0053\n",
            "105/186, train_loss: 0.1016\n",
            "106/186, train_loss: 0.0494\n",
            "107/186, train_loss: 0.0040\n",
            "108/186, train_loss: 0.2871\n",
            "109/186, train_loss: 0.0446\n",
            "110/186, train_loss: 0.0561\n",
            "111/186, train_loss: 0.0490\n",
            "112/186, train_loss: 0.0348\n",
            "113/186, train_loss: 0.0862\n",
            "114/186, train_loss: 0.0550\n",
            "115/186, train_loss: 0.0151\n",
            "116/186, train_loss: 0.0712\n",
            "117/186, train_loss: 0.0210\n",
            "118/186, train_loss: 0.0413\n",
            "119/186, train_loss: 0.2086\n",
            "120/186, train_loss: 0.0643\n",
            "121/186, train_loss: 0.0960\n",
            "122/186, train_loss: 0.0687\n",
            "123/186, train_loss: 0.0062\n",
            "124/186, train_loss: 0.0400\n",
            "125/186, train_loss: 0.0060\n",
            "126/186, train_loss: 0.2464\n",
            "127/186, train_loss: 0.0083\n",
            "128/186, train_loss: 0.0665\n",
            "129/186, train_loss: 0.0439\n",
            "130/186, train_loss: 0.0104\n",
            "131/186, train_loss: 0.0394\n",
            "132/186, train_loss: 0.0403\n",
            "133/186, train_loss: 0.0210\n",
            "134/186, train_loss: 0.2176\n",
            "135/186, train_loss: 0.0414\n",
            "136/186, train_loss: 0.1985\n",
            "137/186, train_loss: 0.0126\n",
            "138/186, train_loss: 0.0059\n",
            "139/186, train_loss: 0.0431\n",
            "140/186, train_loss: 0.0019\n",
            "141/186, train_loss: 0.0843\n",
            "142/186, train_loss: 0.2222\n",
            "143/186, train_loss: 0.0251\n",
            "144/186, train_loss: 0.1870\n",
            "145/186, train_loss: 0.0090\n",
            "146/186, train_loss: 0.2282\n",
            "147/186, train_loss: 0.0365\n",
            "148/186, train_loss: 0.0411\n",
            "149/186, train_loss: 0.1999\n",
            "150/186, train_loss: 0.3121\n",
            "151/186, train_loss: 0.0428\n",
            "152/186, train_loss: 0.0123\n",
            "153/186, train_loss: 0.0037\n",
            "154/186, train_loss: 0.0098\n",
            "155/186, train_loss: 0.0060\n",
            "156/186, train_loss: 0.0102\n",
            "157/186, train_loss: 0.0270\n",
            "158/186, train_loss: 0.0128\n",
            "159/186, train_loss: 0.1529\n",
            "160/186, train_loss: 0.0056\n",
            "161/186, train_loss: 0.0541\n",
            "162/186, train_loss: 0.0550\n",
            "163/186, train_loss: 0.0105\n",
            "164/186, train_loss: 0.0208\n",
            "165/186, train_loss: 0.0030\n",
            "166/186, train_loss: 0.0457\n",
            "167/186, train_loss: 0.4511\n",
            "168/186, train_loss: 0.0127\n",
            "169/186, train_loss: 0.0718\n",
            "170/186, train_loss: 0.1747\n",
            "171/186, train_loss: 0.0070\n",
            "172/186, train_loss: 0.0394\n",
            "173/186, train_loss: 0.0488\n",
            "174/186, train_loss: 1.7881\n",
            "175/186, train_loss: 0.2401\n",
            "176/186, train_loss: 0.0529\n",
            "177/186, train_loss: 0.0030\n",
            "178/186, train_loss: 1.0442\n",
            "179/186, train_loss: 0.0190\n",
            "180/186, train_loss: 0.0440\n",
            "181/186, train_loss: 0.0214\n",
            "182/186, train_loss: 0.0604\n",
            "183/186, train_loss: 0.2119\n",
            "184/186, train_loss: 0.0393\n",
            "185/186, train_loss: 0.0894\n",
            "186/186, train_loss: 0.5231\n",
            "epoch 30 average loss: 0.1553\n",
            "current epoch: 30 current accuracy: 0.8387 best accuracy: 0.8817 at epoch 8\n",
            "----------\n",
            "epoch 31/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/186, train_loss: 0.0799\n",
            "2/186, train_loss: 0.0603\n",
            "3/186, train_loss: 0.0673\n",
            "4/186, train_loss: 0.0529\n",
            "5/186, train_loss: 0.6057\n",
            "6/186, train_loss: 0.1077\n",
            "7/186, train_loss: 0.0502\n",
            "8/186, train_loss: 0.1399\n",
            "9/186, train_loss: 0.0522\n",
            "10/186, train_loss: 0.0788\n",
            "11/186, train_loss: 0.0798\n",
            "12/186, train_loss: 0.3423\n",
            "13/186, train_loss: 0.1210\n",
            "14/186, train_loss: 0.0300\n",
            "15/186, train_loss: 0.0253\n",
            "16/186, train_loss: 0.0373\n",
            "17/186, train_loss: 0.0520\n",
            "18/186, train_loss: 0.6138\n",
            "19/186, train_loss: 0.0237\n",
            "20/186, train_loss: 0.2443\n",
            "21/186, train_loss: 0.0478\n",
            "22/186, train_loss: 0.0404\n",
            "23/186, train_loss: 0.3425\n",
            "24/186, train_loss: 0.1571\n",
            "25/186, train_loss: 0.0370\n",
            "26/186, train_loss: 0.0181\n",
            "27/186, train_loss: 0.0102\n",
            "28/186, train_loss: 0.0086\n",
            "29/186, train_loss: 0.0063\n",
            "30/186, train_loss: 0.0793\n",
            "31/186, train_loss: 0.0429\n",
            "32/186, train_loss: 0.0437\n",
            "33/186, train_loss: 0.3551\n",
            "34/186, train_loss: 0.0199\n",
            "35/186, train_loss: 0.0451\n",
            "36/186, train_loss: 0.2225\n",
            "37/186, train_loss: 0.0439\n",
            "38/186, train_loss: 0.0497\n",
            "39/186, train_loss: 0.0476\n",
            "40/186, train_loss: 0.0320\n",
            "41/186, train_loss: 0.0387\n",
            "42/186, train_loss: 0.0126\n",
            "43/186, train_loss: 0.0056\n",
            "44/186, train_loss: 0.0068\n",
            "45/186, train_loss: 0.0388\n",
            "46/186, train_loss: 0.1181\n",
            "47/186, train_loss: 0.3727\n",
            "48/186, train_loss: 0.1337\n",
            "49/186, train_loss: 0.0683\n",
            "50/186, train_loss: 0.0136\n",
            "51/186, train_loss: 0.0380\n",
            "52/186, train_loss: 0.0425\n",
            "53/186, train_loss: 0.0050\n",
            "54/186, train_loss: 0.4646\n",
            "55/186, train_loss: 0.1225\n",
            "56/186, train_loss: 0.0557\n",
            "57/186, train_loss: 0.0094\n",
            "58/186, train_loss: 0.1399\n",
            "59/186, train_loss: 0.0070\n",
            "60/186, train_loss: 0.0578\n",
            "61/186, train_loss: 0.0735\n",
            "62/186, train_loss: 0.0050\n",
            "63/186, train_loss: 0.0194\n",
            "64/186, train_loss: 0.0100\n",
            "65/186, train_loss: 0.0152\n",
            "66/186, train_loss: 0.0079\n",
            "67/186, train_loss: 0.0315\n",
            "68/186, train_loss: 0.0119\n",
            "69/186, train_loss: 0.1869\n",
            "70/186, train_loss: 0.0059\n",
            "71/186, train_loss: 1.5688\n",
            "72/186, train_loss: 0.2441\n",
            "73/186, train_loss: 0.0618\n",
            "74/186, train_loss: 0.0870\n",
            "75/186, train_loss: 0.0067\n",
            "76/186, train_loss: 0.2274\n",
            "77/186, train_loss: 0.0090\n",
            "78/186, train_loss: 0.2248\n",
            "79/186, train_loss: 0.0348\n",
            "80/186, train_loss: 0.0382\n",
            "81/186, train_loss: 0.0064\n",
            "82/186, train_loss: 0.6322\n",
            "83/186, train_loss: 0.0560\n",
            "84/186, train_loss: 0.0387\n",
            "85/186, train_loss: 0.0476\n",
            "86/186, train_loss: 0.0174\n",
            "87/186, train_loss: 0.0302\n",
            "88/186, train_loss: 0.0061\n",
            "89/186, train_loss: 0.0358\n",
            "90/186, train_loss: 0.2861\n",
            "91/186, train_loss: 0.0074\n",
            "92/186, train_loss: 0.0066\n",
            "93/186, train_loss: 0.2089\n",
            "94/186, train_loss: 0.2534\n",
            "95/186, train_loss: 0.0391\n",
            "96/186, train_loss: 0.0039\n",
            "97/186, train_loss: 0.0362\n",
            "98/186, train_loss: 0.0330\n",
            "99/186, train_loss: 0.0244\n",
            "100/186, train_loss: 0.0150\n",
            "101/186, train_loss: 0.6777\n",
            "102/186, train_loss: 0.2416\n",
            "103/186, train_loss: 0.0253\n",
            "104/186, train_loss: 0.0041\n",
            "105/186, train_loss: 0.0683\n",
            "106/186, train_loss: 0.0244\n",
            "107/186, train_loss: 0.1333\n",
            "108/186, train_loss: 0.0309\n",
            "109/186, train_loss: 0.2537\n",
            "110/186, train_loss: 2.2428\n",
            "111/186, train_loss: 0.5983\n",
            "112/186, train_loss: 0.0067\n",
            "113/186, train_loss: 0.0072\n",
            "114/186, train_loss: 0.0205\n",
            "115/186, train_loss: 0.0386\n",
            "116/186, train_loss: 0.0075\n",
            "117/186, train_loss: 0.4470\n",
            "118/186, train_loss: 0.1225\n",
            "119/186, train_loss: 0.0068\n",
            "120/186, train_loss: 0.0745\n",
            "121/186, train_loss: 0.7737\n",
            "122/186, train_loss: 0.0026\n",
            "123/186, train_loss: 0.0450\n",
            "124/186, train_loss: 0.0847\n",
            "125/186, train_loss: 0.1728\n",
            "126/186, train_loss: 0.2845\n",
            "127/186, train_loss: 0.0705\n",
            "128/186, train_loss: 0.0263\n",
            "129/186, train_loss: 0.1105\n",
            "130/186, train_loss: 0.0955\n",
            "131/186, train_loss: 0.0045\n",
            "132/186, train_loss: 0.2652\n",
            "133/186, train_loss: 0.0111\n",
            "134/186, train_loss: 0.0367\n",
            "135/186, train_loss: 1.4781\n",
            "136/186, train_loss: 0.0930\n",
            "137/186, train_loss: 0.0327\n",
            "138/186, train_loss: 0.0515\n",
            "139/186, train_loss: 0.4871\n",
            "140/186, train_loss: 0.2293\n",
            "141/186, train_loss: 0.0362\n",
            "142/186, train_loss: 0.0747\n",
            "143/186, train_loss: 0.0113\n",
            "144/186, train_loss: 0.0262\n",
            "145/186, train_loss: 0.0067\n",
            "146/186, train_loss: 0.2731\n",
            "147/186, train_loss: 0.0023\n",
            "148/186, train_loss: 1.9419\n",
            "149/186, train_loss: 0.1833\n",
            "150/186, train_loss: 0.0691\n",
            "151/186, train_loss: 0.0517\n",
            "152/186, train_loss: 0.0856\n",
            "153/186, train_loss: 0.0053\n",
            "154/186, train_loss: 0.0439\n",
            "155/186, train_loss: 0.0062\n",
            "156/186, train_loss: 0.0043\n",
            "157/186, train_loss: 0.0040\n",
            "158/186, train_loss: 0.0744\n",
            "159/186, train_loss: 0.0941\n",
            "160/186, train_loss: 0.5745\n",
            "161/186, train_loss: 0.0518\n",
            "162/186, train_loss: 0.8117\n",
            "163/186, train_loss: 0.0675\n",
            "164/186, train_loss: 0.4566\n",
            "165/186, train_loss: 0.0140\n",
            "166/186, train_loss: 0.1228\n",
            "167/186, train_loss: 0.0115\n",
            "168/186, train_loss: 0.0435\n",
            "169/186, train_loss: 0.1742\n",
            "170/186, train_loss: 1.5649\n",
            "171/186, train_loss: 0.0081\n",
            "172/186, train_loss: 0.0259\n",
            "173/186, train_loss: 0.2189\n",
            "174/186, train_loss: 0.1001\n",
            "175/186, train_loss: 0.0556\n",
            "176/186, train_loss: 2.1858\n",
            "177/186, train_loss: 0.0341\n",
            "178/186, train_loss: 0.0248\n",
            "179/186, train_loss: 0.1374\n",
            "180/186, train_loss: 0.0757\n",
            "181/186, train_loss: 0.0394\n",
            "182/186, train_loss: 0.0643\n",
            "183/186, train_loss: 0.0721\n",
            "184/186, train_loss: 0.7275\n",
            "185/186, train_loss: 0.0700\n",
            "186/186, train_loss: 0.0469\n",
            "epoch 31 average loss: 0.1671\n",
            "----------\n",
            "epoch 32/50\n",
            "1/186, train_loss: 0.1479\n",
            "2/186, train_loss: 0.1305\n",
            "3/186, train_loss: 0.0730\n",
            "4/186, train_loss: 0.3712\n",
            "5/186, train_loss: 0.0739\n",
            "6/186, train_loss: 0.0306\n",
            "7/186, train_loss: 0.0067\n",
            "8/186, train_loss: 0.0314\n",
            "9/186, train_loss: 0.0380\n",
            "10/186, train_loss: 0.0452\n",
            "11/186, train_loss: 0.0683\n",
            "12/186, train_loss: 0.1785\n",
            "13/186, train_loss: 0.2948\n",
            "14/186, train_loss: 0.0685\n",
            "15/186, train_loss: 0.0740\n",
            "16/186, train_loss: 0.0571\n",
            "17/186, train_loss: 0.0518\n",
            "18/186, train_loss: 0.0632\n",
            "19/186, train_loss: 0.0657\n",
            "20/186, train_loss: 0.0800\n",
            "21/186, train_loss: 0.0071\n",
            "22/186, train_loss: 0.0352\n",
            "23/186, train_loss: 0.6176\n",
            "24/186, train_loss: 0.1119\n",
            "25/186, train_loss: 0.0560\n",
            "26/186, train_loss: 0.0557\n",
            "27/186, train_loss: 0.0476\n",
            "28/186, train_loss: 0.0083\n",
            "29/186, train_loss: 0.0663\n",
            "30/186, train_loss: 0.1016\n",
            "31/186, train_loss: 0.1126\n",
            "32/186, train_loss: 0.0534\n",
            "33/186, train_loss: 0.0577\n",
            "34/186, train_loss: 0.0403\n",
            "35/186, train_loss: 0.0461\n",
            "36/186, train_loss: 0.0157\n",
            "37/186, train_loss: 0.3666\n",
            "38/186, train_loss: 0.0297\n",
            "39/186, train_loss: 1.0366\n",
            "40/186, train_loss: 0.0673\n",
            "41/186, train_loss: 0.2523\n",
            "42/186, train_loss: 0.0661\n",
            "43/186, train_loss: 0.0496\n",
            "44/186, train_loss: 0.0120\n",
            "45/186, train_loss: 0.0285\n",
            "46/186, train_loss: 0.2071\n",
            "47/186, train_loss: 0.0497\n",
            "48/186, train_loss: 0.0825\n",
            "49/186, train_loss: 0.0400\n",
            "50/186, train_loss: 0.0695\n",
            "51/186, train_loss: 0.2642\n",
            "52/186, train_loss: 0.0152\n",
            "53/186, train_loss: 0.8672\n",
            "54/186, train_loss: 0.0416\n",
            "55/186, train_loss: 0.0571\n",
            "56/186, train_loss: 0.0440\n",
            "57/186, train_loss: 0.0468\n",
            "58/186, train_loss: 0.0619\n",
            "59/186, train_loss: 0.2407\n",
            "60/186, train_loss: 0.1070\n",
            "61/186, train_loss: 0.0317\n",
            "62/186, train_loss: 0.0441\n",
            "63/186, train_loss: 0.0411\n",
            "64/186, train_loss: 0.0898\n",
            "65/186, train_loss: 0.0108\n",
            "66/186, train_loss: 0.0162\n",
            "67/186, train_loss: 0.1828\n",
            "68/186, train_loss: 0.0133\n",
            "69/186, train_loss: 0.0234\n",
            "70/186, train_loss: 0.2512\n",
            "71/186, train_loss: 0.0664\n",
            "72/186, train_loss: 0.6926\n",
            "73/186, train_loss: 0.1526\n",
            "74/186, train_loss: 0.0769\n",
            "75/186, train_loss: 0.1542\n",
            "76/186, train_loss: 0.0150\n",
            "77/186, train_loss: 0.0382\n",
            "78/186, train_loss: 0.0352\n",
            "79/186, train_loss: 0.2308\n",
            "80/186, train_loss: 0.3921\n",
            "81/186, train_loss: 0.2850\n",
            "82/186, train_loss: 0.0151\n",
            "83/186, train_loss: 0.0199\n",
            "84/186, train_loss: 1.5071\n",
            "85/186, train_loss: 0.0164\n",
            "86/186, train_loss: 0.0417\n",
            "87/186, train_loss: 0.0644\n",
            "88/186, train_loss: 0.0252\n",
            "89/186, train_loss: 0.0210\n",
            "90/186, train_loss: 0.0862\n",
            "91/186, train_loss: 0.3610\n",
            "92/186, train_loss: 0.0459\n",
            "93/186, train_loss: 0.0546\n",
            "94/186, train_loss: 0.3141\n",
            "95/186, train_loss: 0.0471\n",
            "96/186, train_loss: 0.0533\n",
            "97/186, train_loss: 0.0057\n",
            "98/186, train_loss: 0.0140\n",
            "99/186, train_loss: 0.0917\n",
            "100/186, train_loss: 0.0386\n",
            "101/186, train_loss: 0.1717\n",
            "102/186, train_loss: 0.0647\n",
            "103/186, train_loss: 1.5310\n",
            "104/186, train_loss: 0.0485\n",
            "105/186, train_loss: 0.0330\n",
            "106/186, train_loss: 0.0968\n",
            "107/186, train_loss: 0.0111\n",
            "108/186, train_loss: 0.0412\n",
            "109/186, train_loss: 0.0436\n",
            "110/186, train_loss: 0.0253\n",
            "111/186, train_loss: 0.1703\n",
            "112/186, train_loss: 1.1929\n",
            "113/186, train_loss: 0.0401\n",
            "114/186, train_loss: 0.1646\n",
            "115/186, train_loss: 0.0109\n",
            "116/186, train_loss: 0.5350\n",
            "117/186, train_loss: 0.0329\n",
            "118/186, train_loss: 0.0316\n",
            "119/186, train_loss: 0.0118\n",
            "120/186, train_loss: 0.0653\n",
            "121/186, train_loss: 0.1505\n",
            "122/186, train_loss: 0.0060\n",
            "123/186, train_loss: 0.0212\n",
            "124/186, train_loss: 0.0405\n",
            "125/186, train_loss: 0.0815\n",
            "126/186, train_loss: 0.2900\n",
            "127/186, train_loss: 0.2384\n",
            "128/186, train_loss: 0.0914\n",
            "129/186, train_loss: 0.0073\n",
            "130/186, train_loss: 0.0441\n",
            "131/186, train_loss: 0.0302\n",
            "132/186, train_loss: 0.0759\n",
            "133/186, train_loss: 0.0853\n",
            "134/186, train_loss: 0.1164\n",
            "135/186, train_loss: 0.0494\n",
            "136/186, train_loss: 0.0101\n",
            "137/186, train_loss: 0.0881\n",
            "138/186, train_loss: 0.0392\n",
            "139/186, train_loss: 0.0576\n",
            "140/186, train_loss: 0.0585\n",
            "141/186, train_loss: 0.0507\n",
            "142/186, train_loss: 0.1063\n",
            "143/186, train_loss: 0.0207\n",
            "144/186, train_loss: 0.0388\n",
            "145/186, train_loss: 0.0428\n",
            "146/186, train_loss: 0.0499\n",
            "147/186, train_loss: 0.0039\n",
            "148/186, train_loss: 0.0066\n",
            "149/186, train_loss: 0.0254\n",
            "150/186, train_loss: 0.0579\n",
            "151/186, train_loss: 0.0055\n",
            "152/186, train_loss: 0.0386\n",
            "153/186, train_loss: 0.2256\n",
            "154/186, train_loss: 0.2424\n",
            "155/186, train_loss: 0.0218\n",
            "156/186, train_loss: 0.0152\n",
            "157/186, train_loss: 0.1007\n",
            "158/186, train_loss: 0.1943\n",
            "159/186, train_loss: 0.0545\n",
            "160/186, train_loss: 0.0074\n",
            "161/186, train_loss: 0.0252\n",
            "162/186, train_loss: 0.1556\n",
            "163/186, train_loss: 0.0045\n",
            "164/186, train_loss: 0.0068\n",
            "165/186, train_loss: 0.0423\n",
            "166/186, train_loss: 0.1042\n",
            "167/186, train_loss: 0.3660\n",
            "168/186, train_loss: 0.2612\n",
            "169/186, train_loss: 0.0424\n",
            "170/186, train_loss: 0.1079\n",
            "171/186, train_loss: 0.0077\n",
            "172/186, train_loss: 0.2521\n",
            "173/186, train_loss: 0.0692\n",
            "174/186, train_loss: 0.0247\n",
            "175/186, train_loss: 0.0994\n",
            "176/186, train_loss: 0.1843\n",
            "177/186, train_loss: 0.0147\n",
            "178/186, train_loss: 0.1779\n",
            "179/186, train_loss: 0.0119\n",
            "180/186, train_loss: 0.0568\n",
            "181/186, train_loss: 0.0179\n",
            "182/186, train_loss: 0.1460\n",
            "183/186, train_loss: 0.0359\n",
            "184/186, train_loss: 0.0468\n",
            "185/186, train_loss: 0.0433\n",
            "186/186, train_loss: 0.0537\n",
            "epoch 32 average loss: 0.1222\n",
            "current epoch: 32 current accuracy: 0.8710 best accuracy: 0.8817 at epoch 8\n",
            "----------\n",
            "epoch 33/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/186, train_loss: 0.0412\n",
            "2/186, train_loss: 0.0370\n",
            "3/186, train_loss: 0.0023\n",
            "4/186, train_loss: 0.0594\n",
            "5/186, train_loss: 0.0828\n",
            "6/186, train_loss: 0.0159\n",
            "7/186, train_loss: 0.0378\n",
            "8/186, train_loss: 1.8329\n",
            "9/186, train_loss: 0.1755\n",
            "10/186, train_loss: 0.0489\n",
            "11/186, train_loss: 0.1379\n",
            "12/186, train_loss: 0.0209\n",
            "13/186, train_loss: 0.0427\n",
            "14/186, train_loss: 0.2167\n",
            "15/186, train_loss: 0.8434\n",
            "16/186, train_loss: 0.0487\n",
            "17/186, train_loss: 0.0491\n",
            "18/186, train_loss: 0.0190\n",
            "19/186, train_loss: 0.0075\n",
            "20/186, train_loss: 0.0165\n",
            "21/186, train_loss: 0.4211\n",
            "22/186, train_loss: 0.4356\n",
            "23/186, train_loss: 1.0283\n",
            "24/186, train_loss: 0.0749\n",
            "25/186, train_loss: 0.3406\n",
            "26/186, train_loss: 0.1560\n",
            "27/186, train_loss: 0.0260\n",
            "28/186, train_loss: 0.1748\n",
            "29/186, train_loss: 0.1285\n",
            "30/186, train_loss: 0.5759\n",
            "31/186, train_loss: 0.0496\n",
            "32/186, train_loss: 0.0152\n",
            "33/186, train_loss: 0.1851\n",
            "34/186, train_loss: 0.1250\n",
            "35/186, train_loss: 0.0520\n",
            "36/186, train_loss: 0.1657\n",
            "37/186, train_loss: 0.0225\n",
            "38/186, train_loss: 0.0401\n",
            "39/186, train_loss: 0.2086\n",
            "40/186, train_loss: 0.0600\n",
            "41/186, train_loss: 0.0830\n",
            "42/186, train_loss: 0.0272\n",
            "43/186, train_loss: 0.0815\n",
            "44/186, train_loss: 0.0205\n",
            "45/186, train_loss: 0.0129\n",
            "46/186, train_loss: 0.0665\n",
            "47/186, train_loss: 0.3513\n",
            "48/186, train_loss: 0.0567\n",
            "49/186, train_loss: 0.1177\n",
            "50/186, train_loss: 0.0123\n",
            "51/186, train_loss: 0.0404\n",
            "52/186, train_loss: 0.5418\n",
            "53/186, train_loss: 0.1089\n",
            "54/186, train_loss: 0.0505\n",
            "55/186, train_loss: 0.0119\n",
            "56/186, train_loss: 0.0170\n",
            "57/186, train_loss: 0.0408\n",
            "58/186, train_loss: 0.0051\n",
            "59/186, train_loss: 0.1009\n",
            "60/186, train_loss: 0.1516\n",
            "61/186, train_loss: 0.3795\n",
            "62/186, train_loss: 0.0480\n",
            "63/186, train_loss: 0.0090\n",
            "64/186, train_loss: 0.0030\n",
            "65/186, train_loss: 0.0072\n",
            "66/186, train_loss: 0.0695\n",
            "67/186, train_loss: 0.0439\n",
            "68/186, train_loss: 0.0330\n",
            "69/186, train_loss: 0.0143\n",
            "70/186, train_loss: 0.0102\n",
            "71/186, train_loss: 0.0154\n",
            "72/186, train_loss: 0.0216\n",
            "73/186, train_loss: 0.2922\n",
            "74/186, train_loss: 0.0316\n",
            "75/186, train_loss: 0.0028\n",
            "76/186, train_loss: 0.0151\n",
            "77/186, train_loss: 0.1175\n",
            "78/186, train_loss: 0.0035\n",
            "79/186, train_loss: 0.0137\n",
            "80/186, train_loss: 0.9763\n",
            "81/186, train_loss: 0.0547\n",
            "82/186, train_loss: 0.3453\n",
            "83/186, train_loss: 0.0019\n",
            "84/186, train_loss: 0.0903\n",
            "85/186, train_loss: 0.0099\n",
            "86/186, train_loss: 0.3368\n",
            "87/186, train_loss: 0.5415\n",
            "88/186, train_loss: 0.0054\n",
            "89/186, train_loss: 0.0448\n",
            "90/186, train_loss: 0.0597\n",
            "91/186, train_loss: 0.0078\n",
            "92/186, train_loss: 0.0602\n",
            "93/186, train_loss: 0.1296\n",
            "94/186, train_loss: 0.7880\n",
            "95/186, train_loss: 0.0663\n",
            "96/186, train_loss: 0.0426\n",
            "97/186, train_loss: 0.0235\n",
            "98/186, train_loss: 0.0206\n",
            "99/186, train_loss: 0.0379\n",
            "100/186, train_loss: 0.7179\n",
            "101/186, train_loss: 0.0442\n",
            "102/186, train_loss: 0.0231\n",
            "103/186, train_loss: 0.0084\n",
            "104/186, train_loss: 0.0399\n",
            "105/186, train_loss: 0.0509\n",
            "106/186, train_loss: 0.6887\n",
            "107/186, train_loss: 0.0857\n",
            "108/186, train_loss: 0.0383\n",
            "109/186, train_loss: 0.1240\n",
            "110/186, train_loss: 0.1574\n",
            "111/186, train_loss: 0.0294\n",
            "112/186, train_loss: 0.0390\n",
            "113/186, train_loss: 0.1553\n",
            "114/186, train_loss: 0.0943\n",
            "115/186, train_loss: 0.0347\n",
            "116/186, train_loss: 0.0122\n",
            "117/186, train_loss: 0.0174\n",
            "118/186, train_loss: 2.0694\n",
            "119/186, train_loss: 0.0351\n",
            "120/186, train_loss: 1.3693\n",
            "121/186, train_loss: 0.0126\n",
            "122/186, train_loss: 0.0601\n",
            "123/186, train_loss: 0.0844\n",
            "124/186, train_loss: 0.0401\n",
            "125/186, train_loss: 0.0270\n",
            "126/186, train_loss: 0.0331\n",
            "127/186, train_loss: 0.0607\n",
            "128/186, train_loss: 0.0267\n",
            "129/186, train_loss: 0.0470\n",
            "130/186, train_loss: 0.0273\n",
            "131/186, train_loss: 0.0385\n",
            "132/186, train_loss: 0.0217\n",
            "133/186, train_loss: 0.0681\n",
            "134/186, train_loss: 0.0208\n",
            "135/186, train_loss: 0.0147\n",
            "136/186, train_loss: 0.0230\n",
            "137/186, train_loss: 0.0439\n",
            "138/186, train_loss: 0.0126\n",
            "139/186, train_loss: 0.0390\n",
            "140/186, train_loss: 0.0669\n",
            "141/186, train_loss: 0.0260\n",
            "142/186, train_loss: 0.6217\n",
            "143/186, train_loss: 0.0094\n",
            "144/186, train_loss: 0.0826\n",
            "145/186, train_loss: 0.3529\n",
            "146/186, train_loss: 0.0418\n",
            "147/186, train_loss: 0.1680\n",
            "148/186, train_loss: 0.0331\n",
            "149/186, train_loss: 0.2310\n",
            "150/186, train_loss: 0.0624\n",
            "151/186, train_loss: 0.0067\n",
            "152/186, train_loss: 0.0529\n",
            "153/186, train_loss: 0.0515\n",
            "154/186, train_loss: 0.1143\n",
            "155/186, train_loss: 0.0663\n",
            "156/186, train_loss: 0.0119\n",
            "157/186, train_loss: 0.0643\n",
            "158/186, train_loss: 0.0338\n",
            "159/186, train_loss: 0.0985\n",
            "160/186, train_loss: 1.5621\n",
            "161/186, train_loss: 0.1140\n",
            "162/186, train_loss: 0.0347\n",
            "163/186, train_loss: 0.0365\n",
            "164/186, train_loss: 0.0428\n",
            "165/186, train_loss: 0.2832\n",
            "166/186, train_loss: 0.0815\n",
            "167/186, train_loss: 0.0901\n",
            "168/186, train_loss: 0.0750\n",
            "169/186, train_loss: 0.0352\n",
            "170/186, train_loss: 0.0437\n",
            "171/186, train_loss: 0.0837\n",
            "172/186, train_loss: 0.0600\n",
            "173/186, train_loss: 0.0153\n",
            "174/186, train_loss: 0.1028\n",
            "175/186, train_loss: 0.0589\n",
            "176/186, train_loss: 0.6641\n",
            "177/186, train_loss: 0.0487\n",
            "178/186, train_loss: 0.0432\n",
            "179/186, train_loss: 0.0089\n",
            "180/186, train_loss: 0.0604\n",
            "181/186, train_loss: 0.0123\n",
            "182/186, train_loss: 0.0043\n",
            "183/186, train_loss: 0.1609\n",
            "184/186, train_loss: 0.0085\n",
            "185/186, train_loss: 0.0088\n",
            "186/186, train_loss: 0.1243\n",
            "epoch 33 average loss: 0.1467\n",
            "----------\n",
            "epoch 34/50\n",
            "1/186, train_loss: 0.0358\n",
            "2/186, train_loss: 0.0067\n",
            "3/186, train_loss: 0.0620\n",
            "4/186, train_loss: 0.6102\n",
            "5/186, train_loss: 0.0239\n",
            "6/186, train_loss: 0.0119\n",
            "7/186, train_loss: 0.0332\n",
            "8/186, train_loss: 0.0122\n",
            "9/186, train_loss: 0.0187\n",
            "10/186, train_loss: 1.9302\n",
            "11/186, train_loss: 0.0116\n",
            "12/186, train_loss: 0.0459\n",
            "13/186, train_loss: 0.0478\n",
            "14/186, train_loss: 0.0055\n",
            "15/186, train_loss: 0.0409\n",
            "16/186, train_loss: 0.0148\n",
            "17/186, train_loss: 0.0671\n",
            "18/186, train_loss: 0.0145\n",
            "19/186, train_loss: 0.0578\n",
            "20/186, train_loss: 0.0068\n",
            "21/186, train_loss: 0.0076\n",
            "22/186, train_loss: 0.7259\n",
            "23/186, train_loss: 0.0083\n",
            "24/186, train_loss: 0.0302\n",
            "25/186, train_loss: 0.0218\n",
            "26/186, train_loss: 0.0138\n",
            "27/186, train_loss: 0.2294\n",
            "28/186, train_loss: 0.0415\n",
            "29/186, train_loss: 1.0202\n",
            "30/186, train_loss: 0.1872\n",
            "31/186, train_loss: 0.0508\n",
            "32/186, train_loss: 0.0336\n",
            "33/186, train_loss: 0.0777\n",
            "34/186, train_loss: 0.0086\n",
            "35/186, train_loss: 0.0110\n",
            "36/186, train_loss: 0.0929\n",
            "37/186, train_loss: 0.0516\n",
            "38/186, train_loss: 0.0134\n",
            "39/186, train_loss: 0.0502\n",
            "40/186, train_loss: 0.6157\n",
            "41/186, train_loss: 0.0564\n",
            "42/186, train_loss: 0.0687\n",
            "43/186, train_loss: 0.5877\n",
            "44/186, train_loss: 0.2930\n",
            "45/186, train_loss: 0.0401\n",
            "46/186, train_loss: 0.0992\n",
            "47/186, train_loss: 0.2271\n",
            "48/186, train_loss: 0.0094\n",
            "49/186, train_loss: 0.0145\n",
            "50/186, train_loss: 0.1520\n",
            "51/186, train_loss: 0.1420\n",
            "52/186, train_loss: 0.0402\n",
            "53/186, train_loss: 0.0480\n",
            "54/186, train_loss: 0.0323\n",
            "55/186, train_loss: 1.6578\n",
            "56/186, train_loss: 0.0072\n",
            "57/186, train_loss: 0.4504\n",
            "58/186, train_loss: 0.0253\n",
            "59/186, train_loss: 0.0677\n",
            "60/186, train_loss: 0.0378\n",
            "61/186, train_loss: 0.1988\n",
            "62/186, train_loss: 0.0168\n",
            "63/186, train_loss: 0.0294\n",
            "64/186, train_loss: 0.0318\n",
            "65/186, train_loss: 0.0255\n",
            "66/186, train_loss: 0.0078\n",
            "67/186, train_loss: 0.0387\n",
            "68/186, train_loss: 0.0121\n",
            "69/186, train_loss: 0.1249\n",
            "70/186, train_loss: 0.0257\n",
            "71/186, train_loss: 0.4891\n",
            "72/186, train_loss: 0.0378\n",
            "73/186, train_loss: 0.0179\n",
            "74/186, train_loss: 0.0213\n",
            "75/186, train_loss: 0.2581\n",
            "76/186, train_loss: 0.2000\n",
            "77/186, train_loss: 0.0226\n",
            "78/186, train_loss: 0.0354\n",
            "79/186, train_loss: 0.0580\n",
            "80/186, train_loss: 1.6883\n",
            "81/186, train_loss: 0.0561\n",
            "82/186, train_loss: 0.2963\n",
            "83/186, train_loss: 0.0910\n",
            "84/186, train_loss: 0.2671\n",
            "85/186, train_loss: 0.0416\n",
            "86/186, train_loss: 0.0567\n",
            "87/186, train_loss: 0.2873\n",
            "88/186, train_loss: 0.0113\n",
            "89/186, train_loss: 0.0204\n",
            "90/186, train_loss: 0.0199\n",
            "91/186, train_loss: 0.0127\n",
            "92/186, train_loss: 0.0753\n",
            "93/186, train_loss: 0.0764\n",
            "94/186, train_loss: 0.0588\n",
            "95/186, train_loss: 0.0339\n",
            "96/186, train_loss: 0.0131\n",
            "97/186, train_loss: 0.0077\n",
            "98/186, train_loss: 0.0200\n",
            "99/186, train_loss: 0.1592\n",
            "100/186, train_loss: 0.0198\n",
            "101/186, train_loss: 1.0518\n",
            "102/186, train_loss: 0.0861\n",
            "103/186, train_loss: 0.0277\n",
            "104/186, train_loss: 0.0178\n",
            "105/186, train_loss: 0.0247\n",
            "106/186, train_loss: 0.2098\n",
            "107/186, train_loss: 1.4104\n",
            "108/186, train_loss: 0.0354\n",
            "109/186, train_loss: 0.0058\n",
            "110/186, train_loss: 0.0394\n",
            "111/186, train_loss: 0.2948\n",
            "112/186, train_loss: 0.0378\n",
            "113/186, train_loss: 0.0663\n",
            "114/186, train_loss: 0.0149\n",
            "115/186, train_loss: 0.0208\n",
            "116/186, train_loss: 0.0175\n",
            "117/186, train_loss: 0.1152\n",
            "118/186, train_loss: 0.6129\n",
            "119/186, train_loss: 0.0087\n",
            "120/186, train_loss: 0.0578\n",
            "121/186, train_loss: 0.0811\n",
            "122/186, train_loss: 0.0085\n",
            "123/186, train_loss: 0.0826\n",
            "124/186, train_loss: 0.0263\n",
            "125/186, train_loss: 0.0092\n",
            "126/186, train_loss: 0.0156\n",
            "127/186, train_loss: 0.0053\n",
            "128/186, train_loss: 0.1110\n",
            "129/186, train_loss: 0.0161\n",
            "130/186, train_loss: 0.0514\n",
            "131/186, train_loss: 0.2473\n",
            "132/186, train_loss: 0.1195\n",
            "133/186, train_loss: 0.0831\n",
            "134/186, train_loss: 0.1554\n",
            "135/186, train_loss: 0.4978\n",
            "136/186, train_loss: 0.0619\n",
            "137/186, train_loss: 0.0452\n",
            "138/186, train_loss: 0.0092\n",
            "139/186, train_loss: 0.2289\n",
            "140/186, train_loss: 1.7628\n",
            "141/186, train_loss: 0.3153\n",
            "142/186, train_loss: 0.0170\n",
            "143/186, train_loss: 0.0519\n",
            "144/186, train_loss: 0.0371\n",
            "145/186, train_loss: 0.1271\n",
            "146/186, train_loss: 0.0165\n",
            "147/186, train_loss: 1.2536\n",
            "148/186, train_loss: 0.0457\n",
            "149/186, train_loss: 0.0263\n",
            "150/186, train_loss: 0.0383\n",
            "151/186, train_loss: 0.0397\n",
            "152/186, train_loss: 0.0200\n",
            "153/186, train_loss: 0.0333\n",
            "154/186, train_loss: 1.0194\n",
            "155/186, train_loss: 1.0103\n",
            "156/186, train_loss: 0.0132\n",
            "157/186, train_loss: 0.4932\n",
            "158/186, train_loss: 0.0538\n",
            "159/186, train_loss: 0.1035\n",
            "160/186, train_loss: 0.2243\n",
            "161/186, train_loss: 0.2122\n",
            "162/186, train_loss: 0.0045\n",
            "163/186, train_loss: 0.0717\n",
            "164/186, train_loss: 0.0445\n",
            "165/186, train_loss: 0.1160\n",
            "166/186, train_loss: 0.5253\n",
            "167/186, train_loss: 0.0531\n",
            "168/186, train_loss: 0.0090\n",
            "169/186, train_loss: 0.0500\n",
            "170/186, train_loss: 0.1818\n",
            "171/186, train_loss: 0.0186\n",
            "172/186, train_loss: 0.1034\n",
            "173/186, train_loss: 0.4205\n",
            "174/186, train_loss: 0.1313\n",
            "175/186, train_loss: 0.0935\n",
            "176/186, train_loss: 0.0063\n",
            "177/186, train_loss: 0.6484\n",
            "178/186, train_loss: 0.0472\n",
            "179/186, train_loss: 0.0029\n",
            "180/186, train_loss: 0.0056\n",
            "181/186, train_loss: 0.1850\n",
            "182/186, train_loss: 0.0641\n",
            "183/186, train_loss: 0.0064\n",
            "184/186, train_loss: 0.2130\n",
            "185/186, train_loss: 0.1549\n",
            "186/186, train_loss: 0.1720\n",
            "epoch 34 average loss: 0.1700\n",
            "saved new best metric model\n",
            "current epoch: 34 current accuracy: 0.9032 best accuracy: 0.9032 at epoch 34\n",
            "----------\n",
            "epoch 35/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/186, train_loss: 0.0483\n",
            "2/186, train_loss: 0.1987\n",
            "3/186, train_loss: 0.0889\n",
            "4/186, train_loss: 0.2341\n",
            "5/186, train_loss: 0.0013\n",
            "6/186, train_loss: 0.0119\n",
            "7/186, train_loss: 0.0390\n",
            "8/186, train_loss: 0.0590\n",
            "9/186, train_loss: 0.0619\n",
            "10/186, train_loss: 0.0064\n",
            "11/186, train_loss: 0.0049\n",
            "12/186, train_loss: 0.4529\n",
            "13/186, train_loss: 0.1428\n",
            "14/186, train_loss: 0.0602\n",
            "15/186, train_loss: 0.0087\n",
            "16/186, train_loss: 0.0153\n",
            "17/186, train_loss: 0.0890\n",
            "18/186, train_loss: 0.0237\n",
            "19/186, train_loss: 0.0067\n",
            "20/186, train_loss: 0.0110\n",
            "21/186, train_loss: 0.0810\n",
            "22/186, train_loss: 0.0073\n",
            "23/186, train_loss: 0.0571\n",
            "24/186, train_loss: 0.1883\n",
            "25/186, train_loss: 1.2522\n",
            "26/186, train_loss: 0.0119\n",
            "27/186, train_loss: 0.0681\n",
            "28/186, train_loss: 0.0464\n",
            "29/186, train_loss: 0.0279\n",
            "30/186, train_loss: 0.0053\n",
            "31/186, train_loss: 0.1080\n",
            "32/186, train_loss: 0.2279\n",
            "33/186, train_loss: 0.0612\n",
            "34/186, train_loss: 0.1536\n",
            "35/186, train_loss: 0.0493\n",
            "36/186, train_loss: 0.0388\n",
            "37/186, train_loss: 0.0106\n",
            "38/186, train_loss: 0.0208\n",
            "39/186, train_loss: 0.0619\n",
            "40/186, train_loss: 1.7005\n",
            "41/186, train_loss: 0.1349\n",
            "42/186, train_loss: 0.0349\n",
            "43/186, train_loss: 0.1723\n",
            "44/186, train_loss: 0.0197\n",
            "45/186, train_loss: 0.0554\n",
            "46/186, train_loss: 0.2145\n",
            "47/186, train_loss: 0.0414\n",
            "48/186, train_loss: 0.0593\n",
            "49/186, train_loss: 0.0380\n",
            "50/186, train_loss: 1.1218\n",
            "51/186, train_loss: 0.3247\n",
            "52/186, train_loss: 0.0163\n",
            "53/186, train_loss: 0.0273\n",
            "54/186, train_loss: 0.0443\n",
            "55/186, train_loss: 0.0156\n",
            "56/186, train_loss: 0.0404\n",
            "57/186, train_loss: 0.0267\n",
            "58/186, train_loss: 0.1587\n",
            "59/186, train_loss: 0.0505\n",
            "60/186, train_loss: 0.0284\n",
            "61/186, train_loss: 0.0315\n",
            "62/186, train_loss: 1.8629\n",
            "63/186, train_loss: 0.0372\n",
            "64/186, train_loss: 0.0698\n",
            "65/186, train_loss: 0.0075\n",
            "66/186, train_loss: 0.0387\n",
            "67/186, train_loss: 0.0547\n",
            "68/186, train_loss: 0.3850\n",
            "69/186, train_loss: 0.3369\n",
            "70/186, train_loss: 0.0630\n",
            "71/186, train_loss: 0.0329\n",
            "72/186, train_loss: 0.2341\n",
            "73/186, train_loss: 0.1647\n",
            "74/186, train_loss: 0.0848\n",
            "75/186, train_loss: 0.0475\n",
            "76/186, train_loss: 0.0107\n",
            "77/186, train_loss: 0.5031\n",
            "78/186, train_loss: 0.0404\n",
            "79/186, train_loss: 0.0354\n",
            "80/186, train_loss: 0.0178\n",
            "81/186, train_loss: 0.0427\n",
            "82/186, train_loss: 0.7803\n",
            "83/186, train_loss: 0.0981\n",
            "84/186, train_loss: 0.0632\n",
            "85/186, train_loss: 0.0338\n",
            "86/186, train_loss: 0.0637\n",
            "87/186, train_loss: 0.0301\n",
            "88/186, train_loss: 0.0594\n",
            "89/186, train_loss: 0.5816\n",
            "90/186, train_loss: 0.0110\n",
            "91/186, train_loss: 0.0436\n",
            "92/186, train_loss: 0.0762\n",
            "93/186, train_loss: 0.3783\n",
            "94/186, train_loss: 0.0803\n",
            "95/186, train_loss: 0.1764\n",
            "96/186, train_loss: 0.1513\n",
            "97/186, train_loss: 0.0228\n",
            "98/186, train_loss: 0.0040\n",
            "99/186, train_loss: 0.0381\n",
            "100/186, train_loss: 0.0223\n",
            "101/186, train_loss: 0.0689\n",
            "102/186, train_loss: 0.1658\n",
            "103/186, train_loss: 0.0044\n",
            "104/186, train_loss: 0.5350\n",
            "105/186, train_loss: 0.0409\n",
            "106/186, train_loss: 0.0361\n",
            "107/186, train_loss: 0.0168\n",
            "108/186, train_loss: 0.0312\n",
            "109/186, train_loss: 0.0352\n",
            "110/186, train_loss: 0.0667\n",
            "111/186, train_loss: 0.0115\n",
            "112/186, train_loss: 0.3966\n",
            "113/186, train_loss: 0.0035\n",
            "114/186, train_loss: 0.0328\n",
            "115/186, train_loss: 0.0636\n",
            "116/186, train_loss: 0.3686\n",
            "117/186, train_loss: 0.0461\n",
            "118/186, train_loss: 0.1599\n",
            "119/186, train_loss: 0.0340\n",
            "120/186, train_loss: 0.1728\n",
            "121/186, train_loss: 0.0272\n",
            "122/186, train_loss: 0.0562\n",
            "123/186, train_loss: 0.0409\n",
            "124/186, train_loss: 0.0321\n",
            "125/186, train_loss: 0.0137\n",
            "126/186, train_loss: 0.0325\n",
            "127/186, train_loss: 0.2625\n",
            "128/186, train_loss: 0.0149\n",
            "129/186, train_loss: 0.0770\n",
            "130/186, train_loss: 0.2338\n",
            "131/186, train_loss: 0.0033\n",
            "132/186, train_loss: 0.0328\n",
            "133/186, train_loss: 0.0519\n",
            "134/186, train_loss: 0.5432\n",
            "135/186, train_loss: 0.0329\n",
            "136/186, train_loss: 0.2615\n",
            "137/186, train_loss: 0.0062\n",
            "138/186, train_loss: 0.0488\n",
            "139/186, train_loss: 0.3386\n",
            "140/186, train_loss: 0.0421\n",
            "141/186, train_loss: 0.2055\n",
            "142/186, train_loss: 0.0828\n",
            "143/186, train_loss: 0.0049\n",
            "144/186, train_loss: 0.0575\n",
            "145/186, train_loss: 0.1398\n",
            "146/186, train_loss: 0.0186\n",
            "147/186, train_loss: 0.0262\n",
            "148/186, train_loss: 0.1445\n",
            "149/186, train_loss: 0.0384\n",
            "150/186, train_loss: 0.1386\n",
            "151/186, train_loss: 0.0719\n",
            "152/186, train_loss: 0.0093\n",
            "153/186, train_loss: 0.1559\n",
            "154/186, train_loss: 0.0117\n",
            "155/186, train_loss: 0.0831\n",
            "156/186, train_loss: 0.0231\n",
            "157/186, train_loss: 0.0076\n",
            "158/186, train_loss: 0.7497\n",
            "159/186, train_loss: 0.0172\n",
            "160/186, train_loss: 0.0674\n",
            "161/186, train_loss: 0.0046\n",
            "162/186, train_loss: 0.0058\n",
            "163/186, train_loss: 0.1333\n",
            "164/186, train_loss: 0.0330\n",
            "165/186, train_loss: 0.0163\n",
            "166/186, train_loss: 0.1464\n",
            "167/186, train_loss: 0.4302\n",
            "168/186, train_loss: 0.0806\n",
            "169/186, train_loss: 0.0116\n",
            "170/186, train_loss: 0.0344\n",
            "171/186, train_loss: 0.0324\n",
            "172/186, train_loss: 0.0146\n",
            "173/186, train_loss: 0.0396\n",
            "174/186, train_loss: 0.0064\n",
            "175/186, train_loss: 0.0577\n",
            "176/186, train_loss: 0.1219\n",
            "177/186, train_loss: 0.0041\n",
            "178/186, train_loss: 0.0426\n",
            "179/186, train_loss: 0.0640\n",
            "180/186, train_loss: 0.7842\n",
            "181/186, train_loss: 0.0881\n",
            "182/186, train_loss: 0.0151\n",
            "183/186, train_loss: 0.1864\n",
            "184/186, train_loss: 0.0095\n",
            "185/186, train_loss: 0.0115\n",
            "186/186, train_loss: 0.0580\n",
            "epoch 35 average loss: 0.1296\n",
            "----------\n",
            "epoch 36/50\n",
            "1/186, train_loss: 0.0039\n",
            "2/186, train_loss: 0.0573\n",
            "3/186, train_loss: 0.0664\n",
            "4/186, train_loss: 0.0044\n",
            "5/186, train_loss: 0.0567\n",
            "6/186, train_loss: 0.0405\n",
            "7/186, train_loss: 0.1986\n",
            "8/186, train_loss: 0.0156\n",
            "9/186, train_loss: 1.6017\n",
            "10/186, train_loss: 0.0252\n",
            "11/186, train_loss: 0.0274\n",
            "12/186, train_loss: 0.0165\n",
            "13/186, train_loss: 0.0239\n",
            "14/186, train_loss: 0.0308\n",
            "15/186, train_loss: 0.0041\n",
            "16/186, train_loss: 0.0052\n",
            "17/186, train_loss: 0.0227\n",
            "18/186, train_loss: 0.0083\n",
            "19/186, train_loss: 0.0217\n",
            "20/186, train_loss: 0.0545\n",
            "21/186, train_loss: 0.0065\n",
            "22/186, train_loss: 0.0226\n",
            "23/186, train_loss: 0.0457\n",
            "24/186, train_loss: 0.1056\n",
            "25/186, train_loss: 0.0060\n",
            "26/186, train_loss: 0.0011\n",
            "27/186, train_loss: 0.1236\n",
            "28/186, train_loss: 0.0664\n",
            "29/186, train_loss: 0.0050\n",
            "30/186, train_loss: 1.8557\n",
            "31/186, train_loss: 0.0662\n",
            "32/186, train_loss: 0.0014\n",
            "33/186, train_loss: 0.0106\n",
            "34/186, train_loss: 0.0058\n",
            "35/186, train_loss: 0.0303\n",
            "36/186, train_loss: 0.0607\n",
            "37/186, train_loss: 0.0037\n",
            "38/186, train_loss: 0.0194\n",
            "39/186, train_loss: 0.0041\n",
            "40/186, train_loss: 0.0553\n",
            "41/186, train_loss: 0.0052\n",
            "42/186, train_loss: 0.0684\n",
            "43/186, train_loss: 0.0033\n",
            "44/186, train_loss: 0.0337\n",
            "45/186, train_loss: 0.0573\n",
            "46/186, train_loss: 0.0297\n",
            "47/186, train_loss: 0.0853\n",
            "48/186, train_loss: 0.0285\n",
            "49/186, train_loss: 0.0252\n",
            "50/186, train_loss: 0.0495\n",
            "51/186, train_loss: 0.1301\n",
            "52/186, train_loss: 0.0363\n",
            "53/186, train_loss: 0.1481\n",
            "54/186, train_loss: 0.0146\n",
            "55/186, train_loss: 0.0444\n",
            "56/186, train_loss: 0.1125\n",
            "57/186, train_loss: 0.0062\n",
            "58/186, train_loss: 0.0546\n",
            "59/186, train_loss: 0.0164\n",
            "60/186, train_loss: 0.0543\n",
            "61/186, train_loss: 0.0381\n",
            "62/186, train_loss: 0.0372\n",
            "63/186, train_loss: 0.0368\n",
            "64/186, train_loss: 0.1373\n",
            "65/186, train_loss: 0.1256\n",
            "66/186, train_loss: 0.0343\n",
            "67/186, train_loss: 1.6236\n",
            "68/186, train_loss: 0.0055\n",
            "69/186, train_loss: 0.0287\n",
            "70/186, train_loss: 0.2505\n",
            "71/186, train_loss: 0.0056\n",
            "72/186, train_loss: 0.0109\n",
            "73/186, train_loss: 0.0142\n",
            "74/186, train_loss: 0.0220\n",
            "75/186, train_loss: 0.0103\n",
            "76/186, train_loss: 0.0086\n",
            "77/186, train_loss: 0.0333\n",
            "78/186, train_loss: 0.0110\n",
            "79/186, train_loss: 0.3529\n",
            "80/186, train_loss: 0.1464\n",
            "81/186, train_loss: 0.1744\n",
            "82/186, train_loss: 0.0414\n",
            "83/186, train_loss: 0.0019\n",
            "84/186, train_loss: 0.1390\n",
            "85/186, train_loss: 0.0138\n",
            "86/186, train_loss: 0.0336\n",
            "87/186, train_loss: 0.0096\n",
            "88/186, train_loss: 0.0093\n",
            "89/186, train_loss: 0.0312\n",
            "90/186, train_loss: 0.1140\n",
            "91/186, train_loss: 0.0755\n",
            "92/186, train_loss: 0.0484\n",
            "93/186, train_loss: 0.0952\n",
            "94/186, train_loss: 0.0245\n",
            "95/186, train_loss: 0.0415\n",
            "96/186, train_loss: 0.0512\n",
            "97/186, train_loss: 0.3070\n",
            "98/186, train_loss: 0.1900\n",
            "99/186, train_loss: 0.0081\n",
            "100/186, train_loss: 0.0348\n",
            "101/186, train_loss: 0.1142\n",
            "102/186, train_loss: 0.1033\n",
            "103/186, train_loss: 0.0070\n",
            "104/186, train_loss: 0.0193\n",
            "105/186, train_loss: 0.0561\n",
            "106/186, train_loss: 0.0532\n",
            "107/186, train_loss: 0.0121\n",
            "108/186, train_loss: 0.1270\n",
            "109/186, train_loss: 0.0051\n",
            "110/186, train_loss: 0.0037\n",
            "111/186, train_loss: 0.1561\n",
            "112/186, train_loss: 1.1777\n",
            "113/186, train_loss: 0.0312\n",
            "114/186, train_loss: 0.0756\n",
            "115/186, train_loss: 0.0711\n",
            "116/186, train_loss: 0.0430\n",
            "117/186, train_loss: 0.1114\n",
            "118/186, train_loss: 0.2664\n",
            "119/186, train_loss: 0.0335\n",
            "120/186, train_loss: 0.0534\n",
            "121/186, train_loss: 0.1103\n",
            "122/186, train_loss: 0.0491\n",
            "123/186, train_loss: 0.0077\n",
            "124/186, train_loss: 0.1816\n",
            "125/186, train_loss: 0.0043\n",
            "126/186, train_loss: 0.0068\n",
            "127/186, train_loss: 0.0061\n",
            "128/186, train_loss: 0.0037\n",
            "129/186, train_loss: 0.0363\n",
            "130/186, train_loss: 0.0688\n",
            "131/186, train_loss: 0.0435\n",
            "132/186, train_loss: 1.4513\n",
            "133/186, train_loss: 0.2124\n",
            "134/186, train_loss: 0.0321\n",
            "135/186, train_loss: 0.2268\n",
            "136/186, train_loss: 0.1776\n",
            "137/186, train_loss: 0.0751\n",
            "138/186, train_loss: 0.0465\n",
            "139/186, train_loss: 0.1607\n",
            "140/186, train_loss: 0.1484\n",
            "141/186, train_loss: 0.0639\n",
            "142/186, train_loss: 0.0097\n",
            "143/186, train_loss: 0.0136\n",
            "144/186, train_loss: 0.0546\n",
            "145/186, train_loss: 0.0218\n",
            "146/186, train_loss: 0.0173\n",
            "147/186, train_loss: 0.0709\n",
            "148/186, train_loss: 0.0390\n",
            "149/186, train_loss: 0.4495\n",
            "150/186, train_loss: 0.0328\n",
            "151/186, train_loss: 0.0378\n",
            "152/186, train_loss: 0.0058\n",
            "153/186, train_loss: 0.0497\n",
            "154/186, train_loss: 0.1099\n",
            "155/186, train_loss: 0.3993\n",
            "156/186, train_loss: 0.0506\n",
            "157/186, train_loss: 0.0834\n",
            "158/186, train_loss: 0.0414\n",
            "159/186, train_loss: 0.0471\n",
            "160/186, train_loss: 0.0184\n",
            "161/186, train_loss: 0.0331\n",
            "162/186, train_loss: 0.0128\n",
            "163/186, train_loss: 1.7757\n",
            "164/186, train_loss: 0.0293\n",
            "165/186, train_loss: 0.5870\n",
            "166/186, train_loss: 0.0519\n",
            "167/186, train_loss: 0.1585\n",
            "168/186, train_loss: 0.0307\n",
            "169/186, train_loss: 0.0342\n",
            "170/186, train_loss: 0.0325\n",
            "171/186, train_loss: 0.3376\n",
            "172/186, train_loss: 0.0068\n",
            "173/186, train_loss: 0.1263\n",
            "174/186, train_loss: 0.0126\n",
            "175/186, train_loss: 0.1225\n",
            "176/186, train_loss: 0.1780\n",
            "177/186, train_loss: 0.0104\n",
            "178/186, train_loss: 0.0281\n",
            "179/186, train_loss: 0.0307\n",
            "180/186, train_loss: 0.0427\n",
            "181/186, train_loss: 0.0417\n",
            "182/186, train_loss: 0.0076\n",
            "183/186, train_loss: 0.0063\n",
            "184/186, train_loss: 0.2596\n",
            "185/186, train_loss: 0.0707\n",
            "186/186, train_loss: 0.0293\n",
            "epoch 36 average loss: 0.1151\n",
            "current epoch: 36 current accuracy: 0.8280 best accuracy: 0.9032 at epoch 34\n",
            "----------\n",
            "epoch 37/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/186, train_loss: 0.0164\n",
            "2/186, train_loss: 0.1813\n",
            "3/186, train_loss: 0.0871\n",
            "4/186, train_loss: 0.0310\n",
            "5/186, train_loss: 0.0622\n",
            "6/186, train_loss: 0.0287\n",
            "7/186, train_loss: 0.0037\n",
            "8/186, train_loss: 1.5140\n",
            "9/186, train_loss: 0.0049\n",
            "10/186, train_loss: 0.0252\n",
            "11/186, train_loss: 0.0361\n",
            "12/186, train_loss: 0.0368\n",
            "13/186, train_loss: 0.0532\n",
            "14/186, train_loss: 0.1043\n",
            "15/186, train_loss: 0.0556\n",
            "16/186, train_loss: 0.0164\n",
            "17/186, train_loss: 0.0607\n",
            "18/186, train_loss: 0.3011\n",
            "19/186, train_loss: 0.1682\n",
            "20/186, train_loss: 0.0471\n",
            "21/186, train_loss: 0.0336\n",
            "22/186, train_loss: 0.0789\n",
            "23/186, train_loss: 0.3636\n",
            "24/186, train_loss: 0.0166\n",
            "25/186, train_loss: 0.1145\n",
            "26/186, train_loss: 0.1458\n",
            "27/186, train_loss: 0.0074\n",
            "28/186, train_loss: 0.0061\n",
            "29/186, train_loss: 0.0377\n",
            "30/186, train_loss: 0.0124\n",
            "31/186, train_loss: 0.6457\n",
            "32/186, train_loss: 0.0532\n",
            "33/186, train_loss: 0.0288\n",
            "34/186, train_loss: 0.2230\n",
            "35/186, train_loss: 0.0341\n",
            "36/186, train_loss: 0.0491\n",
            "37/186, train_loss: 0.0745\n",
            "38/186, train_loss: 0.0823\n",
            "39/186, train_loss: 0.0096\n",
            "40/186, train_loss: 0.0130\n",
            "41/186, train_loss: 0.1816\n",
            "42/186, train_loss: 0.0097\n",
            "43/186, train_loss: 0.0440\n",
            "44/186, train_loss: 0.0775\n",
            "45/186, train_loss: 0.0519\n",
            "46/186, train_loss: 0.0285\n",
            "47/186, train_loss: 0.0274\n",
            "48/186, train_loss: 0.0913\n",
            "49/186, train_loss: 0.0079\n",
            "50/186, train_loss: 0.0450\n",
            "51/186, train_loss: 0.0433\n",
            "52/186, train_loss: 0.0062\n",
            "53/186, train_loss: 0.0281\n",
            "54/186, train_loss: 0.0477\n",
            "55/186, train_loss: 0.0802\n",
            "56/186, train_loss: 0.0084\n",
            "57/186, train_loss: 0.0439\n",
            "58/186, train_loss: 0.0275\n",
            "59/186, train_loss: 0.0280\n",
            "60/186, train_loss: 0.0059\n",
            "61/186, train_loss: 0.0690\n",
            "62/186, train_loss: 0.0568\n",
            "63/186, train_loss: 0.0082\n",
            "64/186, train_loss: 0.0040\n",
            "65/186, train_loss: 0.0428\n",
            "66/186, train_loss: 0.1154\n",
            "67/186, train_loss: 0.0290\n",
            "68/186, train_loss: 0.0993\n",
            "69/186, train_loss: 0.2258\n",
            "70/186, train_loss: 0.0110\n",
            "71/186, train_loss: 1.6776\n",
            "72/186, train_loss: 0.0803\n",
            "73/186, train_loss: 0.0306\n",
            "74/186, train_loss: 0.0592\n",
            "75/186, train_loss: 0.0296\n",
            "76/186, train_loss: 0.0582\n",
            "77/186, train_loss: 0.0145\n",
            "78/186, train_loss: 0.0050\n",
            "79/186, train_loss: 0.0714\n",
            "80/186, train_loss: 0.0065\n",
            "81/186, train_loss: 0.0069\n",
            "82/186, train_loss: 0.0485\n",
            "83/186, train_loss: 0.0175\n",
            "84/186, train_loss: 0.0249\n",
            "85/186, train_loss: 0.0079\n",
            "86/186, train_loss: 0.0431\n",
            "87/186, train_loss: 0.1567\n",
            "88/186, train_loss: 0.0184\n",
            "89/186, train_loss: 0.1596\n",
            "90/186, train_loss: 0.0868\n",
            "91/186, train_loss: 0.0232\n",
            "92/186, train_loss: 0.0204\n",
            "93/186, train_loss: 0.0874\n",
            "94/186, train_loss: 0.0069\n",
            "95/186, train_loss: 0.0284\n",
            "96/186, train_loss: 0.0254\n",
            "97/186, train_loss: 0.0479\n",
            "98/186, train_loss: 0.0341\n",
            "99/186, train_loss: 0.0728\n",
            "100/186, train_loss: 0.0035\n",
            "101/186, train_loss: 0.0151\n",
            "102/186, train_loss: 0.0291\n",
            "103/186, train_loss: 0.0282\n",
            "104/186, train_loss: 0.0111\n",
            "105/186, train_loss: 0.0315\n",
            "106/186, train_loss: 0.0058\n",
            "107/186, train_loss: 0.0104\n",
            "108/186, train_loss: 0.0481\n",
            "109/186, train_loss: 0.0291\n",
            "110/186, train_loss: 0.1547\n",
            "111/186, train_loss: 0.2084\n",
            "112/186, train_loss: 0.4355\n",
            "113/186, train_loss: 0.0089\n",
            "114/186, train_loss: 0.0022\n",
            "115/186, train_loss: 0.0398\n",
            "116/186, train_loss: 0.4509\n",
            "117/186, train_loss: 0.0285\n",
            "118/186, train_loss: 0.0304\n",
            "119/186, train_loss: 0.0277\n",
            "120/186, train_loss: 0.0316\n",
            "121/186, train_loss: 0.0074\n",
            "122/186, train_loss: 0.0332\n",
            "123/186, train_loss: 0.0536\n",
            "124/186, train_loss: 0.1855\n",
            "125/186, train_loss: 0.0698\n",
            "126/186, train_loss: 0.0404\n",
            "127/186, train_loss: 0.2677\n",
            "128/186, train_loss: 0.0855\n",
            "129/186, train_loss: 0.0119\n",
            "130/186, train_loss: 0.0182\n",
            "131/186, train_loss: 0.2182\n",
            "132/186, train_loss: 0.0056\n",
            "133/186, train_loss: 0.0142\n",
            "134/186, train_loss: 0.0097\n",
            "135/186, train_loss: 0.0028\n",
            "136/186, train_loss: 0.1460\n",
            "137/186, train_loss: 0.0168\n",
            "138/186, train_loss: 0.0619\n",
            "139/186, train_loss: 0.0270\n",
            "140/186, train_loss: 0.0362\n",
            "141/186, train_loss: 0.0024\n",
            "142/186, train_loss: 0.5298\n",
            "143/186, train_loss: 0.0043\n",
            "144/186, train_loss: 0.0044\n",
            "145/186, train_loss: 0.0042\n",
            "146/186, train_loss: 0.0335\n",
            "147/186, train_loss: 0.0245\n",
            "148/186, train_loss: 0.0592\n",
            "149/186, train_loss: 0.0345\n",
            "150/186, train_loss: 0.0273\n",
            "151/186, train_loss: 0.0280\n",
            "152/186, train_loss: 0.0589\n",
            "153/186, train_loss: 0.0151\n",
            "154/186, train_loss: 0.0069\n",
            "155/186, train_loss: 0.0787\n",
            "156/186, train_loss: 0.0490\n",
            "157/186, train_loss: 0.0091\n",
            "158/186, train_loss: 0.0411\n",
            "159/186, train_loss: 0.0084\n",
            "160/186, train_loss: 0.0087\n",
            "161/186, train_loss: 0.0037\n",
            "162/186, train_loss: 0.0103\n",
            "163/186, train_loss: 0.0220\n",
            "164/186, train_loss: 0.0691\n",
            "165/186, train_loss: 0.0040\n",
            "166/186, train_loss: 0.0204\n",
            "167/186, train_loss: 0.0112\n",
            "168/186, train_loss: 0.4547\n",
            "169/186, train_loss: 0.0523\n",
            "170/186, train_loss: 0.0037\n",
            "171/186, train_loss: 0.1289\n",
            "172/186, train_loss: 0.0527\n",
            "173/186, train_loss: 0.0519\n",
            "174/186, train_loss: 0.0021\n",
            "175/186, train_loss: 0.0346\n",
            "176/186, train_loss: 0.1307\n",
            "177/186, train_loss: 0.0092\n",
            "178/186, train_loss: 1.7643\n",
            "179/186, train_loss: 0.0272\n",
            "180/186, train_loss: 0.0554\n",
            "181/186, train_loss: 0.0357\n",
            "182/186, train_loss: 0.0378\n",
            "183/186, train_loss: 0.0669\n",
            "184/186, train_loss: 0.0158\n",
            "185/186, train_loss: 0.0143\n",
            "186/186, train_loss: 0.0246\n",
            "epoch 37 average loss: 0.0883\n",
            "----------\n",
            "epoch 38/50\n",
            "1/186, train_loss: 0.0285\n",
            "2/186, train_loss: 0.0271\n",
            "3/186, train_loss: 0.0510\n",
            "4/186, train_loss: 0.0035\n",
            "5/186, train_loss: 0.0253\n",
            "6/186, train_loss: 0.1216\n",
            "7/186, train_loss: 0.0095\n",
            "8/186, train_loss: 0.0312\n",
            "9/186, train_loss: 0.6054\n",
            "10/186, train_loss: 0.0056\n",
            "11/186, train_loss: 0.0052\n",
            "12/186, train_loss: 0.0636\n",
            "13/186, train_loss: 0.0328\n",
            "14/186, train_loss: 0.2196\n",
            "15/186, train_loss: 0.0040\n",
            "16/186, train_loss: 0.3098\n",
            "17/186, train_loss: 0.0030\n",
            "18/186, train_loss: 0.0189\n",
            "19/186, train_loss: 0.0388\n",
            "20/186, train_loss: 0.0347\n",
            "21/186, train_loss: 0.0028\n",
            "22/186, train_loss: 0.0473\n",
            "23/186, train_loss: 0.0052\n",
            "24/186, train_loss: 0.0174\n",
            "25/186, train_loss: 0.0346\n",
            "26/186, train_loss: 0.0085\n",
            "27/186, train_loss: 0.0134\n",
            "28/186, train_loss: 0.1104\n",
            "29/186, train_loss: 0.0141\n",
            "30/186, train_loss: 1.3112\n",
            "31/186, train_loss: 0.0513\n",
            "32/186, train_loss: 0.0316\n",
            "33/186, train_loss: 0.1335\n",
            "34/186, train_loss: 0.0111\n",
            "35/186, train_loss: 0.0026\n",
            "36/186, train_loss: 0.0195\n",
            "37/186, train_loss: 0.0375\n",
            "38/186, train_loss: 0.0084\n",
            "39/186, train_loss: 0.0042\n",
            "40/186, train_loss: 0.0020\n",
            "41/186, train_loss: 0.0139\n",
            "42/186, train_loss: 0.0562\n",
            "43/186, train_loss: 0.0490\n",
            "44/186, train_loss: 0.0202\n",
            "45/186, train_loss: 0.0440\n",
            "46/186, train_loss: 0.0298\n",
            "47/186, train_loss: 0.0128\n",
            "48/186, train_loss: 0.2118\n",
            "49/186, train_loss: 0.0379\n",
            "50/186, train_loss: 0.0616\n",
            "51/186, train_loss: 0.0427\n",
            "52/186, train_loss: 1.5687\n",
            "53/186, train_loss: 0.0022\n",
            "54/186, train_loss: 0.0434\n",
            "55/186, train_loss: 0.2000\n",
            "56/186, train_loss: 0.0348\n",
            "57/186, train_loss: 0.1895\n",
            "58/186, train_loss: 0.1325\n",
            "59/186, train_loss: 0.0603\n",
            "60/186, train_loss: 0.1179\n",
            "61/186, train_loss: 0.2250\n",
            "62/186, train_loss: 0.0446\n",
            "63/186, train_loss: 0.3149\n",
            "64/186, train_loss: 0.0474\n",
            "65/186, train_loss: 0.1216\n",
            "66/186, train_loss: 0.0753\n",
            "67/186, train_loss: 0.0300\n",
            "68/186, train_loss: 0.0305\n",
            "69/186, train_loss: 0.0240\n",
            "70/186, train_loss: 0.0406\n",
            "71/186, train_loss: 0.0761\n",
            "72/186, train_loss: 0.0310\n",
            "73/186, train_loss: 0.0295\n",
            "74/186, train_loss: 0.0611\n",
            "75/186, train_loss: 0.0506\n",
            "76/186, train_loss: 0.1123\n",
            "77/186, train_loss: 0.0227\n",
            "78/186, train_loss: 0.0308\n",
            "79/186, train_loss: 0.0689\n",
            "80/186, train_loss: 0.1760\n",
            "81/186, train_loss: 0.4667\n",
            "82/186, train_loss: 0.0075\n",
            "83/186, train_loss: 1.0986\n",
            "84/186, train_loss: 0.0524\n",
            "85/186, train_loss: 0.0412\n",
            "86/186, train_loss: 0.0140\n",
            "87/186, train_loss: 0.0078\n",
            "88/186, train_loss: 0.0415\n",
            "89/186, train_loss: 0.0091\n",
            "90/186, train_loss: 0.0314\n",
            "91/186, train_loss: 0.0449\n",
            "92/186, train_loss: 0.0299\n",
            "93/186, train_loss: 0.1133\n",
            "94/186, train_loss: 0.0317\n",
            "95/186, train_loss: 0.0292\n",
            "96/186, train_loss: 0.0292\n",
            "97/186, train_loss: 0.0455\n",
            "98/186, train_loss: 0.0043\n",
            "99/186, train_loss: 0.1167\n",
            "100/186, train_loss: 0.0078\n",
            "101/186, train_loss: 0.1089\n",
            "102/186, train_loss: 0.5010\n",
            "103/186, train_loss: 0.0543\n",
            "104/186, train_loss: 0.0225\n",
            "105/186, train_loss: 0.0054\n",
            "106/186, train_loss: 0.0183\n",
            "107/186, train_loss: 1.6416\n",
            "108/186, train_loss: 0.0132\n",
            "109/186, train_loss: 0.1208\n",
            "110/186, train_loss: 0.0428\n",
            "111/186, train_loss: 0.1619\n",
            "112/186, train_loss: 0.1432\n",
            "113/186, train_loss: 0.0057\n",
            "114/186, train_loss: 0.2499\n",
            "115/186, train_loss: 0.0352\n",
            "116/186, train_loss: 0.0281\n",
            "117/186, train_loss: 1.6653\n",
            "118/186, train_loss: 0.0466\n",
            "119/186, train_loss: 0.0549\n",
            "120/186, train_loss: 0.0375\n",
            "121/186, train_loss: 0.0533\n",
            "122/186, train_loss: 0.0653\n",
            "123/186, train_loss: 0.1488\n",
            "124/186, train_loss: 0.0532\n",
            "125/186, train_loss: 0.1506\n",
            "126/186, train_loss: 0.0503\n",
            "127/186, train_loss: 0.0851\n",
            "128/186, train_loss: 0.0065\n",
            "129/186, train_loss: 0.1374\n",
            "130/186, train_loss: 0.1408\n",
            "131/186, train_loss: 0.0791\n",
            "132/186, train_loss: 0.0345\n",
            "133/186, train_loss: 0.1827\n",
            "134/186, train_loss: 0.0121\n",
            "135/186, train_loss: 0.0760\n",
            "136/186, train_loss: 0.0049\n",
            "137/186, train_loss: 0.0533\n",
            "138/186, train_loss: 0.0610\n",
            "139/186, train_loss: 0.0338\n",
            "140/186, train_loss: 0.0359\n",
            "141/186, train_loss: 0.0511\n",
            "142/186, train_loss: 0.1414\n",
            "143/186, train_loss: 0.0040\n",
            "144/186, train_loss: 0.0033\n",
            "145/186, train_loss: 0.0311\n",
            "146/186, train_loss: 0.1213\n",
            "147/186, train_loss: 0.0076\n",
            "148/186, train_loss: 0.0404\n",
            "149/186, train_loss: 0.0023\n",
            "150/186, train_loss: 0.0504\n",
            "151/186, train_loss: 0.3447\n",
            "152/186, train_loss: 0.1191\n",
            "153/186, train_loss: 0.0115\n",
            "154/186, train_loss: 0.0023\n",
            "155/186, train_loss: 0.0059\n",
            "156/186, train_loss: 0.1544\n",
            "157/186, train_loss: 0.0340\n",
            "158/186, train_loss: 0.0086\n",
            "159/186, train_loss: 0.0078\n",
            "160/186, train_loss: 0.0301\n",
            "161/186, train_loss: 0.0114\n",
            "162/186, train_loss: 0.0307\n",
            "163/186, train_loss: 0.2318\n",
            "164/186, train_loss: 0.0972\n",
            "165/186, train_loss: 0.0028\n",
            "166/186, train_loss: 0.3094\n",
            "167/186, train_loss: 0.0417\n",
            "168/186, train_loss: 0.0345\n",
            "169/186, train_loss: 0.0079\n",
            "170/186, train_loss: 0.0498\n",
            "171/186, train_loss: 0.0062\n",
            "172/186, train_loss: 0.0994\n",
            "173/186, train_loss: 0.0530\n",
            "174/186, train_loss: 0.1624\n",
            "175/186, train_loss: 0.0332\n",
            "176/186, train_loss: 0.0311\n",
            "177/186, train_loss: 0.1421\n",
            "178/186, train_loss: 0.0162\n",
            "179/186, train_loss: 0.0036\n",
            "180/186, train_loss: 0.0105\n",
            "181/186, train_loss: 0.0362\n",
            "182/186, train_loss: 0.0029\n",
            "183/186, train_loss: 0.0418\n",
            "184/186, train_loss: 0.0213\n",
            "185/186, train_loss: 0.0351\n",
            "186/186, train_loss: 0.0577\n",
            "epoch 38 average loss: 0.1045\n",
            "current epoch: 38 current accuracy: 0.9032 best accuracy: 0.9032 at epoch 34\n",
            "----------\n",
            "epoch 39/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/186, train_loss: 0.0316\n",
            "2/186, train_loss: 0.0022\n",
            "3/186, train_loss: 0.0430\n",
            "4/186, train_loss: 0.0342\n",
            "5/186, train_loss: 0.0268\n",
            "6/186, train_loss: 0.0059\n",
            "7/186, train_loss: 0.3030\n",
            "8/186, train_loss: 0.0260\n",
            "9/186, train_loss: 0.1053\n",
            "10/186, train_loss: 0.0358\n",
            "11/186, train_loss: 0.0053\n",
            "12/186, train_loss: 0.0492\n",
            "13/186, train_loss: 0.0032\n",
            "14/186, train_loss: 0.0028\n",
            "15/186, train_loss: 0.1626\n",
            "16/186, train_loss: 0.0087\n",
            "17/186, train_loss: 0.3519\n",
            "18/186, train_loss: 0.0019\n",
            "19/186, train_loss: 0.1758\n",
            "20/186, train_loss: 0.0103\n",
            "21/186, train_loss: 0.0383\n",
            "22/186, train_loss: 0.0032\n",
            "23/186, train_loss: 1.9236\n",
            "24/186, train_loss: 0.0183\n",
            "25/186, train_loss: 0.0227\n",
            "26/186, train_loss: 0.3790\n",
            "27/186, train_loss: 0.0480\n",
            "28/186, train_loss: 0.0048\n",
            "29/186, train_loss: 0.0230\n",
            "30/186, train_loss: 0.0414\n",
            "31/186, train_loss: 0.0141\n",
            "32/186, train_loss: 0.0314\n",
            "33/186, train_loss: 0.3256\n",
            "34/186, train_loss: 0.0493\n",
            "35/186, train_loss: 0.0306\n",
            "36/186, train_loss: 0.0374\n",
            "37/186, train_loss: 0.1219\n",
            "38/186, train_loss: 0.0297\n",
            "39/186, train_loss: 0.0125\n",
            "40/186, train_loss: 0.0376\n",
            "41/186, train_loss: 1.4943\n",
            "42/186, train_loss: 0.0296\n",
            "43/186, train_loss: 0.0416\n",
            "44/186, train_loss: 0.0319\n",
            "45/186, train_loss: 0.0420\n",
            "46/186, train_loss: 0.0299\n",
            "47/186, train_loss: 0.0180\n",
            "48/186, train_loss: 0.0361\n",
            "49/186, train_loss: 0.0348\n",
            "50/186, train_loss: 0.0306\n",
            "51/186, train_loss: 0.0382\n",
            "52/186, train_loss: 0.0092\n",
            "53/186, train_loss: 0.1278\n",
            "54/186, train_loss: 0.2905\n",
            "55/186, train_loss: 0.0329\n",
            "56/186, train_loss: 0.0011\n",
            "57/186, train_loss: 0.0370\n",
            "58/186, train_loss: 0.3456\n",
            "59/186, train_loss: 0.0059\n",
            "60/186, train_loss: 0.0630\n",
            "61/186, train_loss: 0.1792\n",
            "62/186, train_loss: 0.0172\n",
            "63/186, train_loss: 0.1041\n",
            "64/186, train_loss: 0.0198\n",
            "65/186, train_loss: 0.0494\n",
            "66/186, train_loss: 0.0943\n",
            "67/186, train_loss: 0.2023\n",
            "68/186, train_loss: 0.0115\n",
            "69/186, train_loss: 0.0562\n",
            "70/186, train_loss: 0.3155\n",
            "71/186, train_loss: 0.0295\n",
            "72/186, train_loss: 0.3625\n",
            "73/186, train_loss: 0.0190\n",
            "74/186, train_loss: 0.0367\n",
            "75/186, train_loss: 0.0047\n",
            "76/186, train_loss: 0.1700\n",
            "77/186, train_loss: 0.0046\n",
            "78/186, train_loss: 0.0601\n",
            "79/186, train_loss: 0.0410\n",
            "80/186, train_loss: 0.3961\n",
            "81/186, train_loss: 0.3093\n",
            "82/186, train_loss: 0.0500\n",
            "83/186, train_loss: 0.0093\n",
            "84/186, train_loss: 0.0080\n",
            "85/186, train_loss: 0.0710\n",
            "86/186, train_loss: 0.0666\n",
            "87/186, train_loss: 0.0736\n",
            "88/186, train_loss: 0.0525\n",
            "89/186, train_loss: 0.0094\n",
            "90/186, train_loss: 0.3423\n",
            "91/186, train_loss: 0.0082\n",
            "92/186, train_loss: 0.0314\n",
            "93/186, train_loss: 1.6348\n",
            "94/186, train_loss: 0.1795\n",
            "95/186, train_loss: 0.0335\n",
            "96/186, train_loss: 0.0154\n",
            "97/186, train_loss: 0.0504\n",
            "98/186, train_loss: 0.0323\n",
            "99/186, train_loss: 0.0491\n",
            "100/186, train_loss: 0.0299\n",
            "101/186, train_loss: 0.1229\n",
            "102/186, train_loss: 0.0504\n",
            "103/186, train_loss: 0.0042\n",
            "104/186, train_loss: 0.0932\n",
            "105/186, train_loss: 0.0566\n",
            "106/186, train_loss: 0.0117\n",
            "107/186, train_loss: 0.0207\n",
            "108/186, train_loss: 0.0511\n",
            "109/186, train_loss: 0.0496\n",
            "110/186, train_loss: 0.1466\n",
            "111/186, train_loss: 0.0584\n",
            "112/186, train_loss: 0.2936\n",
            "113/186, train_loss: 0.0041\n",
            "114/186, train_loss: 0.0789\n",
            "115/186, train_loss: 0.0985\n",
            "116/186, train_loss: 0.1202\n",
            "117/186, train_loss: 0.0291\n",
            "118/186, train_loss: 0.0093\n",
            "119/186, train_loss: 0.0331\n",
            "120/186, train_loss: 0.0459\n",
            "121/186, train_loss: 0.0084\n",
            "122/186, train_loss: 0.1256\n",
            "123/186, train_loss: 0.0400\n",
            "124/186, train_loss: 0.0114\n",
            "125/186, train_loss: 0.0378\n",
            "126/186, train_loss: 0.0559\n",
            "127/186, train_loss: 0.0285\n",
            "128/186, train_loss: 0.0361\n",
            "129/186, train_loss: 0.0193\n",
            "130/186, train_loss: 0.0081\n",
            "131/186, train_loss: 0.0190\n",
            "132/186, train_loss: 0.0299\n",
            "133/186, train_loss: 0.3007\n",
            "134/186, train_loss: 0.0037\n",
            "135/186, train_loss: 0.1429\n",
            "136/186, train_loss: 0.0303\n",
            "137/186, train_loss: 0.0696\n",
            "138/186, train_loss: 0.0318\n",
            "139/186, train_loss: 0.0281\n",
            "140/186, train_loss: 0.0311\n",
            "141/186, train_loss: 0.1936\n",
            "142/186, train_loss: 0.0300\n",
            "143/186, train_loss: 0.0521\n",
            "144/186, train_loss: 0.1012\n",
            "145/186, train_loss: 0.1215\n",
            "146/186, train_loss: 0.0362\n",
            "147/186, train_loss: 0.0493\n",
            "148/186, train_loss: 0.4886\n",
            "149/186, train_loss: 0.2195\n",
            "150/186, train_loss: 0.0030\n",
            "151/186, train_loss: 0.0077\n",
            "152/186, train_loss: 0.0323\n",
            "153/186, train_loss: 0.0345\n",
            "154/186, train_loss: 0.0030\n",
            "155/186, train_loss: 0.0342\n",
            "156/186, train_loss: 0.0067\n",
            "157/186, train_loss: 0.0072\n",
            "158/186, train_loss: 0.0243\n",
            "159/186, train_loss: 0.0530\n",
            "160/186, train_loss: 0.0050\n",
            "161/186, train_loss: 0.0286\n",
            "162/186, train_loss: 0.0224\n",
            "163/186, train_loss: 0.0933\n",
            "164/186, train_loss: 0.1058\n",
            "165/186, train_loss: 0.0101\n",
            "166/186, train_loss: 0.0185\n",
            "167/186, train_loss: 0.0219\n",
            "168/186, train_loss: 0.0020\n",
            "169/186, train_loss: 0.2453\n",
            "170/186, train_loss: 0.0486\n",
            "171/186, train_loss: 0.4218\n",
            "172/186, train_loss: 0.0044\n",
            "173/186, train_loss: 0.0426\n",
            "174/186, train_loss: 0.0215\n",
            "175/186, train_loss: 0.0068\n",
            "176/186, train_loss: 0.0085\n",
            "177/186, train_loss: 0.7150\n",
            "178/186, train_loss: 0.0050\n",
            "179/186, train_loss: 0.0010\n",
            "180/186, train_loss: 0.0463\n",
            "181/186, train_loss: 0.0019\n",
            "182/186, train_loss: 0.0095\n",
            "183/186, train_loss: 0.0293\n",
            "184/186, train_loss: 0.0355\n",
            "185/186, train_loss: 0.0215\n",
            "186/186, train_loss: 0.0059\n",
            "epoch 39 average loss: 0.0992\n",
            "----------\n",
            "epoch 40/50\n",
            "1/186, train_loss: 0.0511\n",
            "2/186, train_loss: 0.0033\n",
            "3/186, train_loss: 0.0929\n",
            "4/186, train_loss: 0.3277\n",
            "5/186, train_loss: 0.0562\n",
            "6/186, train_loss: 0.1648\n",
            "7/186, train_loss: 0.0311\n",
            "8/186, train_loss: 0.0077\n",
            "9/186, train_loss: 0.0037\n",
            "10/186, train_loss: 1.5535\n",
            "11/186, train_loss: 0.0313\n",
            "12/186, train_loss: 0.0059\n",
            "13/186, train_loss: 0.0381\n",
            "14/186, train_loss: 0.0021\n",
            "15/186, train_loss: 0.2477\n",
            "16/186, train_loss: 0.0321\n",
            "17/186, train_loss: 0.0142\n",
            "18/186, train_loss: 0.0060\n",
            "19/186, train_loss: 0.0033\n",
            "20/186, train_loss: 0.0050\n",
            "21/186, train_loss: 0.0122\n",
            "22/186, train_loss: 0.0292\n",
            "23/186, train_loss: 0.0840\n",
            "24/186, train_loss: 0.0122\n",
            "25/186, train_loss: 0.0273\n",
            "26/186, train_loss: 0.0036\n",
            "27/186, train_loss: 0.0180\n",
            "28/186, train_loss: 0.1148\n",
            "29/186, train_loss: 0.0130\n",
            "30/186, train_loss: 0.0300\n",
            "31/186, train_loss: 0.0567\n",
            "32/186, train_loss: 0.1250\n",
            "33/186, train_loss: 0.0664\n",
            "34/186, train_loss: 0.0048\n",
            "35/186, train_loss: 0.0054\n",
            "36/186, train_loss: 0.0035\n",
            "37/186, train_loss: 0.0168\n",
            "38/186, train_loss: 0.0785\n",
            "39/186, train_loss: 0.0022\n",
            "40/186, train_loss: 0.1637\n",
            "41/186, train_loss: 0.0335\n",
            "42/186, train_loss: 0.0483\n",
            "43/186, train_loss: 0.0069\n",
            "44/186, train_loss: 0.0320\n",
            "45/186, train_loss: 0.0543\n",
            "46/186, train_loss: 0.0344\n",
            "47/186, train_loss: 0.0264\n",
            "48/186, train_loss: 0.0050\n",
            "49/186, train_loss: 0.2451\n",
            "50/186, train_loss: 0.0312\n",
            "51/186, train_loss: 0.2745\n",
            "52/186, train_loss: 0.0186\n",
            "53/186, train_loss: 0.0519\n",
            "54/186, train_loss: 0.0017\n",
            "55/186, train_loss: 0.0030\n",
            "56/186, train_loss: 0.0905\n",
            "57/186, train_loss: 0.0060\n",
            "58/186, train_loss: 0.0063\n",
            "59/186, train_loss: 0.0297\n",
            "60/186, train_loss: 0.0056\n",
            "61/186, train_loss: 0.0063\n",
            "62/186, train_loss: 0.0301\n",
            "63/186, train_loss: 0.0092\n",
            "64/186, train_loss: 0.0097\n",
            "65/186, train_loss: 0.0050\n",
            "66/186, train_loss: 0.0145\n",
            "67/186, train_loss: 0.0278\n",
            "68/186, train_loss: 0.3176\n",
            "69/186, train_loss: 0.0101\n",
            "70/186, train_loss: 0.0122\n",
            "71/186, train_loss: 0.1135\n",
            "72/186, train_loss: 0.1086\n",
            "73/186, train_loss: 0.0023\n",
            "74/186, train_loss: 0.0033\n",
            "75/186, train_loss: 0.0119\n",
            "76/186, train_loss: 0.0538\n",
            "77/186, train_loss: 0.0545\n",
            "78/186, train_loss: 0.0311\n",
            "79/186, train_loss: 0.0347\n",
            "80/186, train_loss: 0.0424\n",
            "81/186, train_loss: 0.0252\n",
            "82/186, train_loss: 0.0049\n",
            "83/186, train_loss: 0.1253\n",
            "84/186, train_loss: 0.1577\n",
            "85/186, train_loss: 0.0367\n",
            "86/186, train_loss: 0.0058\n",
            "87/186, train_loss: 0.4045\n",
            "88/186, train_loss: 0.9312\n",
            "89/186, train_loss: 0.0059\n",
            "90/186, train_loss: 0.0549\n",
            "91/186, train_loss: 0.0018\n",
            "92/186, train_loss: 0.2127\n",
            "93/186, train_loss: 0.0295\n",
            "94/186, train_loss: 0.0151\n",
            "95/186, train_loss: 0.0591\n",
            "96/186, train_loss: 0.0036\n",
            "97/186, train_loss: 0.0423\n",
            "98/186, train_loss: 0.0330\n",
            "99/186, train_loss: 0.1829\n",
            "100/186, train_loss: 0.0483\n",
            "101/186, train_loss: 0.0083\n",
            "102/186, train_loss: 0.0072\n",
            "103/186, train_loss: 0.1647\n",
            "104/186, train_loss: 1.7171\n",
            "105/186, train_loss: 0.0062\n",
            "106/186, train_loss: 0.0540\n",
            "107/186, train_loss: 0.0617\n",
            "108/186, train_loss: 1.3928\n",
            "109/186, train_loss: 0.0372\n",
            "110/186, train_loss: 0.0430\n",
            "111/186, train_loss: 0.0422\n",
            "112/186, train_loss: 0.0145\n",
            "113/186, train_loss: 0.0361\n",
            "114/186, train_loss: 0.1059\n",
            "115/186, train_loss: 0.0286\n",
            "116/186, train_loss: 0.0067\n",
            "117/186, train_loss: 0.0247\n",
            "118/186, train_loss: 0.0418\n",
            "119/186, train_loss: 0.1439\n",
            "120/186, train_loss: 0.0051\n",
            "121/186, train_loss: 0.1730\n",
            "122/186, train_loss: 0.2311\n",
            "123/186, train_loss: 0.0422\n",
            "124/186, train_loss: 0.0131\n",
            "125/186, train_loss: 0.0479\n",
            "126/186, train_loss: 0.0339\n",
            "127/186, train_loss: 0.0345\n",
            "128/186, train_loss: 0.0773\n",
            "129/186, train_loss: 0.0278\n",
            "130/186, train_loss: 0.2355\n",
            "131/186, train_loss: 0.2388\n",
            "132/186, train_loss: 0.0288\n",
            "133/186, train_loss: 0.0486\n",
            "134/186, train_loss: 0.0398\n",
            "135/186, train_loss: 0.0622\n",
            "136/186, train_loss: 0.0557\n",
            "137/186, train_loss: 0.0374\n",
            "138/186, train_loss: 0.0999\n",
            "139/186, train_loss: 0.0482\n",
            "140/186, train_loss: 0.0080\n",
            "141/186, train_loss: 0.1033\n",
            "142/186, train_loss: 0.7321\n",
            "143/186, train_loss: 0.0159\n",
            "144/186, train_loss: 0.0134\n",
            "145/186, train_loss: 0.1644\n",
            "146/186, train_loss: 0.0109\n",
            "147/186, train_loss: 0.0028\n",
            "148/186, train_loss: 0.0349\n",
            "149/186, train_loss: 0.0861\n",
            "150/186, train_loss: 0.0205\n",
            "151/186, train_loss: 0.0038\n",
            "152/186, train_loss: 0.2109\n",
            "153/186, train_loss: 0.4980\n",
            "154/186, train_loss: 0.0072\n",
            "155/186, train_loss: 0.0042\n",
            "156/186, train_loss: 0.0237\n",
            "157/186, train_loss: 0.0059\n",
            "158/186, train_loss: 0.8391\n",
            "159/186, train_loss: 0.9606\n",
            "160/186, train_loss: 0.0325\n",
            "161/186, train_loss: 2.6399\n",
            "162/186, train_loss: 0.0804\n",
            "163/186, train_loss: 0.0294\n",
            "164/186, train_loss: 0.1672\n",
            "165/186, train_loss: 0.0228\n",
            "166/186, train_loss: 0.0293\n",
            "167/186, train_loss: 0.1716\n",
            "168/186, train_loss: 0.0267\n",
            "169/186, train_loss: 0.0308\n",
            "170/186, train_loss: 0.0330\n",
            "171/186, train_loss: 0.0756\n",
            "172/186, train_loss: 0.0285\n",
            "173/186, train_loss: 0.0494\n",
            "174/186, train_loss: 0.0489\n",
            "175/186, train_loss: 0.0356\n",
            "176/186, train_loss: 0.0671\n",
            "177/186, train_loss: 0.0630\n",
            "178/186, train_loss: 0.0194\n",
            "179/186, train_loss: 0.1171\n",
            "180/186, train_loss: 0.0324\n",
            "181/186, train_loss: 0.3192\n",
            "182/186, train_loss: 0.0663\n",
            "183/186, train_loss: 0.0533\n",
            "184/186, train_loss: 0.0420\n",
            "185/186, train_loss: 0.0604\n",
            "186/186, train_loss: 0.0325\n",
            "epoch 40 average loss: 0.1154\n",
            "current epoch: 40 current accuracy: 0.7957 best accuracy: 0.9032 at epoch 34\n",
            "----------\n",
            "epoch 41/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/186, train_loss: 0.1135\n",
            "2/186, train_loss: 0.0822\n",
            "3/186, train_loss: 0.1000\n",
            "4/186, train_loss: 0.1292\n",
            "5/186, train_loss: 0.0483\n",
            "6/186, train_loss: 0.0298\n",
            "7/186, train_loss: 0.0402\n",
            "8/186, train_loss: 0.0119\n",
            "9/186, train_loss: 0.1075\n",
            "10/186, train_loss: 0.0690\n",
            "11/186, train_loss: 0.0148\n",
            "12/186, train_loss: 0.3818\n",
            "13/186, train_loss: 0.0106\n",
            "14/186, train_loss: 0.0110\n",
            "15/186, train_loss: 0.0489\n",
            "16/186, train_loss: 0.0343\n",
            "17/186, train_loss: 0.0315\n",
            "18/186, train_loss: 0.0322\n",
            "19/186, train_loss: 0.0568\n",
            "20/186, train_loss: 0.0302\n",
            "21/186, train_loss: 0.0657\n",
            "22/186, train_loss: 0.0354\n",
            "23/186, train_loss: 0.0055\n",
            "24/186, train_loss: 0.0468\n",
            "25/186, train_loss: 0.0059\n",
            "26/186, train_loss: 0.0273\n",
            "27/186, train_loss: 0.0354\n",
            "28/186, train_loss: 0.0509\n",
            "29/186, train_loss: 0.0300\n",
            "30/186, train_loss: 0.0101\n",
            "31/186, train_loss: 0.0923\n",
            "32/186, train_loss: 0.0233\n",
            "33/186, train_loss: 1.7007\n",
            "34/186, train_loss: 0.0532\n",
            "35/186, train_loss: 0.0526\n",
            "36/186, train_loss: 0.0341\n",
            "37/186, train_loss: 0.0109\n",
            "38/186, train_loss: 0.0447\n",
            "39/186, train_loss: 0.1261\n",
            "40/186, train_loss: 0.9409\n",
            "41/186, train_loss: 0.0145\n",
            "42/186, train_loss: 0.0044\n",
            "43/186, train_loss: 0.0986\n",
            "44/186, train_loss: 0.0204\n",
            "45/186, train_loss: 0.1756\n",
            "46/186, train_loss: 0.0387\n",
            "47/186, train_loss: 0.0370\n",
            "48/186, train_loss: 0.0432\n",
            "49/186, train_loss: 0.0373\n",
            "50/186, train_loss: 0.3522\n",
            "51/186, train_loss: 0.0350\n",
            "52/186, train_loss: 1.2130\n",
            "53/186, train_loss: 0.0561\n",
            "54/186, train_loss: 0.0459\n",
            "55/186, train_loss: 0.1282\n",
            "56/186, train_loss: 0.0302\n",
            "57/186, train_loss: 0.1120\n",
            "58/186, train_loss: 0.3677\n",
            "59/186, train_loss: 0.0944\n",
            "60/186, train_loss: 0.0996\n",
            "61/186, train_loss: 0.0414\n",
            "62/186, train_loss: 0.0198\n",
            "63/186, train_loss: 0.0600\n",
            "64/186, train_loss: 0.1066\n",
            "65/186, train_loss: 0.0301\n",
            "66/186, train_loss: 0.0971\n",
            "67/186, train_loss: 0.0160\n",
            "68/186, train_loss: 0.1747\n",
            "69/186, train_loss: 0.0634\n",
            "70/186, train_loss: 0.0404\n",
            "71/186, train_loss: 0.0675\n",
            "72/186, train_loss: 0.0813\n",
            "73/186, train_loss: 0.0327\n",
            "74/186, train_loss: 0.0788\n",
            "75/186, train_loss: 0.1974\n",
            "76/186, train_loss: 0.0498\n",
            "77/186, train_loss: 0.0324\n",
            "78/186, train_loss: 0.0753\n",
            "79/186, train_loss: 0.1086\n",
            "80/186, train_loss: 0.0873\n",
            "81/186, train_loss: 0.0817\n",
            "82/186, train_loss: 0.0579\n",
            "83/186, train_loss: 0.0481\n",
            "84/186, train_loss: 0.0767\n",
            "85/186, train_loss: 0.0304\n",
            "86/186, train_loss: 0.1370\n",
            "87/186, train_loss: 0.0173\n",
            "88/186, train_loss: 0.0035\n",
            "89/186, train_loss: 0.0283\n",
            "90/186, train_loss: 0.0389\n",
            "91/186, train_loss: 0.0439\n",
            "92/186, train_loss: 0.0370\n",
            "93/186, train_loss: 0.0541\n",
            "94/186, train_loss: 1.2916\n",
            "95/186, train_loss: 0.0264\n",
            "96/186, train_loss: 0.0105\n",
            "97/186, train_loss: 0.0262\n",
            "98/186, train_loss: 0.0932\n",
            "99/186, train_loss: 0.0377\n",
            "100/186, train_loss: 0.0433\n",
            "101/186, train_loss: 0.0812\n",
            "102/186, train_loss: 0.0560\n",
            "103/186, train_loss: 0.0550\n",
            "104/186, train_loss: 0.0256\n",
            "105/186, train_loss: 0.0393\n",
            "106/186, train_loss: 0.0737\n",
            "107/186, train_loss: 0.0364\n",
            "108/186, train_loss: 0.0217\n",
            "109/186, train_loss: 0.0312\n",
            "110/186, train_loss: 0.0108\n",
            "111/186, train_loss: 0.0300\n",
            "112/186, train_loss: 0.0139\n",
            "113/186, train_loss: 0.0321\n",
            "114/186, train_loss: 0.0535\n",
            "115/186, train_loss: 0.0994\n",
            "116/186, train_loss: 0.0198\n",
            "117/186, train_loss: 0.0245\n",
            "118/186, train_loss: 0.0083\n",
            "119/186, train_loss: 0.1060\n",
            "120/186, train_loss: 0.0522\n",
            "121/186, train_loss: 0.0259\n",
            "122/186, train_loss: 0.0279\n",
            "123/186, train_loss: 0.0407\n",
            "124/186, train_loss: 0.0791\n",
            "125/186, train_loss: 0.0244\n",
            "126/186, train_loss: 0.0225\n",
            "127/186, train_loss: 0.0136\n",
            "128/186, train_loss: 0.1586\n",
            "129/186, train_loss: 1.4471\n",
            "130/186, train_loss: 0.0502\n",
            "131/186, train_loss: 0.0937\n",
            "132/186, train_loss: 0.0191\n",
            "133/186, train_loss: 0.0895\n",
            "134/186, train_loss: 0.0498\n",
            "135/186, train_loss: 0.0417\n",
            "136/186, train_loss: 0.0514\n",
            "137/186, train_loss: 0.1300\n",
            "138/186, train_loss: 0.0333\n",
            "139/186, train_loss: 0.0112\n",
            "140/186, train_loss: 0.0640\n",
            "141/186, train_loss: 0.1327\n",
            "142/186, train_loss: 0.0045\n",
            "143/186, train_loss: 0.0059\n",
            "144/186, train_loss: 0.0361\n",
            "145/186, train_loss: 0.0095\n",
            "146/186, train_loss: 0.0165\n",
            "147/186, train_loss: 0.0339\n",
            "148/186, train_loss: 0.0156\n",
            "149/186, train_loss: 0.0409\n",
            "150/186, train_loss: 0.0055\n",
            "151/186, train_loss: 0.3143\n",
            "152/186, train_loss: 0.0422\n",
            "153/186, train_loss: 0.0466\n",
            "154/186, train_loss: 0.0251\n",
            "155/186, train_loss: 0.0240\n",
            "156/186, train_loss: 0.0320\n",
            "157/186, train_loss: 0.0300\n",
            "158/186, train_loss: 0.0101\n",
            "159/186, train_loss: 0.0483\n",
            "160/186, train_loss: 0.0373\n",
            "161/186, train_loss: 0.0227\n",
            "162/186, train_loss: 0.1103\n",
            "163/186, train_loss: 0.0184\n",
            "164/186, train_loss: 0.0750\n",
            "165/186, train_loss: 0.0058\n",
            "166/186, train_loss: 0.0202\n",
            "167/186, train_loss: 0.0387\n",
            "168/186, train_loss: 0.0276\n",
            "169/186, train_loss: 0.0065\n",
            "170/186, train_loss: 0.0109\n",
            "171/186, train_loss: 0.0730\n",
            "172/186, train_loss: 0.0266\n",
            "173/186, train_loss: 0.0477\n",
            "174/186, train_loss: 0.0042\n",
            "175/186, train_loss: 0.0051\n",
            "176/186, train_loss: 0.0035\n",
            "177/186, train_loss: 0.0190\n",
            "178/186, train_loss: 0.0619\n",
            "179/186, train_loss: 0.1685\n",
            "180/186, train_loss: 0.0335\n",
            "181/186, train_loss: 0.0109\n",
            "182/186, train_loss: 0.0124\n",
            "183/186, train_loss: 0.0284\n",
            "184/186, train_loss: 0.0564\n",
            "185/186, train_loss: 0.0075\n",
            "186/186, train_loss: 0.0486\n",
            "epoch 41 average loss: 0.0894\n",
            "----------\n",
            "epoch 42/50\n",
            "1/186, train_loss: 0.0648\n",
            "2/186, train_loss: 0.0034\n",
            "3/186, train_loss: 0.2390\n",
            "4/186, train_loss: 0.5366\n",
            "5/186, train_loss: 0.0403\n",
            "6/186, train_loss: 0.1678\n",
            "7/186, train_loss: 0.0038\n",
            "8/186, train_loss: 0.2093\n",
            "9/186, train_loss: 1.7718\n",
            "10/186, train_loss: 0.0574\n",
            "11/186, train_loss: 0.1115\n",
            "12/186, train_loss: 0.0054\n",
            "13/186, train_loss: 0.0555\n",
            "14/186, train_loss: 0.0267\n",
            "15/186, train_loss: 0.0270\n",
            "16/186, train_loss: 0.0409\n",
            "17/186, train_loss: 0.5927\n",
            "18/186, train_loss: 0.5811\n",
            "19/186, train_loss: 0.1028\n",
            "20/186, train_loss: 0.0252\n",
            "21/186, train_loss: 0.0485\n",
            "22/186, train_loss: 0.0467\n",
            "23/186, train_loss: 0.0492\n",
            "24/186, train_loss: 0.0200\n",
            "25/186, train_loss: 0.0353\n",
            "26/186, train_loss: 0.0335\n",
            "27/186, train_loss: 0.3427\n",
            "28/186, train_loss: 0.0315\n",
            "29/186, train_loss: 0.0057\n",
            "30/186, train_loss: 1.4643\n",
            "31/186, train_loss: 0.0322\n",
            "32/186, train_loss: 0.0270\n",
            "33/186, train_loss: 0.2631\n",
            "34/186, train_loss: 0.0558\n",
            "35/186, train_loss: 0.0902\n",
            "36/186, train_loss: 0.0452\n",
            "37/186, train_loss: 0.3508\n",
            "38/186, train_loss: 0.0798\n",
            "39/186, train_loss: 0.0248\n",
            "40/186, train_loss: 0.0237\n",
            "41/186, train_loss: 0.0227\n",
            "42/186, train_loss: 0.0080\n",
            "43/186, train_loss: 0.0725\n",
            "44/186, train_loss: 0.0173\n",
            "45/186, train_loss: 0.0490\n",
            "46/186, train_loss: 0.0148\n",
            "47/186, train_loss: 0.1139\n",
            "48/186, train_loss: 0.0603\n",
            "49/186, train_loss: 0.0302\n",
            "50/186, train_loss: 0.0321\n",
            "51/186, train_loss: 0.0526\n",
            "52/186, train_loss: 0.0262\n",
            "53/186, train_loss: 0.0907\n",
            "54/186, train_loss: 0.0264\n",
            "55/186, train_loss: 0.0241\n",
            "56/186, train_loss: 0.1524\n",
            "57/186, train_loss: 0.0339\n",
            "58/186, train_loss: 0.0907\n",
            "59/186, train_loss: 0.1107\n",
            "60/186, train_loss: 0.0428\n",
            "61/186, train_loss: 0.6412\n",
            "62/186, train_loss: 0.0278\n",
            "63/186, train_loss: 0.0527\n",
            "64/186, train_loss: 1.5546\n",
            "65/186, train_loss: 0.0345\n",
            "66/186, train_loss: 1.7296\n",
            "67/186, train_loss: 1.3559\n",
            "68/186, train_loss: 0.0495\n",
            "69/186, train_loss: 0.3281\n",
            "70/186, train_loss: 0.0392\n",
            "71/186, train_loss: 0.0453\n",
            "72/186, train_loss: 0.0373\n",
            "73/186, train_loss: 0.0283\n",
            "74/186, train_loss: 0.0181\n",
            "75/186, train_loss: 0.1606\n",
            "76/186, train_loss: 0.0352\n",
            "77/186, train_loss: 0.0054\n",
            "78/186, train_loss: 0.0361\n",
            "79/186, train_loss: 0.0213\n",
            "80/186, train_loss: 0.1623\n",
            "81/186, train_loss: 0.0155\n",
            "82/186, train_loss: 0.2335\n",
            "83/186, train_loss: 0.2677\n",
            "84/186, train_loss: 0.0280\n",
            "85/186, train_loss: 0.0048\n",
            "86/186, train_loss: 0.0872\n",
            "87/186, train_loss: 0.0645\n",
            "88/186, train_loss: 0.0273\n",
            "89/186, train_loss: 0.0296\n",
            "90/186, train_loss: 0.0377\n",
            "91/186, train_loss: 0.0812\n",
            "92/186, train_loss: 0.0411\n",
            "93/186, train_loss: 0.0549\n",
            "94/186, train_loss: 0.0546\n",
            "95/186, train_loss: 0.0296\n",
            "96/186, train_loss: 0.0214\n",
            "97/186, train_loss: 0.0513\n",
            "98/186, train_loss: 0.5717\n",
            "99/186, train_loss: 0.0270\n",
            "100/186, train_loss: 0.0251\n",
            "101/186, train_loss: 0.0026\n",
            "102/186, train_loss: 0.0160\n",
            "103/186, train_loss: 0.0037\n",
            "104/186, train_loss: 0.0310\n",
            "105/186, train_loss: 0.0084\n",
            "106/186, train_loss: 0.0071\n",
            "107/186, train_loss: 0.0480\n",
            "108/186, train_loss: 0.0036\n",
            "109/186, train_loss: 0.0645\n",
            "110/186, train_loss: 0.0033\n",
            "111/186, train_loss: 0.0311\n",
            "112/186, train_loss: 0.0511\n",
            "113/186, train_loss: 0.0056\n",
            "114/186, train_loss: 0.0108\n",
            "115/186, train_loss: 0.0370\n",
            "116/186, train_loss: 0.0498\n",
            "117/186, train_loss: 0.0743\n",
            "118/186, train_loss: 0.0258\n",
            "119/186, train_loss: 0.0246\n",
            "120/186, train_loss: 0.0029\n",
            "121/186, train_loss: 0.1129\n",
            "122/186, train_loss: 0.0053\n",
            "123/186, train_loss: 0.0734\n",
            "124/186, train_loss: 0.0283\n",
            "125/186, train_loss: 0.0229\n",
            "126/186, train_loss: 0.0090\n",
            "127/186, train_loss: 0.0037\n",
            "128/186, train_loss: 0.0112\n",
            "129/186, train_loss: 0.1487\n",
            "130/186, train_loss: 0.1161\n",
            "131/186, train_loss: 0.0320\n",
            "132/186, train_loss: 0.0317\n",
            "133/186, train_loss: 0.0301\n",
            "134/186, train_loss: 0.0891\n",
            "135/186, train_loss: 0.0773\n",
            "136/186, train_loss: 0.0199\n",
            "137/186, train_loss: 0.1233\n",
            "138/186, train_loss: 0.0410\n",
            "139/186, train_loss: 1.0323\n",
            "140/186, train_loss: 0.0255\n",
            "141/186, train_loss: 0.0440\n",
            "142/186, train_loss: 0.0738\n",
            "143/186, train_loss: 0.0577\n",
            "144/186, train_loss: 0.0031\n",
            "145/186, train_loss: 0.0291\n",
            "146/186, train_loss: 0.0121\n",
            "147/186, train_loss: 0.1095\n",
            "148/186, train_loss: 0.0305\n",
            "149/186, train_loss: 0.0159\n",
            "150/186, train_loss: 0.1052\n",
            "151/186, train_loss: 0.0043\n",
            "152/186, train_loss: 0.0287\n",
            "153/186, train_loss: 0.0243\n",
            "154/186, train_loss: 0.0263\n",
            "155/186, train_loss: 0.2382\n",
            "156/186, train_loss: 0.0318\n",
            "157/186, train_loss: 0.0125\n",
            "158/186, train_loss: 0.0250\n",
            "159/186, train_loss: 0.2165\n",
            "160/186, train_loss: 1.4789\n",
            "161/186, train_loss: 0.0375\n",
            "162/186, train_loss: 0.0148\n",
            "163/186, train_loss: 0.2546\n",
            "164/186, train_loss: 0.0124\n",
            "165/186, train_loss: 0.0658\n",
            "166/186, train_loss: 0.0276\n",
            "167/186, train_loss: 0.0114\n",
            "168/186, train_loss: 0.0565\n",
            "169/186, train_loss: 0.0114\n",
            "170/186, train_loss: 0.0073\n",
            "171/186, train_loss: 0.0338\n",
            "172/186, train_loss: 0.0056\n",
            "173/186, train_loss: 0.0277\n",
            "174/186, train_loss: 0.0253\n",
            "175/186, train_loss: 0.0740\n",
            "176/186, train_loss: 0.0392\n",
            "177/186, train_loss: 0.0444\n",
            "178/186, train_loss: 0.0258\n",
            "179/186, train_loss: 0.0615\n",
            "180/186, train_loss: 0.3130\n",
            "181/186, train_loss: 0.0757\n",
            "182/186, train_loss: 0.0259\n",
            "183/186, train_loss: 0.0065\n",
            "184/186, train_loss: 0.0172\n",
            "185/186, train_loss: 0.0477\n",
            "186/186, train_loss: 0.0558\n",
            "epoch 42 average loss: 0.1258\n",
            "current epoch: 42 current accuracy: 0.8817 best accuracy: 0.9032 at epoch 34\n",
            "----------\n",
            "epoch 43/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/186, train_loss: 0.0315\n",
            "2/186, train_loss: 0.1320\n",
            "3/186, train_loss: 0.0108\n",
            "4/186, train_loss: 0.0311\n",
            "5/186, train_loss: 0.1018\n",
            "6/186, train_loss: 0.0615\n",
            "7/186, train_loss: 0.0205\n",
            "8/186, train_loss: 0.3688\n",
            "9/186, train_loss: 0.0335\n",
            "10/186, train_loss: 0.0547\n",
            "11/186, train_loss: 0.0769\n",
            "12/186, train_loss: 0.0290\n",
            "13/186, train_loss: 0.0361\n",
            "14/186, train_loss: 0.0142\n",
            "15/186, train_loss: 0.0259\n",
            "16/186, train_loss: 0.0443\n",
            "17/186, train_loss: 0.0259\n",
            "18/186, train_loss: 0.0834\n",
            "19/186, train_loss: 0.0250\n",
            "20/186, train_loss: 0.0082\n",
            "21/186, train_loss: 0.0879\n",
            "22/186, train_loss: 0.0031\n",
            "23/186, train_loss: 0.1174\n",
            "24/186, train_loss: 0.0743\n",
            "25/186, train_loss: 0.0060\n",
            "26/186, train_loss: 0.0454\n",
            "27/186, train_loss: 0.0244\n",
            "28/186, train_loss: 0.0860\n",
            "29/186, train_loss: 0.0249\n",
            "30/186, train_loss: 0.0070\n",
            "31/186, train_loss: 0.0825\n",
            "32/186, train_loss: 0.0077\n",
            "33/186, train_loss: 0.0261\n",
            "34/186, train_loss: 0.0274\n",
            "35/186, train_loss: 0.2077\n",
            "36/186, train_loss: 0.0801\n",
            "37/186, train_loss: 0.3666\n",
            "38/186, train_loss: 0.3448\n",
            "39/186, train_loss: 0.0240\n",
            "40/186, train_loss: 0.0243\n",
            "41/186, train_loss: 0.6229\n",
            "42/186, train_loss: 0.0256\n",
            "43/186, train_loss: 0.0416\n",
            "44/186, train_loss: 0.0278\n",
            "45/186, train_loss: 0.0073\n",
            "46/186, train_loss: 0.0323\n",
            "47/186, train_loss: 0.0542\n",
            "48/186, train_loss: 0.0172\n",
            "49/186, train_loss: 0.0134\n",
            "50/186, train_loss: 0.0528\n",
            "51/186, train_loss: 0.0051\n",
            "52/186, train_loss: 0.0065\n",
            "53/186, train_loss: 0.0221\n",
            "54/186, train_loss: 0.0077\n",
            "55/186, train_loss: 0.0318\n",
            "56/186, train_loss: 0.0065\n",
            "57/186, train_loss: 0.0363\n",
            "58/186, train_loss: 0.0031\n",
            "59/186, train_loss: 0.0331\n",
            "60/186, train_loss: 0.0257\n",
            "61/186, train_loss: 0.0309\n",
            "62/186, train_loss: 0.0357\n",
            "63/186, train_loss: 0.5698\n",
            "64/186, train_loss: 0.0059\n",
            "65/186, train_loss: 0.0149\n",
            "66/186, train_loss: 0.0015\n",
            "67/186, train_loss: 0.1514\n",
            "68/186, train_loss: 0.1117\n",
            "69/186, train_loss: 0.2226\n",
            "70/186, train_loss: 0.0268\n",
            "71/186, train_loss: 0.0221\n",
            "72/186, train_loss: 0.0997\n",
            "73/186, train_loss: 0.0344\n",
            "74/186, train_loss: 0.2950\n",
            "75/186, train_loss: 0.0522\n",
            "76/186, train_loss: 0.0044\n",
            "77/186, train_loss: 0.0812\n",
            "78/186, train_loss: 0.0514\n",
            "79/186, train_loss: 0.0474\n",
            "80/186, train_loss: 0.0347\n",
            "81/186, train_loss: 0.0032\n",
            "82/186, train_loss: 0.0051\n",
            "83/186, train_loss: 0.0082\n",
            "84/186, train_loss: 0.0071\n",
            "85/186, train_loss: 0.0148\n",
            "86/186, train_loss: 0.0157\n",
            "87/186, train_loss: 0.0430\n",
            "88/186, train_loss: 0.0065\n",
            "89/186, train_loss: 0.0137\n",
            "90/186, train_loss: 0.0121\n",
            "91/186, train_loss: 0.0603\n",
            "92/186, train_loss: 0.1345\n",
            "93/186, train_loss: 0.0238\n",
            "94/186, train_loss: 0.0278\n",
            "95/186, train_loss: 0.0043\n",
            "96/186, train_loss: 2.3477\n",
            "97/186, train_loss: 0.0312\n",
            "98/186, train_loss: 0.0285\n",
            "99/186, train_loss: 0.0068\n",
            "100/186, train_loss: 0.0496\n",
            "101/186, train_loss: 0.0296\n",
            "102/186, train_loss: 0.0062\n",
            "103/186, train_loss: 2.8976\n",
            "104/186, train_loss: 0.0026\n",
            "105/186, train_loss: 0.0091\n",
            "106/186, train_loss: 0.0393\n",
            "107/186, train_loss: 0.0796\n",
            "108/186, train_loss: 0.7947\n",
            "109/186, train_loss: 0.0495\n",
            "110/186, train_loss: 0.0471\n",
            "111/186, train_loss: 0.0715\n",
            "112/186, train_loss: 0.0389\n",
            "113/186, train_loss: 0.0108\n",
            "114/186, train_loss: 0.0304\n",
            "115/186, train_loss: 0.0413\n",
            "116/186, train_loss: 0.0138\n",
            "117/186, train_loss: 0.0286\n",
            "118/186, train_loss: 0.0194\n",
            "119/186, train_loss: 0.0184\n",
            "120/186, train_loss: 0.3634\n",
            "121/186, train_loss: 0.0388\n",
            "122/186, train_loss: 0.0101\n",
            "123/186, train_loss: 0.0364\n",
            "124/186, train_loss: 0.0360\n",
            "125/186, train_loss: 0.0293\n",
            "126/186, train_loss: 0.0148\n",
            "127/186, train_loss: 0.0355\n",
            "128/186, train_loss: 0.8167\n",
            "129/186, train_loss: 0.0278\n",
            "130/186, train_loss: 0.0068\n",
            "131/186, train_loss: 1.5130\n",
            "132/186, train_loss: 0.1008\n",
            "133/186, train_loss: 0.1186\n",
            "134/186, train_loss: 0.0087\n",
            "135/186, train_loss: 0.0134\n",
            "136/186, train_loss: 0.0376\n",
            "137/186, train_loss: 0.0200\n",
            "138/186, train_loss: 0.0507\n",
            "139/186, train_loss: 0.1649\n",
            "140/186, train_loss: 0.0117\n",
            "141/186, train_loss: 0.1255\n",
            "142/186, train_loss: 0.0033\n",
            "143/186, train_loss: 0.0700\n",
            "144/186, train_loss: 0.0036\n",
            "145/186, train_loss: 0.0467\n",
            "146/186, train_loss: 0.0295\n",
            "147/186, train_loss: 0.0085\n",
            "148/186, train_loss: 0.0117\n",
            "149/186, train_loss: 0.0089\n",
            "150/186, train_loss: 1.5856\n",
            "151/186, train_loss: 0.0022\n",
            "152/186, train_loss: 0.0397\n",
            "153/186, train_loss: 0.0033\n",
            "154/186, train_loss: 0.0124\n",
            "155/186, train_loss: 0.0067\n",
            "156/186, train_loss: 1.0536\n",
            "157/186, train_loss: 0.0114\n",
            "158/186, train_loss: 0.0062\n",
            "159/186, train_loss: 0.0304\n",
            "160/186, train_loss: 0.0104\n",
            "161/186, train_loss: 0.0343\n",
            "162/186, train_loss: 0.0594\n",
            "163/186, train_loss: 0.0106\n",
            "164/186, train_loss: 0.2451\n",
            "165/186, train_loss: 0.0430\n",
            "166/186, train_loss: 0.0408\n",
            "167/186, train_loss: 0.0494\n",
            "168/186, train_loss: 0.1896\n",
            "169/186, train_loss: 0.0049\n",
            "170/186, train_loss: 0.0197\n",
            "171/186, train_loss: 0.0320\n",
            "172/186, train_loss: 0.0100\n",
            "173/186, train_loss: 0.0648\n",
            "174/186, train_loss: 0.0280\n",
            "175/186, train_loss: 0.0348\n",
            "176/186, train_loss: 0.0089\n",
            "177/186, train_loss: 0.0921\n",
            "178/186, train_loss: 0.0167\n",
            "179/186, train_loss: 0.0254\n",
            "180/186, train_loss: 0.0748\n",
            "181/186, train_loss: 0.0808\n",
            "182/186, train_loss: 0.0159\n",
            "183/186, train_loss: 0.0391\n",
            "184/186, train_loss: 0.3301\n",
            "185/186, train_loss: 0.0076\n",
            "186/186, train_loss: 0.0243\n",
            "epoch 43 average loss: 0.1131\n",
            "----------\n",
            "epoch 44/50\n",
            "1/186, train_loss: 0.0059\n",
            "2/186, train_loss: 0.0266\n",
            "3/186, train_loss: 0.0616\n",
            "4/186, train_loss: 0.1090\n",
            "5/186, train_loss: 0.0274\n",
            "6/186, train_loss: 0.0076\n",
            "7/186, train_loss: 0.0067\n",
            "8/186, train_loss: 0.0155\n",
            "9/186, train_loss: 0.0995\n",
            "10/186, train_loss: 0.0126\n",
            "11/186, train_loss: 0.0033\n",
            "12/186, train_loss: 0.0388\n",
            "13/186, train_loss: 0.0097\n",
            "14/186, train_loss: 0.0060\n",
            "15/186, train_loss: 0.0136\n",
            "16/186, train_loss: 0.0290\n",
            "17/186, train_loss: 0.0222\n",
            "18/186, train_loss: 0.1734\n",
            "19/186, train_loss: 0.1971\n",
            "20/186, train_loss: 0.0370\n",
            "21/186, train_loss: 0.0052\n",
            "22/186, train_loss: 0.0941\n",
            "23/186, train_loss: 0.0254\n",
            "24/186, train_loss: 0.0112\n",
            "25/186, train_loss: 0.0830\n",
            "26/186, train_loss: 0.0354\n",
            "27/186, train_loss: 0.1873\n",
            "28/186, train_loss: 0.0359\n",
            "29/186, train_loss: 0.0028\n",
            "30/186, train_loss: 0.0046\n",
            "31/186, train_loss: 0.0506\n",
            "32/186, train_loss: 0.0348\n",
            "33/186, train_loss: 0.0068\n",
            "34/186, train_loss: 0.0136\n",
            "35/186, train_loss: 0.0442\n",
            "36/186, train_loss: 0.0688\n",
            "37/186, train_loss: 0.0028\n",
            "38/186, train_loss: 0.0397\n",
            "39/186, train_loss: 0.0305\n",
            "40/186, train_loss: 0.0325\n",
            "41/186, train_loss: 0.0305\n",
            "42/186, train_loss: 0.0386\n",
            "43/186, train_loss: 0.0282\n",
            "44/186, train_loss: 0.0435\n",
            "45/186, train_loss: 0.0025\n",
            "46/186, train_loss: 0.0102\n",
            "47/186, train_loss: 0.0248\n",
            "48/186, train_loss: 0.0417\n",
            "49/186, train_loss: 0.0239\n",
            "50/186, train_loss: 0.0232\n",
            "51/186, train_loss: 0.0300\n",
            "52/186, train_loss: 0.0429\n",
            "53/186, train_loss: 0.0262\n",
            "54/186, train_loss: 0.3630\n",
            "55/186, train_loss: 0.0477\n",
            "56/186, train_loss: 0.0649\n",
            "57/186, train_loss: 0.0531\n",
            "58/186, train_loss: 0.0249\n",
            "59/186, train_loss: 0.0054\n",
            "60/186, train_loss: 0.0202\n",
            "61/186, train_loss: 0.0026\n",
            "62/186, train_loss: 0.0326\n",
            "63/186, train_loss: 0.0119\n",
            "64/186, train_loss: 0.1217\n",
            "65/186, train_loss: 0.0106\n",
            "66/186, train_loss: 0.0111\n",
            "67/186, train_loss: 0.1221\n",
            "68/186, train_loss: 0.0581\n",
            "69/186, train_loss: 0.0424\n",
            "70/186, train_loss: 1.6891\n",
            "71/186, train_loss: 0.0087\n",
            "72/186, train_loss: 0.0748\n",
            "73/186, train_loss: 0.0290\n",
            "74/186, train_loss: 0.0263\n",
            "75/186, train_loss: 0.0313\n",
            "76/186, train_loss: 0.0292\n",
            "77/186, train_loss: 0.0964\n",
            "78/186, train_loss: 0.0888\n",
            "79/186, train_loss: 0.0927\n",
            "80/186, train_loss: 0.0098\n",
            "81/186, train_loss: 0.0523\n",
            "82/186, train_loss: 0.0075\n",
            "83/186, train_loss: 0.0335\n",
            "84/186, train_loss: 0.0261\n",
            "85/186, train_loss: 0.0053\n",
            "86/186, train_loss: 0.0214\n",
            "87/186, train_loss: 0.0436\n",
            "88/186, train_loss: 0.0465\n",
            "89/186, train_loss: 0.1254\n",
            "90/186, train_loss: 1.1202\n",
            "91/186, train_loss: 0.0248\n",
            "92/186, train_loss: 0.1619\n",
            "93/186, train_loss: 0.0185\n",
            "94/186, train_loss: 0.0118\n",
            "95/186, train_loss: 0.0340\n",
            "96/186, train_loss: 0.0061\n",
            "97/186, train_loss: 1.6645\n",
            "98/186, train_loss: 0.0249\n",
            "99/186, train_loss: 0.0051\n",
            "100/186, train_loss: 0.0314\n",
            "101/186, train_loss: 0.0606\n",
            "102/186, train_loss: 0.0342\n",
            "103/186, train_loss: 0.0223\n",
            "104/186, train_loss: 0.0169\n",
            "105/186, train_loss: 0.2316\n",
            "106/186, train_loss: 0.0171\n",
            "107/186, train_loss: 0.0514\n",
            "108/186, train_loss: 0.0296\n",
            "109/186, train_loss: 0.0315\n",
            "110/186, train_loss: 0.3259\n",
            "111/186, train_loss: 0.0904\n",
            "112/186, train_loss: 0.0154\n",
            "113/186, train_loss: 0.0232\n",
            "114/186, train_loss: 0.0236\n",
            "115/186, train_loss: 0.0269\n",
            "116/186, train_loss: 0.0205\n",
            "117/186, train_loss: 0.0855\n",
            "118/186, train_loss: 0.0303\n",
            "119/186, train_loss: 0.2050\n",
            "120/186, train_loss: 0.0105\n",
            "121/186, train_loss: 0.3002\n",
            "122/186, train_loss: 0.0232\n",
            "123/186, train_loss: 0.0710\n",
            "124/186, train_loss: 0.0238\n",
            "125/186, train_loss: 0.0600\n",
            "126/186, train_loss: 0.0194\n",
            "127/186, train_loss: 0.1018\n",
            "128/186, train_loss: 0.0415\n",
            "129/186, train_loss: 0.0191\n",
            "130/186, train_loss: 0.0445\n",
            "131/186, train_loss: 0.0242\n",
            "132/186, train_loss: 0.0145\n",
            "133/186, train_loss: 0.0287\n",
            "134/186, train_loss: 0.1230\n",
            "135/186, train_loss: 0.0323\n",
            "136/186, train_loss: 0.0144\n",
            "137/186, train_loss: 1.6573\n",
            "138/186, train_loss: 0.0164\n",
            "139/186, train_loss: 0.0331\n",
            "140/186, train_loss: 0.0107\n",
            "141/186, train_loss: 0.0413\n",
            "142/186, train_loss: 0.0151\n",
            "143/186, train_loss: 0.0815\n",
            "144/186, train_loss: 0.0224\n",
            "145/186, train_loss: 0.0249\n",
            "146/186, train_loss: 0.0193\n",
            "147/186, train_loss: 0.0235\n",
            "148/186, train_loss: 0.0572\n",
            "149/186, train_loss: 0.0077\n",
            "150/186, train_loss: 1.9651\n",
            "151/186, train_loss: 0.0272\n",
            "152/186, train_loss: 0.0354\n",
            "153/186, train_loss: 0.0387\n",
            "154/186, train_loss: 0.0124\n",
            "155/186, train_loss: 2.2036\n",
            "156/186, train_loss: 0.0992\n",
            "157/186, train_loss: 0.0505\n",
            "158/186, train_loss: 0.0255\n",
            "159/186, train_loss: 0.0308\n",
            "160/186, train_loss: 0.2234\n",
            "161/186, train_loss: 0.0253\n",
            "162/186, train_loss: 0.0318\n",
            "163/186, train_loss: 0.0869\n",
            "164/186, train_loss: 0.0284\n",
            "165/186, train_loss: 0.0463\n",
            "166/186, train_loss: 0.1390\n",
            "167/186, train_loss: 0.0208\n",
            "168/186, train_loss: 0.1054\n",
            "169/186, train_loss: 0.1118\n",
            "170/186, train_loss: 0.0199\n",
            "171/186, train_loss: 0.1348\n",
            "172/186, train_loss: 0.0260\n",
            "173/186, train_loss: 0.0665\n",
            "174/186, train_loss: 0.0346\n",
            "175/186, train_loss: 0.0413\n",
            "176/186, train_loss: 0.0762\n",
            "177/186, train_loss: 0.5804\n",
            "178/186, train_loss: 0.0102\n",
            "179/186, train_loss: 0.0041\n",
            "180/186, train_loss: 0.0319\n",
            "181/186, train_loss: 0.0585\n",
            "182/186, train_loss: 0.0070\n",
            "183/186, train_loss: 0.0309\n",
            "184/186, train_loss: 0.0995\n",
            "185/186, train_loss: 0.0199\n",
            "186/186, train_loss: 0.0198\n",
            "epoch 44 average loss: 0.1053\n",
            "saved new best metric model\n",
            "current epoch: 44 current accuracy: 0.9140 best accuracy: 0.9140 at epoch 44\n",
            "----------\n",
            "epoch 45/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/186, train_loss: 0.0737\n",
            "2/186, train_loss: 0.0113\n",
            "3/186, train_loss: 0.0063\n",
            "4/186, train_loss: 0.1070\n",
            "5/186, train_loss: 1.0439\n",
            "6/186, train_loss: 0.0079\n",
            "7/186, train_loss: 0.0351\n",
            "8/186, train_loss: 0.0126\n",
            "9/186, train_loss: 0.0237\n",
            "10/186, train_loss: 0.0802\n",
            "11/186, train_loss: 0.0643\n",
            "12/186, train_loss: 0.0342\n",
            "13/186, train_loss: 0.0430\n",
            "14/186, train_loss: 0.0320\n",
            "15/186, train_loss: 0.0432\n",
            "16/186, train_loss: 0.0426\n",
            "17/186, train_loss: 0.0693\n",
            "18/186, train_loss: 0.0561\n",
            "19/186, train_loss: 0.1562\n",
            "20/186, train_loss: 0.0332\n",
            "21/186, train_loss: 0.0681\n",
            "22/186, train_loss: 0.0763\n",
            "23/186, train_loss: 0.1071\n",
            "24/186, train_loss: 0.1041\n",
            "25/186, train_loss: 0.0232\n",
            "26/186, train_loss: 0.1357\n",
            "27/186, train_loss: 0.0255\n",
            "28/186, train_loss: 0.0229\n",
            "29/186, train_loss: 0.0264\n",
            "30/186, train_loss: 0.0092\n",
            "31/186, train_loss: 0.0311\n",
            "32/186, train_loss: 0.0552\n",
            "33/186, train_loss: 0.0374\n",
            "34/186, train_loss: 0.0212\n",
            "35/186, train_loss: 0.0126\n",
            "36/186, train_loss: 0.0325\n",
            "37/186, train_loss: 0.0353\n",
            "38/186, train_loss: 0.0239\n",
            "39/186, train_loss: 0.0696\n",
            "40/186, train_loss: 0.0088\n",
            "41/186, train_loss: 0.0306\n",
            "42/186, train_loss: 0.0257\n",
            "43/186, train_loss: 0.0161\n",
            "44/186, train_loss: 0.0217\n",
            "45/186, train_loss: 0.0099\n",
            "46/186, train_loss: 0.0242\n",
            "47/186, train_loss: 0.0289\n",
            "48/186, train_loss: 0.0862\n",
            "49/186, train_loss: 0.1136\n",
            "50/186, train_loss: 0.0154\n",
            "51/186, train_loss: 0.0353\n",
            "52/186, train_loss: 0.0211\n",
            "53/186, train_loss: 0.0420\n",
            "54/186, train_loss: 0.0165\n",
            "55/186, train_loss: 0.0443\n",
            "56/186, train_loss: 0.0239\n",
            "57/186, train_loss: 0.0755\n",
            "58/186, train_loss: 0.0689\n",
            "59/186, train_loss: 0.0235\n",
            "60/186, train_loss: 0.0435\n",
            "61/186, train_loss: 0.0348\n",
            "62/186, train_loss: 0.0269\n",
            "63/186, train_loss: 0.0520\n",
            "64/186, train_loss: 0.0240\n",
            "65/186, train_loss: 0.0292\n",
            "66/186, train_loss: 0.0062\n",
            "67/186, train_loss: 0.0026\n",
            "68/186, train_loss: 2.5895\n",
            "69/186, train_loss: 0.0374\n",
            "70/186, train_loss: 0.0105\n",
            "71/186, train_loss: 0.2736\n",
            "72/186, train_loss: 0.0124\n",
            "73/186, train_loss: 0.1827\n",
            "74/186, train_loss: 0.0604\n",
            "75/186, train_loss: 0.1188\n",
            "76/186, train_loss: 0.0154\n",
            "77/186, train_loss: 0.1174\n",
            "78/186, train_loss: 0.0207\n",
            "79/186, train_loss: 0.0107\n",
            "80/186, train_loss: 0.2647\n",
            "81/186, train_loss: 0.0178\n",
            "82/186, train_loss: 0.0039\n",
            "83/186, train_loss: 0.0287\n",
            "84/186, train_loss: 0.0196\n",
            "85/186, train_loss: 0.0534\n",
            "86/186, train_loss: 0.0551\n",
            "87/186, train_loss: 0.0406\n",
            "88/186, train_loss: 0.0140\n",
            "89/186, train_loss: 0.0422\n",
            "90/186, train_loss: 0.0790\n",
            "91/186, train_loss: 0.0435\n",
            "92/186, train_loss: 0.0323\n",
            "93/186, train_loss: 0.0068\n",
            "94/186, train_loss: 1.3765\n",
            "95/186, train_loss: 0.1604\n",
            "96/186, train_loss: 0.0520\n",
            "97/186, train_loss: 0.0109\n",
            "98/186, train_loss: 0.0510\n",
            "99/186, train_loss: 0.0289\n",
            "100/186, train_loss: 0.0515\n",
            "101/186, train_loss: 0.0384\n",
            "102/186, train_loss: 0.0879\n",
            "103/186, train_loss: 0.2330\n",
            "104/186, train_loss: 0.0497\n",
            "105/186, train_loss: 0.0347\n",
            "106/186, train_loss: 0.3498\n",
            "107/186, train_loss: 0.0392\n",
            "108/186, train_loss: 0.1011\n",
            "109/186, train_loss: 1.4457\n",
            "110/186, train_loss: 0.0364\n",
            "111/186, train_loss: 0.0354\n",
            "112/186, train_loss: 0.0354\n",
            "113/186, train_loss: 0.0420\n",
            "114/186, train_loss: 0.0403\n",
            "115/186, train_loss: 0.0177\n",
            "116/186, train_loss: 0.0343\n",
            "117/186, train_loss: 0.0483\n",
            "118/186, train_loss: 0.0109\n",
            "119/186, train_loss: 0.0258\n",
            "120/186, train_loss: 0.0593\n",
            "121/186, train_loss: 0.0029\n",
            "122/186, train_loss: 0.0359\n",
            "123/186, train_loss: 0.3270\n",
            "124/186, train_loss: 0.0507\n",
            "125/186, train_loss: 0.0016\n",
            "126/186, train_loss: 0.3416\n",
            "127/186, train_loss: 0.0398\n",
            "128/186, train_loss: 0.0317\n",
            "129/186, train_loss: 0.0349\n",
            "130/186, train_loss: 0.0281\n",
            "131/186, train_loss: 0.0492\n",
            "132/186, train_loss: 0.0033\n",
            "133/186, train_loss: 0.0814\n",
            "134/186, train_loss: 0.5108\n",
            "135/186, train_loss: 0.0310\n",
            "136/186, train_loss: 0.0458\n",
            "137/186, train_loss: 0.1068\n",
            "138/186, train_loss: 0.0334\n",
            "139/186, train_loss: 0.0458\n",
            "140/186, train_loss: 0.0474\n",
            "141/186, train_loss: 0.0086\n",
            "142/186, train_loss: 0.0235\n",
            "143/186, train_loss: 0.0060\n",
            "144/186, train_loss: 0.0028\n",
            "145/186, train_loss: 0.0373\n",
            "146/186, train_loss: 0.0171\n",
            "147/186, train_loss: 0.0390\n",
            "148/186, train_loss: 0.0824\n",
            "149/186, train_loss: 0.1530\n",
            "150/186, train_loss: 0.0482\n",
            "151/186, train_loss: 0.0259\n",
            "152/186, train_loss: 0.0481\n",
            "153/186, train_loss: 0.0017\n",
            "154/186, train_loss: 0.0525\n",
            "155/186, train_loss: 0.1955\n",
            "156/186, train_loss: 0.0315\n",
            "157/186, train_loss: 0.0031\n",
            "158/186, train_loss: 0.0406\n",
            "159/186, train_loss: 0.0083\n",
            "160/186, train_loss: 0.1458\n",
            "161/186, train_loss: 0.0088\n",
            "162/186, train_loss: 0.0071\n",
            "163/186, train_loss: 0.0293\n",
            "164/186, train_loss: 0.1561\n",
            "165/186, train_loss: 0.0522\n",
            "166/186, train_loss: 0.4721\n",
            "167/186, train_loss: 0.0114\n",
            "168/186, train_loss: 0.0490\n",
            "169/186, train_loss: 0.0082\n",
            "170/186, train_loss: 0.0413\n",
            "171/186, train_loss: 0.0465\n",
            "172/186, train_loss: 0.0854\n",
            "173/186, train_loss: 0.2563\n",
            "174/186, train_loss: 0.0119\n",
            "175/186, train_loss: 0.0105\n",
            "176/186, train_loss: 0.0029\n",
            "177/186, train_loss: 0.0277\n",
            "178/186, train_loss: 0.0150\n",
            "179/186, train_loss: 0.0294\n",
            "180/186, train_loss: 0.0057\n",
            "181/186, train_loss: 0.0013\n",
            "182/186, train_loss: 0.0504\n",
            "183/186, train_loss: 0.2072\n",
            "184/186, train_loss: 0.0030\n",
            "185/186, train_loss: 0.0112\n",
            "186/186, train_loss: 0.0331\n",
            "epoch 45 average loss: 0.0911\n",
            "----------\n",
            "epoch 46/50\n",
            "1/186, train_loss: 0.0359\n",
            "2/186, train_loss: 0.0290\n",
            "3/186, train_loss: 0.0054\n",
            "4/186, train_loss: 0.1090\n",
            "5/186, train_loss: 0.3039\n",
            "6/186, train_loss: 0.0459\n",
            "7/186, train_loss: 0.0646\n",
            "8/186, train_loss: 0.0983\n",
            "9/186, train_loss: 0.0320\n",
            "10/186, train_loss: 0.1581\n",
            "11/186, train_loss: 0.0885\n",
            "12/186, train_loss: 0.0222\n",
            "13/186, train_loss: 0.3381\n",
            "14/186, train_loss: 0.0238\n",
            "15/186, train_loss: 1.4073\n",
            "16/186, train_loss: 0.0728\n",
            "17/186, train_loss: 0.2427\n",
            "18/186, train_loss: 0.0477\n",
            "19/186, train_loss: 0.0263\n",
            "20/186, train_loss: 0.1280\n",
            "21/186, train_loss: 0.0097\n",
            "22/186, train_loss: 0.0359\n",
            "23/186, train_loss: 0.0332\n",
            "24/186, train_loss: 0.0030\n",
            "25/186, train_loss: 0.0117\n",
            "26/186, train_loss: 0.0407\n",
            "27/186, train_loss: 0.0886\n",
            "28/186, train_loss: 0.0589\n",
            "29/186, train_loss: 0.0333\n",
            "30/186, train_loss: 0.0087\n",
            "31/186, train_loss: 0.0458\n",
            "32/186, train_loss: 0.0764\n",
            "33/186, train_loss: 0.0399\n",
            "34/186, train_loss: 0.0094\n",
            "35/186, train_loss: 0.0519\n",
            "36/186, train_loss: 0.0271\n",
            "37/186, train_loss: 0.0444\n",
            "38/186, train_loss: 0.0346\n",
            "39/186, train_loss: 0.0073\n",
            "40/186, train_loss: 0.0427\n",
            "41/186, train_loss: 0.0019\n",
            "42/186, train_loss: 0.1824\n",
            "43/186, train_loss: 0.0066\n",
            "44/186, train_loss: 0.0888\n",
            "45/186, train_loss: 0.0539\n",
            "46/186, train_loss: 0.1509\n",
            "47/186, train_loss: 0.0167\n",
            "48/186, train_loss: 0.0298\n",
            "49/186, train_loss: 0.0680\n",
            "50/186, train_loss: 0.3642\n",
            "51/186, train_loss: 0.0375\n",
            "52/186, train_loss: 0.0386\n",
            "53/186, train_loss: 0.0018\n",
            "54/186, train_loss: 0.0129\n",
            "55/186, train_loss: 0.0349\n",
            "56/186, train_loss: 0.0074\n",
            "57/186, train_loss: 0.0312\n",
            "58/186, train_loss: 0.0111\n",
            "59/186, train_loss: 1.8238\n",
            "60/186, train_loss: 0.0234\n",
            "61/186, train_loss: 0.0734\n",
            "62/186, train_loss: 0.0336\n",
            "63/186, train_loss: 0.0254\n",
            "64/186, train_loss: 0.0088\n",
            "65/186, train_loss: 0.0239\n",
            "66/186, train_loss: 0.0186\n",
            "67/186, train_loss: 0.0100\n",
            "68/186, train_loss: 0.0013\n",
            "69/186, train_loss: 0.0618\n",
            "70/186, train_loss: 0.4090\n",
            "71/186, train_loss: 0.0954\n",
            "72/186, train_loss: 0.1375\n",
            "73/186, train_loss: 0.0369\n",
            "74/186, train_loss: 0.0141\n",
            "75/186, train_loss: 0.0189\n",
            "76/186, train_loss: 0.0356\n",
            "77/186, train_loss: 0.0420\n",
            "78/186, train_loss: 0.0383\n",
            "79/186, train_loss: 0.0387\n",
            "80/186, train_loss: 0.0624\n",
            "81/186, train_loss: 0.0198\n",
            "82/186, train_loss: 0.1531\n",
            "83/186, train_loss: 0.0337\n",
            "84/186, train_loss: 0.1513\n",
            "85/186, train_loss: 0.0298\n",
            "86/186, train_loss: 0.0267\n",
            "87/186, train_loss: 0.1900\n",
            "88/186, train_loss: 0.0053\n",
            "89/186, train_loss: 0.0541\n",
            "90/186, train_loss: 0.0678\n",
            "91/186, train_loss: 0.0735\n",
            "92/186, train_loss: 0.1753\n",
            "93/186, train_loss: 0.0355\n",
            "94/186, train_loss: 0.0342\n",
            "95/186, train_loss: 0.0080\n",
            "96/186, train_loss: 0.2142\n",
            "97/186, train_loss: 0.0666\n",
            "98/186, train_loss: 0.0341\n",
            "99/186, train_loss: 0.0250\n",
            "100/186, train_loss: 0.0324\n",
            "101/186, train_loss: 0.0238\n",
            "102/186, train_loss: 0.0280\n",
            "103/186, train_loss: 0.2305\n",
            "104/186, train_loss: 0.0459\n",
            "105/186, train_loss: 0.0643\n",
            "106/186, train_loss: 0.1020\n",
            "107/186, train_loss: 0.0348\n",
            "108/186, train_loss: 0.0249\n",
            "109/186, train_loss: 0.0354\n",
            "110/186, train_loss: 0.0379\n",
            "111/186, train_loss: 0.8759\n",
            "112/186, train_loss: 0.0346\n",
            "113/186, train_loss: 0.0298\n",
            "114/186, train_loss: 0.0491\n",
            "115/186, train_loss: 0.0277\n",
            "116/186, train_loss: 0.0696\n",
            "117/186, train_loss: 0.0222\n",
            "118/186, train_loss: 0.0425\n",
            "119/186, train_loss: 0.0054\n",
            "120/186, train_loss: 0.0276\n",
            "121/186, train_loss: 0.0251\n",
            "122/186, train_loss: 0.0480\n",
            "123/186, train_loss: 0.0106\n",
            "124/186, train_loss: 0.0083\n",
            "125/186, train_loss: 0.0695\n",
            "126/186, train_loss: 0.0831\n",
            "127/186, train_loss: 0.0136\n",
            "128/186, train_loss: 0.0509\n",
            "129/186, train_loss: 0.0265\n",
            "130/186, train_loss: 0.0754\n",
            "131/186, train_loss: 0.0247\n",
            "132/186, train_loss: 0.0672\n",
            "133/186, train_loss: 0.0052\n",
            "134/186, train_loss: 0.0483\n",
            "135/186, train_loss: 0.0488\n",
            "136/186, train_loss: 0.0234\n",
            "137/186, train_loss: 0.0037\n",
            "138/186, train_loss: 0.0229\n",
            "139/186, train_loss: 0.0383\n",
            "140/186, train_loss: 0.0127\n",
            "141/186, train_loss: 0.0474\n",
            "142/186, train_loss: 0.0633\n",
            "143/186, train_loss: 0.0251\n",
            "144/186, train_loss: 0.0139\n",
            "145/186, train_loss: 0.0620\n",
            "146/186, train_loss: 0.0448\n",
            "147/186, train_loss: 0.7248\n",
            "148/186, train_loss: 0.0218\n",
            "149/186, train_loss: 0.1240\n",
            "150/186, train_loss: 0.0102\n",
            "151/186, train_loss: 0.0182\n",
            "152/186, train_loss: 1.3926\n",
            "153/186, train_loss: 0.0651\n",
            "154/186, train_loss: 0.0072\n",
            "155/186, train_loss: 0.0116\n",
            "156/186, train_loss: 0.0923\n",
            "157/186, train_loss: 0.0166\n",
            "158/186, train_loss: 0.0090\n",
            "159/186, train_loss: 0.0720\n",
            "160/186, train_loss: 0.5928\n",
            "161/186, train_loss: 0.0279\n",
            "162/186, train_loss: 0.0285\n",
            "163/186, train_loss: 0.0539\n",
            "164/186, train_loss: 0.0335\n",
            "165/186, train_loss: 0.8915\n",
            "166/186, train_loss: 0.0244\n",
            "167/186, train_loss: 0.0575\n",
            "168/186, train_loss: 0.0375\n",
            "169/186, train_loss: 0.0366\n",
            "170/186, train_loss: 0.0289\n",
            "171/186, train_loss: 0.6294\n",
            "172/186, train_loss: 0.0290\n",
            "173/186, train_loss: 0.0435\n",
            "174/186, train_loss: 0.0475\n",
            "175/186, train_loss: 0.0234\n",
            "176/186, train_loss: 0.0628\n",
            "177/186, train_loss: 0.0069\n",
            "178/186, train_loss: 0.0703\n",
            "179/186, train_loss: 0.0100\n",
            "180/186, train_loss: 0.6326\n",
            "181/186, train_loss: 0.0052\n",
            "182/186, train_loss: 0.0366\n",
            "183/186, train_loss: 0.1024\n",
            "184/186, train_loss: 0.0429\n",
            "185/186, train_loss: 0.0065\n",
            "186/186, train_loss: 0.0751\n",
            "epoch 46 average loss: 0.0998\n",
            "current epoch: 46 current accuracy: 0.9032 best accuracy: 0.9140 at epoch 44\n",
            "----------\n",
            "epoch 47/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/186, train_loss: 0.0385\n",
            "2/186, train_loss: 0.0273\n",
            "3/186, train_loss: 0.0262\n",
            "4/186, train_loss: 0.0116\n",
            "5/186, train_loss: 0.0240\n",
            "6/186, train_loss: 0.0491\n",
            "7/186, train_loss: 0.0094\n",
            "8/186, train_loss: 0.0086\n",
            "9/186, train_loss: 0.0447\n",
            "10/186, train_loss: 0.0087\n",
            "11/186, train_loss: 0.0313\n",
            "12/186, train_loss: 0.0490\n",
            "13/186, train_loss: 0.0224\n",
            "14/186, train_loss: 0.0324\n",
            "15/186, train_loss: 0.2418\n",
            "16/186, train_loss: 0.0324\n",
            "17/186, train_loss: 0.0079\n",
            "18/186, train_loss: 0.0035\n",
            "19/186, train_loss: 0.1345\n",
            "20/186, train_loss: 0.1071\n",
            "21/186, train_loss: 0.0233\n",
            "22/186, train_loss: 0.0186\n",
            "23/186, train_loss: 0.0054\n",
            "24/186, train_loss: 0.0219\n",
            "25/186, train_loss: 0.0054\n",
            "26/186, train_loss: 0.0041\n",
            "27/186, train_loss: 0.0136\n",
            "28/186, train_loss: 0.0053\n",
            "29/186, train_loss: 0.0795\n",
            "30/186, train_loss: 0.1116\n",
            "31/186, train_loss: 1.5512\n",
            "32/186, train_loss: 0.0253\n",
            "33/186, train_loss: 0.0063\n",
            "34/186, train_loss: 0.0056\n",
            "35/186, train_loss: 0.0339\n",
            "36/186, train_loss: 0.0469\n",
            "37/186, train_loss: 0.0335\n",
            "38/186, train_loss: 0.0034\n",
            "39/186, train_loss: 0.0760\n",
            "40/186, train_loss: 0.9087\n",
            "41/186, train_loss: 0.0448\n",
            "42/186, train_loss: 0.0058\n",
            "43/186, train_loss: 0.0393\n",
            "44/186, train_loss: 0.0894\n",
            "45/186, train_loss: 0.0177\n",
            "46/186, train_loss: 0.0420\n",
            "47/186, train_loss: 0.0248\n",
            "48/186, train_loss: 0.0467\n",
            "49/186, train_loss: 0.0083\n",
            "50/186, train_loss: 0.0036\n",
            "51/186, train_loss: 0.0151\n",
            "52/186, train_loss: 0.2670\n",
            "53/186, train_loss: 0.0336\n",
            "54/186, train_loss: 0.0285\n",
            "55/186, train_loss: 0.0717\n",
            "56/186, train_loss: 0.4674\n",
            "57/186, train_loss: 0.0392\n",
            "58/186, train_loss: 0.0015\n",
            "59/186, train_loss: 0.5154\n",
            "60/186, train_loss: 0.0268\n",
            "61/186, train_loss: 0.0193\n",
            "62/186, train_loss: 0.0303\n",
            "63/186, train_loss: 0.0277\n",
            "64/186, train_loss: 0.0224\n",
            "65/186, train_loss: 0.0174\n",
            "66/186, train_loss: 0.0363\n",
            "67/186, train_loss: 0.0294\n",
            "68/186, train_loss: 0.0653\n",
            "69/186, train_loss: 0.0212\n",
            "70/186, train_loss: 0.0048\n",
            "71/186, train_loss: 0.0463\n",
            "72/186, train_loss: 0.0057\n",
            "73/186, train_loss: 0.0046\n",
            "74/186, train_loss: 0.0238\n",
            "75/186, train_loss: 0.1208\n",
            "76/186, train_loss: 0.1017\n",
            "77/186, train_loss: 0.0099\n",
            "78/186, train_loss: 0.0272\n",
            "79/186, train_loss: 0.0210\n",
            "80/186, train_loss: 0.0338\n",
            "81/186, train_loss: 0.1138\n",
            "82/186, train_loss: 0.1700\n",
            "83/186, train_loss: 0.1107\n",
            "84/186, train_loss: 0.0263\n",
            "85/186, train_loss: 0.0080\n",
            "86/186, train_loss: 0.0109\n",
            "87/186, train_loss: 0.2368\n",
            "88/186, train_loss: 0.0104\n",
            "89/186, train_loss: 0.0087\n",
            "90/186, train_loss: 0.0209\n",
            "91/186, train_loss: 0.0111\n",
            "92/186, train_loss: 0.0656\n",
            "93/186, train_loss: 0.0203\n",
            "94/186, train_loss: 0.0049\n",
            "95/186, train_loss: 0.0412\n",
            "96/186, train_loss: 1.5980\n",
            "97/186, train_loss: 0.0695\n",
            "98/186, train_loss: 0.0026\n",
            "99/186, train_loss: 0.0216\n",
            "100/186, train_loss: 0.0022\n",
            "101/186, train_loss: 0.0250\n",
            "102/186, train_loss: 0.0114\n",
            "103/186, train_loss: 0.0315\n",
            "104/186, train_loss: 0.0093\n",
            "105/186, train_loss: 0.0251\n",
            "106/186, train_loss: 0.0863\n",
            "107/186, train_loss: 0.0724\n",
            "108/186, train_loss: 0.0082\n",
            "109/186, train_loss: 0.0082\n",
            "110/186, train_loss: 0.0270\n",
            "111/186, train_loss: 1.4508\n",
            "112/186, train_loss: 0.0171\n",
            "113/186, train_loss: 0.0085\n",
            "114/186, train_loss: 0.0236\n",
            "115/186, train_loss: 0.1158\n",
            "116/186, train_loss: 0.0217\n",
            "117/186, train_loss: 0.0057\n",
            "118/186, train_loss: 0.0075\n",
            "119/186, train_loss: 0.1176\n",
            "120/186, train_loss: 0.2074\n",
            "121/186, train_loss: 0.0692\n",
            "122/186, train_loss: 0.0199\n",
            "123/186, train_loss: 0.1720\n",
            "124/186, train_loss: 0.0233\n",
            "125/186, train_loss: 0.0071\n",
            "126/186, train_loss: 0.0150\n",
            "127/186, train_loss: 0.0069\n",
            "128/186, train_loss: 0.0043\n",
            "129/186, train_loss: 0.0285\n",
            "130/186, train_loss: 0.0241\n",
            "131/186, train_loss: 0.0176\n",
            "132/186, train_loss: 0.0022\n",
            "133/186, train_loss: 0.0241\n",
            "134/186, train_loss: 0.1925\n",
            "135/186, train_loss: 0.0315\n",
            "136/186, train_loss: 0.0327\n",
            "137/186, train_loss: 0.0060\n",
            "138/186, train_loss: 0.0042\n",
            "139/186, train_loss: 0.0383\n",
            "140/186, train_loss: 0.0313\n",
            "141/186, train_loss: 0.0090\n",
            "142/186, train_loss: 0.0418\n",
            "143/186, train_loss: 0.0065\n",
            "144/186, train_loss: 0.0188\n",
            "145/186, train_loss: 0.0261\n",
            "146/186, train_loss: 0.0022\n",
            "147/186, train_loss: 0.1680\n",
            "148/186, train_loss: 0.0561\n",
            "149/186, train_loss: 0.0274\n",
            "150/186, train_loss: 0.0459\n",
            "151/186, train_loss: 0.0114\n",
            "152/186, train_loss: 0.0344\n",
            "153/186, train_loss: 0.0323\n",
            "154/186, train_loss: 0.1477\n",
            "155/186, train_loss: 0.0055\n",
            "156/186, train_loss: 0.0241\n",
            "157/186, train_loss: 0.0333\n",
            "158/186, train_loss: 0.0665\n",
            "159/186, train_loss: 0.0134\n",
            "160/186, train_loss: 0.0089\n",
            "161/186, train_loss: 0.0100\n",
            "162/186, train_loss: 0.0703\n",
            "163/186, train_loss: 0.0190\n",
            "164/186, train_loss: 0.0199\n",
            "165/186, train_loss: 0.0104\n",
            "166/186, train_loss: 0.0770\n",
            "167/186, train_loss: 0.0352\n",
            "168/186, train_loss: 0.0013\n",
            "169/186, train_loss: 0.0029\n",
            "170/186, train_loss: 0.0024\n",
            "171/186, train_loss: 0.0101\n",
            "172/186, train_loss: 0.0370\n",
            "173/186, train_loss: 0.0030\n",
            "174/186, train_loss: 0.0169\n",
            "175/186, train_loss: 0.0061\n",
            "176/186, train_loss: 0.0064\n",
            "177/186, train_loss: 0.0054\n",
            "178/186, train_loss: 2.0225\n",
            "179/186, train_loss: 0.0250\n",
            "180/186, train_loss: 0.0024\n",
            "181/186, train_loss: 0.0232\n",
            "182/186, train_loss: 0.0116\n",
            "183/186, train_loss: 0.0554\n",
            "184/186, train_loss: 0.0184\n",
            "185/186, train_loss: 0.0104\n",
            "186/186, train_loss: 0.0151\n",
            "epoch 47 average loss: 0.0819\n",
            "----------\n",
            "epoch 48/50\n",
            "1/186, train_loss: 0.0257\n",
            "2/186, train_loss: 0.0604\n",
            "3/186, train_loss: 0.0871\n",
            "4/186, train_loss: 0.0240\n",
            "5/186, train_loss: 0.0225\n",
            "6/186, train_loss: 0.0221\n",
            "7/186, train_loss: 0.0623\n",
            "8/186, train_loss: 0.0419\n",
            "9/186, train_loss: 0.0365\n",
            "10/186, train_loss: 0.0085\n",
            "11/186, train_loss: 0.0293\n",
            "12/186, train_loss: 0.0321\n",
            "13/186, train_loss: 0.0246\n",
            "14/186, train_loss: 0.0141\n",
            "15/186, train_loss: 0.0142\n",
            "16/186, train_loss: 0.0491\n",
            "17/186, train_loss: 0.0187\n",
            "18/186, train_loss: 0.0267\n",
            "19/186, train_loss: 0.3979\n",
            "20/186, train_loss: 0.0514\n",
            "21/186, train_loss: 0.0182\n",
            "22/186, train_loss: 0.0188\n",
            "23/186, train_loss: 0.0390\n",
            "24/186, train_loss: 0.0257\n",
            "25/186, train_loss: 0.0814\n",
            "26/186, train_loss: 0.1325\n",
            "27/186, train_loss: 0.0214\n",
            "28/186, train_loss: 0.0137\n",
            "29/186, train_loss: 0.0359\n",
            "30/186, train_loss: 0.0223\n",
            "31/186, train_loss: 0.0199\n",
            "32/186, train_loss: 0.1077\n",
            "33/186, train_loss: 0.0066\n",
            "34/186, train_loss: 0.0061\n",
            "35/186, train_loss: 0.0765\n",
            "36/186, train_loss: 0.0079\n",
            "37/186, train_loss: 0.0481\n",
            "38/186, train_loss: 0.0253\n",
            "39/186, train_loss: 0.0112\n",
            "40/186, train_loss: 0.0517\n",
            "41/186, train_loss: 0.0422\n",
            "42/186, train_loss: 0.0325\n",
            "43/186, train_loss: 0.0280\n",
            "44/186, train_loss: 0.0130\n",
            "45/186, train_loss: 0.0046\n",
            "46/186, train_loss: 0.0551\n",
            "47/186, train_loss: 0.0695\n",
            "48/186, train_loss: 0.0647\n",
            "49/186, train_loss: 0.0202\n",
            "50/186, train_loss: 1.9465\n",
            "51/186, train_loss: 0.0079\n",
            "52/186, train_loss: 0.0244\n",
            "53/186, train_loss: 0.2644\n",
            "54/186, train_loss: 0.0072\n",
            "55/186, train_loss: 0.0299\n",
            "56/186, train_loss: 0.0043\n",
            "57/186, train_loss: 0.0062\n",
            "58/186, train_loss: 0.0642\n",
            "59/186, train_loss: 0.0085\n",
            "60/186, train_loss: 0.0070\n",
            "61/186, train_loss: 1.6001\n",
            "62/186, train_loss: 0.0418\n",
            "63/186, train_loss: 0.0195\n",
            "64/186, train_loss: 0.0328\n",
            "65/186, train_loss: 0.0741\n",
            "66/186, train_loss: 0.0376\n",
            "67/186, train_loss: 0.0323\n",
            "68/186, train_loss: 0.0047\n",
            "69/186, train_loss: 0.0442\n",
            "70/186, train_loss: 0.0826\n",
            "71/186, train_loss: 0.0368\n",
            "72/186, train_loss: 0.0015\n",
            "73/186, train_loss: 0.0646\n",
            "74/186, train_loss: 0.0520\n",
            "75/186, train_loss: 0.0652\n",
            "76/186, train_loss: 1.4385\n",
            "77/186, train_loss: 0.0777\n",
            "78/186, train_loss: 0.0806\n",
            "79/186, train_loss: 0.0559\n",
            "80/186, train_loss: 0.0385\n",
            "81/186, train_loss: 0.0258\n",
            "82/186, train_loss: 0.0272\n",
            "83/186, train_loss: 0.0068\n",
            "84/186, train_loss: 0.0428\n",
            "85/186, train_loss: 0.0269\n",
            "86/186, train_loss: 0.0374\n",
            "87/186, train_loss: 0.0423\n",
            "88/186, train_loss: 0.0114\n",
            "89/186, train_loss: 0.0348\n",
            "90/186, train_loss: 0.0248\n",
            "91/186, train_loss: 0.0263\n",
            "92/186, train_loss: 0.0343\n",
            "93/186, train_loss: 0.0291\n",
            "94/186, train_loss: 0.1206\n",
            "95/186, train_loss: 0.5738\n",
            "96/186, train_loss: 2.1295\n",
            "97/186, train_loss: 0.0233\n",
            "98/186, train_loss: 0.0121\n",
            "99/186, train_loss: 0.0268\n",
            "100/186, train_loss: 0.0126\n",
            "101/186, train_loss: 0.0286\n",
            "102/186, train_loss: 0.0295\n",
            "103/186, train_loss: 0.0437\n",
            "104/186, train_loss: 0.0023\n",
            "105/186, train_loss: 0.0499\n",
            "106/186, train_loss: 0.0071\n",
            "107/186, train_loss: 0.0704\n",
            "108/186, train_loss: 0.1694\n",
            "109/186, train_loss: 0.0286\n",
            "110/186, train_loss: 0.0333\n",
            "111/186, train_loss: 0.0482\n",
            "112/186, train_loss: 0.0238\n",
            "113/186, train_loss: 0.0537\n",
            "114/186, train_loss: 0.1048\n",
            "115/186, train_loss: 0.0580\n",
            "116/186, train_loss: 0.0874\n",
            "117/186, train_loss: 0.0127\n",
            "118/186, train_loss: 0.0050\n",
            "119/186, train_loss: 0.1052\n",
            "120/186, train_loss: 0.0325\n",
            "121/186, train_loss: 0.0211\n",
            "122/186, train_loss: 0.0261\n",
            "123/186, train_loss: 0.0139\n",
            "124/186, train_loss: 0.0996\n",
            "125/186, train_loss: 0.0135\n",
            "126/186, train_loss: 0.0414\n",
            "127/186, train_loss: 0.0237\n",
            "128/186, train_loss: 0.0039\n",
            "129/186, train_loss: 0.0400\n",
            "130/186, train_loss: 0.0526\n",
            "131/186, train_loss: 0.0352\n",
            "132/186, train_loss: 0.5271\n",
            "133/186, train_loss: 0.0048\n",
            "134/186, train_loss: 0.4989\n",
            "135/186, train_loss: 0.0158\n",
            "136/186, train_loss: 0.0073\n",
            "137/186, train_loss: 0.0580\n",
            "138/186, train_loss: 0.0270\n",
            "139/186, train_loss: 0.0025\n",
            "140/186, train_loss: 0.1110\n",
            "141/186, train_loss: 0.0034\n",
            "142/186, train_loss: 0.0033\n",
            "143/186, train_loss: 0.0267\n",
            "144/186, train_loss: 0.0263\n",
            "145/186, train_loss: 0.0251\n",
            "146/186, train_loss: 0.0329\n",
            "147/186, train_loss: 0.0053\n",
            "148/186, train_loss: 0.0253\n",
            "149/186, train_loss: 0.5036\n",
            "150/186, train_loss: 0.0515\n",
            "151/186, train_loss: 0.0238\n",
            "152/186, train_loss: 0.0897\n",
            "153/186, train_loss: 0.0290\n",
            "154/186, train_loss: 0.0281\n",
            "155/186, train_loss: 0.0194\n",
            "156/186, train_loss: 0.0951\n",
            "157/186, train_loss: 0.0232\n",
            "158/186, train_loss: 0.0234\n",
            "159/186, train_loss: 0.0014\n",
            "160/186, train_loss: 0.0211\n",
            "161/186, train_loss: 0.0312\n",
            "162/186, train_loss: 0.0242\n",
            "163/186, train_loss: 0.0036\n",
            "164/186, train_loss: 0.0232\n",
            "165/186, train_loss: 0.0084\n",
            "166/186, train_loss: 0.1213\n",
            "167/186, train_loss: 0.0957\n",
            "168/186, train_loss: 0.0154\n",
            "169/186, train_loss: 0.0047\n",
            "170/186, train_loss: 0.0256\n",
            "171/186, train_loss: 0.0268\n",
            "172/186, train_loss: 0.0225\n",
            "173/186, train_loss: 0.1172\n",
            "174/186, train_loss: 0.0073\n",
            "175/186, train_loss: 0.0277\n",
            "176/186, train_loss: 0.0286\n",
            "177/186, train_loss: 0.0084\n",
            "178/186, train_loss: 0.0204\n",
            "179/186, train_loss: 0.0228\n",
            "180/186, train_loss: 0.0024\n",
            "181/186, train_loss: 0.0071\n",
            "182/186, train_loss: 0.0017\n",
            "183/186, train_loss: 0.0231\n",
            "184/186, train_loss: 0.3415\n",
            "185/186, train_loss: 0.0187\n",
            "186/186, train_loss: 0.0328\n",
            "epoch 48 average loss: 0.0882\n",
            "saved new best metric model\n",
            "current epoch: 48 current accuracy: 0.9247 best accuracy: 0.9247 at epoch 48\n",
            "----------\n",
            "epoch 49/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/186, train_loss: 0.0055\n",
            "2/186, train_loss: 0.0037\n",
            "3/186, train_loss: 0.0090\n",
            "4/186, train_loss: 0.0412\n",
            "5/186, train_loss: 0.0134\n",
            "6/186, train_loss: 0.0026\n",
            "7/186, train_loss: 0.0662\n",
            "8/186, train_loss: 0.0025\n",
            "9/186, train_loss: 0.0201\n",
            "10/186, train_loss: 0.0073\n",
            "11/186, train_loss: 0.0053\n",
            "12/186, train_loss: 0.0076\n",
            "13/186, train_loss: 0.0317\n",
            "14/186, train_loss: 0.0379\n",
            "15/186, train_loss: 0.0207\n",
            "16/186, train_loss: 0.0254\n",
            "17/186, train_loss: 0.0194\n",
            "18/186, train_loss: 0.0296\n",
            "19/186, train_loss: 0.0260\n",
            "20/186, train_loss: 0.0319\n",
            "21/186, train_loss: 0.0020\n",
            "22/186, train_loss: 0.0205\n",
            "23/186, train_loss: 0.0127\n",
            "24/186, train_loss: 0.0956\n",
            "25/186, train_loss: 0.0599\n",
            "26/186, train_loss: 0.0057\n",
            "27/186, train_loss: 0.0029\n",
            "28/186, train_loss: 0.0414\n",
            "29/186, train_loss: 1.8695\n",
            "30/186, train_loss: 0.0017\n",
            "31/186, train_loss: 0.8020\n",
            "32/186, train_loss: 0.0120\n",
            "33/186, train_loss: 0.0061\n",
            "34/186, train_loss: 0.0110\n",
            "35/186, train_loss: 0.0078\n",
            "36/186, train_loss: 0.0057\n",
            "37/186, train_loss: 0.0067\n",
            "38/186, train_loss: 0.0273\n",
            "39/186, train_loss: 0.0503\n",
            "40/186, train_loss: 0.1413\n",
            "41/186, train_loss: 0.0412\n",
            "42/186, train_loss: 0.0849\n",
            "43/186, train_loss: 0.0135\n",
            "44/186, train_loss: 0.0406\n",
            "45/186, train_loss: 0.0255\n",
            "46/186, train_loss: 0.0685\n",
            "47/186, train_loss: 0.4406\n",
            "48/186, train_loss: 0.0114\n",
            "49/186, train_loss: 0.0094\n",
            "50/186, train_loss: 0.0030\n",
            "51/186, train_loss: 0.0429\n",
            "52/186, train_loss: 0.0482\n",
            "53/186, train_loss: 0.0317\n",
            "54/186, train_loss: 0.0556\n",
            "55/186, train_loss: 0.0088\n",
            "56/186, train_loss: 1.2849\n",
            "57/186, train_loss: 0.0470\n",
            "58/186, train_loss: 0.0093\n",
            "59/186, train_loss: 0.0281\n",
            "60/186, train_loss: 0.0314\n",
            "61/186, train_loss: 0.5125\n",
            "62/186, train_loss: 0.0065\n",
            "63/186, train_loss: 0.0018\n",
            "64/186, train_loss: 0.0309\n",
            "65/186, train_loss: 1.3905\n",
            "66/186, train_loss: 0.1337\n",
            "67/186, train_loss: 0.0050\n",
            "68/186, train_loss: 0.0105\n",
            "69/186, train_loss: 0.0280\n",
            "70/186, train_loss: 0.0300\n",
            "71/186, train_loss: 0.0131\n",
            "72/186, train_loss: 0.0166\n",
            "73/186, train_loss: 0.0389\n",
            "74/186, train_loss: 0.3720\n",
            "75/186, train_loss: 0.0101\n",
            "76/186, train_loss: 0.0695\n",
            "77/186, train_loss: 0.0286\n",
            "78/186, train_loss: 0.0731\n",
            "79/186, train_loss: 0.0048\n",
            "80/186, train_loss: 0.0499\n",
            "81/186, train_loss: 0.0365\n",
            "82/186, train_loss: 0.0086\n",
            "83/186, train_loss: 0.0910\n",
            "84/186, train_loss: 0.0272\n",
            "85/186, train_loss: 0.0342\n",
            "86/186, train_loss: 0.0301\n",
            "87/186, train_loss: 0.0028\n",
            "88/186, train_loss: 0.0209\n",
            "89/186, train_loss: 0.0027\n",
            "90/186, train_loss: 0.0080\n",
            "91/186, train_loss: 0.0353\n",
            "92/186, train_loss: 0.0363\n",
            "93/186, train_loss: 0.0124\n",
            "94/186, train_loss: 0.0093\n",
            "95/186, train_loss: 0.0569\n",
            "96/186, train_loss: 0.0170\n",
            "97/186, train_loss: 0.0026\n",
            "98/186, train_loss: 0.0369\n",
            "99/186, train_loss: 0.0489\n",
            "100/186, train_loss: 0.0325\n",
            "101/186, train_loss: 0.0102\n",
            "102/186, train_loss: 0.0077\n",
            "103/186, train_loss: 0.0607\n",
            "104/186, train_loss: 0.0113\n",
            "105/186, train_loss: 0.0063\n",
            "106/186, train_loss: 0.0022\n",
            "107/186, train_loss: 0.0090\n",
            "108/186, train_loss: 0.0068\n",
            "109/186, train_loss: 0.4738\n",
            "110/186, train_loss: 0.0377\n",
            "111/186, train_loss: 0.0324\n",
            "112/186, train_loss: 0.0297\n",
            "113/186, train_loss: 0.0101\n",
            "114/186, train_loss: 0.0223\n",
            "115/186, train_loss: 0.0282\n",
            "116/186, train_loss: 0.0047\n",
            "117/186, train_loss: 0.2091\n",
            "118/186, train_loss: 0.0115\n",
            "119/186, train_loss: 0.0022\n",
            "120/186, train_loss: 0.0121\n",
            "121/186, train_loss: 0.0421\n",
            "122/186, train_loss: 0.0084\n",
            "123/186, train_loss: 0.0069\n",
            "124/186, train_loss: 0.0044\n",
            "125/186, train_loss: 0.0763\n",
            "126/186, train_loss: 0.0261\n",
            "127/186, train_loss: 0.0654\n",
            "128/186, train_loss: 0.2770\n",
            "129/186, train_loss: 0.0164\n",
            "130/186, train_loss: 0.0258\n",
            "131/186, train_loss: 0.0037\n",
            "132/186, train_loss: 0.0132\n",
            "133/186, train_loss: 0.0024\n",
            "134/186, train_loss: 0.0226\n",
            "135/186, train_loss: 0.0514\n",
            "136/186, train_loss: 0.0398\n",
            "137/186, train_loss: 0.0055\n",
            "138/186, train_loss: 0.0248\n",
            "139/186, train_loss: 0.1585\n",
            "140/186, train_loss: 0.0336\n",
            "141/186, train_loss: 0.0151\n",
            "142/186, train_loss: 0.0012\n",
            "143/186, train_loss: 0.0480\n",
            "144/186, train_loss: 0.0193\n",
            "145/186, train_loss: 0.0262\n",
            "146/186, train_loss: 0.0475\n",
            "147/186, train_loss: 0.0535\n",
            "148/186, train_loss: 0.0601\n",
            "149/186, train_loss: 0.0085\n",
            "150/186, train_loss: 0.0195\n",
            "151/186, train_loss: 0.0070\n",
            "152/186, train_loss: 0.0639\n",
            "153/186, train_loss: 0.0113\n",
            "154/186, train_loss: 0.0244\n",
            "155/186, train_loss: 0.0162\n",
            "156/186, train_loss: 0.0684\n",
            "157/186, train_loss: 0.0254\n",
            "158/186, train_loss: 0.1491\n",
            "159/186, train_loss: 0.0303\n",
            "160/186, train_loss: 0.0222\n",
            "161/186, train_loss: 0.0080\n",
            "162/186, train_loss: 0.0026\n",
            "163/186, train_loss: 0.0242\n",
            "164/186, train_loss: 0.0329\n",
            "165/186, train_loss: 0.0223\n",
            "166/186, train_loss: 0.0076\n",
            "167/186, train_loss: 0.1611\n",
            "168/186, train_loss: 0.0412\n",
            "169/186, train_loss: 0.8905\n",
            "170/186, train_loss: 0.0096\n",
            "171/186, train_loss: 1.8064\n",
            "172/186, train_loss: 0.0273\n",
            "173/186, train_loss: 0.0330\n",
            "174/186, train_loss: 0.0034\n",
            "175/186, train_loss: 0.0054\n",
            "176/186, train_loss: 0.0158\n",
            "177/186, train_loss: 0.0088\n",
            "178/186, train_loss: 0.0042\n",
            "179/186, train_loss: 0.9264\n",
            "180/186, train_loss: 0.0364\n",
            "181/186, train_loss: 0.0250\n",
            "182/186, train_loss: 0.0013\n",
            "183/186, train_loss: 0.0441\n",
            "184/186, train_loss: 0.1844\n",
            "185/186, train_loss: 0.0198\n",
            "186/186, train_loss: 0.0311\n",
            "epoch 49 average loss: 0.0875\n",
            "----------\n",
            "epoch 50/50\n",
            "1/186, train_loss: 0.0103\n",
            "2/186, train_loss: 0.0087\n",
            "3/186, train_loss: 0.0050\n",
            "4/186, train_loss: 0.0096\n",
            "5/186, train_loss: 0.0227\n",
            "6/186, train_loss: 0.0649\n",
            "7/186, train_loss: 0.0388\n",
            "8/186, train_loss: 0.0223\n",
            "9/186, train_loss: 0.0266\n",
            "10/186, train_loss: 0.0231\n",
            "11/186, train_loss: 0.2362\n",
            "12/186, train_loss: 0.1119\n",
            "13/186, train_loss: 0.0249\n",
            "14/186, train_loss: 0.0292\n",
            "15/186, train_loss: 0.0399\n",
            "16/186, train_loss: 1.7238\n",
            "17/186, train_loss: 0.0066\n",
            "18/186, train_loss: 0.0155\n",
            "19/186, train_loss: 0.0495\n",
            "20/186, train_loss: 0.0214\n",
            "21/186, train_loss: 0.0400\n",
            "22/186, train_loss: 0.0019\n",
            "23/186, train_loss: 0.0243\n",
            "24/186, train_loss: 1.0005\n",
            "25/186, train_loss: 0.0238\n",
            "26/186, train_loss: 0.0082\n",
            "27/186, train_loss: 0.0639\n",
            "28/186, train_loss: 0.0121\n",
            "29/186, train_loss: 0.0014\n",
            "30/186, train_loss: 0.0012\n",
            "31/186, train_loss: 0.0337\n",
            "32/186, train_loss: 0.0042\n",
            "33/186, train_loss: 0.0017\n",
            "34/186, train_loss: 0.0591\n",
            "35/186, train_loss: 0.0140\n",
            "36/186, train_loss: 0.0414\n",
            "37/186, train_loss: 0.0271\n",
            "38/186, train_loss: 0.0066\n",
            "39/186, train_loss: 0.0072\n",
            "40/186, train_loss: 0.0235\n",
            "41/186, train_loss: 0.0282\n",
            "42/186, train_loss: 0.0036\n",
            "43/186, train_loss: 0.0038\n",
            "44/186, train_loss: 0.0039\n",
            "45/186, train_loss: 0.0412\n",
            "46/186, train_loss: 0.0049\n",
            "47/186, train_loss: 0.0309\n",
            "48/186, train_loss: 0.0264\n",
            "49/186, train_loss: 0.0323\n",
            "50/186, train_loss: 0.1085\n",
            "51/186, train_loss: 0.0478\n",
            "52/186, train_loss: 0.0478\n",
            "53/186, train_loss: 0.0398\n",
            "54/186, train_loss: 0.0245\n",
            "55/186, train_loss: 0.0015\n",
            "56/186, train_loss: 0.0249\n",
            "57/186, train_loss: 0.0026\n",
            "58/186, train_loss: 0.0049\n",
            "59/186, train_loss: 0.0037\n",
            "60/186, train_loss: 2.1171\n",
            "61/186, train_loss: 0.0037\n",
            "62/186, train_loss: 0.0240\n",
            "63/186, train_loss: 0.0220\n",
            "64/186, train_loss: 0.0682\n",
            "65/186, train_loss: 0.0356\n",
            "66/186, train_loss: 0.0249\n",
            "67/186, train_loss: 0.0280\n",
            "68/186, train_loss: 0.0578\n",
            "69/186, train_loss: 0.0134\n",
            "70/186, train_loss: 0.0172\n",
            "71/186, train_loss: 1.6266\n",
            "72/186, train_loss: 0.0699\n",
            "73/186, train_loss: 0.0338\n",
            "74/186, train_loss: 0.0696\n",
            "75/186, train_loss: 0.0071\n",
            "76/186, train_loss: 0.0907\n",
            "77/186, train_loss: 0.0473\n",
            "78/186, train_loss: 0.0063\n",
            "79/186, train_loss: 0.0312\n",
            "80/186, train_loss: 0.0040\n",
            "81/186, train_loss: 0.0238\n",
            "82/186, train_loss: 0.0286\n",
            "83/186, train_loss: 0.0333\n",
            "84/186, train_loss: 0.0250\n",
            "85/186, train_loss: 0.0272\n",
            "86/186, train_loss: 0.0240\n",
            "87/186, train_loss: 0.1161\n",
            "88/186, train_loss: 0.0123\n",
            "89/186, train_loss: 0.0485\n",
            "90/186, train_loss: 0.0065\n",
            "91/186, train_loss: 0.0023\n",
            "92/186, train_loss: 0.0104\n",
            "93/186, train_loss: 0.0770\n",
            "94/186, train_loss: 0.0131\n",
            "95/186, train_loss: 0.0239\n",
            "96/186, train_loss: 0.0396\n",
            "97/186, train_loss: 0.0028\n",
            "98/186, train_loss: 0.0052\n",
            "99/186, train_loss: 0.1500\n",
            "100/186, train_loss: 0.0186\n",
            "101/186, train_loss: 0.0283\n",
            "102/186, train_loss: 0.0266\n",
            "103/186, train_loss: 0.0931\n",
            "104/186, train_loss: 0.0056\n",
            "105/186, train_loss: 0.0019\n",
            "106/186, train_loss: 0.0277\n",
            "107/186, train_loss: 0.0277\n",
            "108/186, train_loss: 0.0565\n",
            "109/186, train_loss: 0.0324\n",
            "110/186, train_loss: 0.0343\n",
            "111/186, train_loss: 0.0185\n",
            "112/186, train_loss: 0.0775\n",
            "113/186, train_loss: 0.5740\n",
            "114/186, train_loss: 0.1237\n",
            "115/186, train_loss: 0.0216\n",
            "116/186, train_loss: 0.0193\n",
            "117/186, train_loss: 0.0971\n",
            "118/186, train_loss: 0.0770\n",
            "119/186, train_loss: 0.0364\n",
            "120/186, train_loss: 0.0340\n",
            "121/186, train_loss: 0.0344\n",
            "122/186, train_loss: 0.0662\n",
            "123/186, train_loss: 0.0129\n",
            "124/186, train_loss: 0.0125\n",
            "125/186, train_loss: 0.0249\n",
            "126/186, train_loss: 0.2096\n",
            "127/186, train_loss: 0.0444\n",
            "128/186, train_loss: 0.1102\n",
            "129/186, train_loss: 0.1156\n",
            "130/186, train_loss: 0.0044\n",
            "131/186, train_loss: 0.0050\n",
            "132/186, train_loss: 0.0353\n",
            "133/186, train_loss: 0.1059\n",
            "134/186, train_loss: 0.0399\n",
            "135/186, train_loss: 0.0023\n",
            "136/186, train_loss: 0.0844\n",
            "137/186, train_loss: 0.0057\n",
            "138/186, train_loss: 0.0105\n",
            "139/186, train_loss: 0.0363\n",
            "140/186, train_loss: 0.0092\n",
            "141/186, train_loss: 0.0093\n",
            "142/186, train_loss: 0.0266\n",
            "143/186, train_loss: 0.0137\n",
            "144/186, train_loss: 0.0042\n",
            "145/186, train_loss: 0.0018\n",
            "146/186, train_loss: 0.1322\n",
            "147/186, train_loss: 0.0232\n",
            "148/186, train_loss: 0.0452\n",
            "149/186, train_loss: 0.0010\n",
            "150/186, train_loss: 0.0589\n",
            "151/186, train_loss: 0.0365\n",
            "152/186, train_loss: 0.0670\n",
            "153/186, train_loss: 0.0021\n",
            "154/186, train_loss: 0.0104\n",
            "155/186, train_loss: 0.3305\n",
            "156/186, train_loss: 0.0653\n",
            "157/186, train_loss: 0.0027\n",
            "158/186, train_loss: 0.0014\n",
            "159/186, train_loss: 0.0350\n",
            "160/186, train_loss: 0.8210\n",
            "161/186, train_loss: 0.0255\n",
            "162/186, train_loss: 0.1059\n",
            "163/186, train_loss: 0.0117\n",
            "164/186, train_loss: 0.0292\n",
            "165/186, train_loss: 0.2644\n",
            "166/186, train_loss: 0.0019\n",
            "167/186, train_loss: 0.0158\n",
            "168/186, train_loss: 0.0868\n",
            "169/186, train_loss: 0.0019\n",
            "170/186, train_loss: 0.0460\n",
            "171/186, train_loss: 0.0023\n",
            "172/186, train_loss: 0.0343\n",
            "173/186, train_loss: 0.0174\n",
            "174/186, train_loss: 0.0194\n",
            "175/186, train_loss: 0.0358\n",
            "176/186, train_loss: 0.0154\n",
            "177/186, train_loss: 0.0036\n",
            "178/186, train_loss: 0.0363\n",
            "179/186, train_loss: 0.0327\n",
            "180/186, train_loss: 0.0166\n",
            "181/186, train_loss: 0.0248\n",
            "182/186, train_loss: 0.0012\n",
            "183/186, train_loss: 0.0080\n",
            "184/186, train_loss: 0.0209\n",
            "185/186, train_loss: 0.0308\n",
            "186/186, train_loss: 0.0400\n",
            "epoch 50 average loss: 0.0777\n",
            "current epoch: 50 current accuracy: 0.9032 best accuracy: 0.9247 at epoch 48\n",
            "train completed, best_metric: 0.9247 at epoch: 48\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import logging\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import monai\n",
        "from monai.data import ImageDataset, DataLoader\n",
        "from monai.transforms import EnsureChannelFirst, Compose, RandRotate90, Resize, ScaleIntensity, RepeatChannel\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, recall_score, roc_auc_score, f1_score, roc_curve, confusion_matrix, matthews_corrcoef\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision.models.video import r3d_18\n",
        "\n",
        "def load_image_paths_and_labels(cancer_dir, normal_dir):\n",
        "    \"\"\"\n",
        "    Load image paths and corresponding labels from the cancer and normal directories.\n",
        "\n",
        "    Args:\n",
        "    - cancer_dir (str): Directory containing the cancer image files.\n",
        "    - normal_dir (str): Directory containing the normal image files.\n",
        "\n",
        "    Returns:\n",
        "    - image_paths (List[str]): List of image file paths.\n",
        "    - labels (List[int]): List of labels corresponding to the image file paths.\n",
        "    \"\"\"\n",
        "    image_paths = []\n",
        "    labels = []\n",
        "\n",
        "    # Load cancer images\n",
        "    for file in os.listdir(cancer_dir):\n",
        "        if file.endswith('.nii.gz'):\n",
        "            image_paths.append(os.path.join(cancer_dir, file))\n",
        "            labels.append(1)  # Cancer label\n",
        "\n",
        "    # Load normal images\n",
        "    for file in os.listdir(normal_dir):\n",
        "        if file.endswith('.nii.gz'):\n",
        "            image_paths.append(os.path.join(normal_dir, file))\n",
        "            labels.append(0)  # Normal label\n",
        "\n",
        "    return image_paths, labels\n",
        "\n",
        "def plot_and_save_metrics(epochs, train_metrics, val_metrics, metric_name, save_path):\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, train_metrics, label=f'Train {metric_name}')\n",
        "    plt.plot(epochs, val_metrics, label=f'Validation {metric_name}')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel(metric_name)\n",
        "    plt.legend()\n",
        "    plt.title(f'Train and Validation {metric_name}')\n",
        "    plt.savefig(os.path.join(save_path, f'{metric_name}.png'))\n",
        "\n",
        "class ResNeXt3D(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super(ResNeXt3D, self).__init__()\n",
        "        self.model = r3d_18(pretrained=True)\n",
        "        self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "def main():\n",
        "    monai.config.print_config()\n",
        "    logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
        "\n",
        "    # Define data paths\n",
        "    cancer_dir = '/content/drive/MyDrive/Praktikum/common_datasets/common_30P/'  # Directory containing the cancer image files\n",
        "    normal_dir = '/content/drive/MyDrive/Praktikum/common_datasets/common_30P_normal/'  # Directory containing the normal image files\n",
        "\n",
        "    # Number of epochs\n",
        "    num_epochs = 50  # Change this value to set the number of epochs\n",
        "\n",
        "    # Load image paths and labels\n",
        "    images, labels = load_image_paths_and_labels(cancer_dir, normal_dir)\n",
        "    labels = np.array(labels, dtype=np.int64)\n",
        "\n",
        "    # Debugging: Print number of images and labels\n",
        "    print(f\"Number of images: {len(images)}, Number of labels: {len(labels)}\")\n",
        "    print(f\"Labels distribution: {np.bincount(labels)}\")\n",
        "\n",
        "    # Define transforms\n",
        "    train_transforms = Compose([ScaleIntensity(), EnsureChannelFirst(), RepeatChannel(repeats=3), Resize((96, 96, 96)), RandRotate90()])\n",
        "    val_transforms = Compose([ScaleIntensity(), EnsureChannelFirst(), RepeatChannel(repeats=3), Resize((96, 96, 96))])\n",
        "\n",
        "    # Split dataset into training and validation sets\n",
        "    train_images, val_images, train_labels, val_labels = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Debugging: Print train and validation label distributions\n",
        "    print(f\"Train labels distribution: {np.bincount(train_labels)}\")\n",
        "    print(f\"Validation labels distribution: {np.bincount(val_labels)}\")\n",
        "\n",
        "    # Create datasets and dataloaders\n",
        "    train_ds = ImageDataset(image_files=train_images, labels=train_labels, transform=train_transforms)\n",
        "    val_ds = ImageDataset(image_files=val_images, labels=val_labels, transform=val_transforms)\n",
        "\n",
        "    train_loader = DataLoader(train_ds, batch_size=2, shuffle=True, num_workers=2, pin_memory=torch.cuda.is_available())\n",
        "    val_loader = DataLoader(val_ds, batch_size=2, num_workers=2, pin_memory=torch.cuda.is_available())\n",
        "\n",
        "    # Create ResNeXt50 3D, CrossEntropyLoss and Adam optimizer\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = ResNeXt3D(num_classes=2).to(device)\n",
        "    loss_function = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), 1e-5)\n",
        "\n",
        "    val_interval = 2\n",
        "    best_metric = -1\n",
        "    best_metric_epoch = -1\n",
        "    epoch_loss_values = list()\n",
        "    epoch_accuracy_values = list()\n",
        "    epoch_recall_values = list()\n",
        "    epoch_auc_values = list()\n",
        "    epoch_f1_values = list()\n",
        "    epoch_mcc_values = list()\n",
        "    writer = SummaryWriter()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(\"-\" * 10)\n",
        "        print(f\"epoch {epoch + 1}/{num_epochs}\")\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        step = 0\n",
        "        for batch_data in train_loader:\n",
        "            step += 1\n",
        "            inputs, labels = batch_data[0].to(device), batch_data[1].to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_function(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_len = len(train_ds) // train_loader.batch_size\n",
        "            print(f\"{step}/{epoch_len}, train_loss: {loss.item():.4f}\")\n",
        "            writer.add_scalar(\"train_loss\", loss.item(), epoch_len * epoch + step)\n",
        "        epoch_loss /= step\n",
        "        epoch_loss_values.append(epoch_loss)\n",
        "        print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
        "\n",
        "        if (epoch + 1) % val_interval == 0:\n",
        "            model.eval()\n",
        "            val_preds = []\n",
        "            val_true = []\n",
        "            with torch.no_grad():\n",
        "                num_correct = 0.0\n",
        "                metric_count = 0\n",
        "                for val_data in val_loader:\n",
        "                    val_images, val_labels = val_data[0].to(device), val_data[1].to(device)\n",
        "                    val_outputs = model(val_images)\n",
        "                    val_preds.extend(val_outputs.argmax(dim=1).cpu().numpy())\n",
        "                    val_true.extend(val_labels.cpu().numpy())\n",
        "                    value = torch.eq(val_outputs.argmax(dim=1), val_labels)\n",
        "                    metric_count += len(value)\n",
        "                    num_correct += value.sum().item()\n",
        "            accuracy = accuracy_score(val_true, val_preds)\n",
        "            recall = recall_score(val_true, val_preds)\n",
        "            auc = roc_auc_score(val_true, val_preds)\n",
        "            f1 = f1_score(val_true, val_preds)\n",
        "            mcc = matthews_corrcoef(val_true, val_preds)\n",
        "\n",
        "            epoch_accuracy_values.append(accuracy)\n",
        "            epoch_recall_values.append(recall)\n",
        "            epoch_auc_values.append(auc)\n",
        "            epoch_f1_values.append(f1)\n",
        "            epoch_mcc_values.append(mcc)\n",
        "\n",
        "            if accuracy > best_metric:\n",
        "                best_metric = accuracy\n",
        "                best_metric_epoch = epoch + 1\n",
        "                torch.save(model.state_dict(), \"best_metric_model_classification3d_5E_RNext50_3D_512_20P.pth\")\n",
        "                print(\"saved new best metric model\")\n",
        "            print(\n",
        "                f\"current epoch: {epoch + 1} current accuracy: {accuracy:.4f} best accuracy: {best_metric:.4f} at epoch {best_metric_epoch}\"\n",
        "            )\n",
        "            writer.add_scalar(\"val_accuracy\", accuracy, epoch + 1)\n",
        "\n",
        "    # Save metrics as PNG\n",
        "    epochs = list(range(1, num_epochs + 1))\n",
        "    metrics = {\n",
        "        'accuracy': epoch_accuracy_values,\n",
        "        'recall': epoch_recall_values,\n",
        "        'auc': epoch_auc_values,\n",
        "        'f1': epoch_f1_values,\n",
        "        'mcc': epoch_mcc_values\n",
        "    }\n",
        "    for metric_name, metric_values in metrics.items():\n",
        "        plot_and_save_metrics(epochs[:len(metric_values)], epoch_loss_values[:len(metric_values)], metric_values, metric_name, '/content/')\n",
        "\n",
        "    print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")\n",
        "    writer.close()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}